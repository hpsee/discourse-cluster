{
    "303": [
        "<p>This category is for questions that fit into a traditional Question/Answer format where there is a \u201cbest\u201d answer.  The Answer may evolve/change over time, so voting on answers by the community is highly encouraged to ensure that the  current best answer rises to the top!</p>\n<p>Please also vote on your favorite questions as this will determine the order in which they appear in the list!</p>"
    ],
    "74": [
        "<p>I want to use Jupyter notebook to run an analysis which needs access to data stored on the cluster. How can I launch a notebook server on the cluster?</p>\n<p><strong>CURATOR:</strong> Raminder Singh</p>",
        "<p>I recent document this for Harvard users but its very generic. This can help to run Jupyter server remotely on compute nodes of the cluster and connect to your computational notebook using a local browser of your workstation/laptop. <a href=\"https://www.rc.fas.harvard.edu/jupyter-notebook-server-on-odyssey/\">https://www.rc.fas.harvard.edu/jupyter-notebook-server-on-odyssey/</a></p>",
        "<p>A lot of clusters have web interfaces these days, but sometimes you just need basic ssh forwarding and wrappers to help users do it! To help with this, we have the forward tool at Stanford:</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://github.githubassets.com/favicon.ico\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://github.com/vsoch/forward\" target=\"_blank\" rel=\"nofollow noopener\">GitHub</a>\n  </header>\n  <article class=\"onebox-body\">\n    <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/0aed684c8af7d70bea5e2aca1bc7bae3b503fd71.png\" class=\"thumbnail onebox-avatar\" width=\"400\" height=\"400\">\n\n<h3><a href=\"https://github.com/vsoch/forward\" target=\"_blank\" rel=\"nofollow noopener\">vsoch/forward</a></h3>\n\n<p>Sherlock Port Forwarding Utility. Contribute to vsoch/forward development by creating an account on GitHub.</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>And several \u201ctiny tutorials\u201d in the README to help you get started. The ssh configurations are managed in the \u201cssh\u201d folder and the batch submission jobs in the \u201cbatches\u201d folder, so if you have a new cluster or job that you\u2019 like to add, just open an issue and I\u2019d be happy to do this for you (and write another mini tutorial!).</p>",
        "<p>The University of Arizona uses Ohio Supercomputing\u2019s OnDemand software to provide Jupyter notebooks and remote desktops.  It\u2019s free, and easily installed and configured by an experienced admin.  Run\u2019s on CentOS/RHEL 7 and perhaps other Linux variants.</p>\n<p>Intro is at <a href=\"https://www.osc.edu/resources/online_portals/ondemand\">https://www.osc.edu/resources/online_portals/ondemand</a></p>\n<p>Install guide and other info is at <a href=\"https://osc.github.io/ood-documentation/master/\">https://osc.github.io/ood-documentation/master/</a></p>",
        "<p>At Iowa State University, we have Jupyter installed as a module (via spack), and instructions to login via port-forwarding over an ssh tunnel are here:<br>\nVideo: <a href=\"https://researchit.las.iastate.edu/video/research-computing-using-jupyter-notebook\" rel=\"nofollow noopener\">https://researchit.las.iastate.edu/video/research-computing-using-jupyter-notebook</a><br>\nWritten: <a href=\"https://researchit.las.iastate.edu/running-jupyter-notebook-research-it-servers-iowa-state\" rel=\"nofollow noopener\">https://researchit.las.iastate.edu/running-jupyter-notebook-research-it-servers-iowa-state</a></p>\n<p>Note, a user on nearly any system could use <a href=\"https://spack.io\" rel=\"nofollow noopener\">https://spack.io</a> to install jupyter in their own directory and follow these same basic steps, wthether it\u2019s been provided by the institution or not</p>",
        "<p>On the Shared Computing Cluster (SCC) at Boston University, the steps to run Jupyter Notebooks are outlined on the following webpage:<br>\n<a href=\"http://www.bu.edu/tech/support/research/software-and-programming/common-languages/python/jupyter/\">http://www.bu.edu/tech/support/research/software-and-programming/common-languages/python/jupyter/</a></p>"
    ],
    "264": [
        "<p>For a particular type of analysis, I have a large set of <code>*.tar.gz</code> files.  While they are relatively modest in size (100MB-1GB), they are full of roughly 1kB files.  In testing, the overhead of extracting hundreds of thousands of files to disk is far more expensive than the processing I need to do on the data itself.</p>\n<p>Is there a way of directly processing the data inside the <code>tar</code> file, without having to extract it first?</p>",
        "<p>If you use python (or your language of choice) there is a core module called <code>tarfile</code> that can do wonders to:</p>\n<ol>\n<li>read a tarfile into memory</li>\n<li>either edit members in place and write to memory (and then update file) or write to new thing.</li>\n</ol>\n<p>For example, I just wrote up this little snippet <a href=\"https://gist.github.com/vsoch/5ef7cc7974d3bf94a83c16fbc8cda9a8\">https://gist.github.com/vsoch/5ef7cc7974d3bf94a83c16fbc8cda9a8</a> to read a .tar.gz into memory, check permissions, and change if necessary. I\u2019ll also include it here:</p>\n<pre><code class=\"lang-python\">import tarfile\nimport tempfile\nimport stat\nimport os\n\ntar_file = \"input.tar.gz\"\ntar = tarfile.open(tar_file, \"r:gz\")\nmembers = tar.getmembers()\n\nfile_permission = stat.S_IRUSR | stat.S_IWUSR\nfolder_permission = stat.S_IRUSR | stat.S_IWUSR | stat.S_IXUSR\n\n# Let's pretend we want to edit, and write to new tar\nif len(members) &gt; 0:\n    fd, tmp_tar = tempfile.mkstemp(prefix=(\"%s.fixed.\" % tar_file))\n    os.close(fd)\n    fixed_tar = tarfile.open(tmp_tar, \"w:gz\")\n\n    # Then process members\n    for member in members:\n\n        # add o+rwx for directories\n        if member.isdir() and not member.issym():\n            member.mode = folder_permission | member.mode\n            extracted = tar.extractfile(member)\n            fixed_tar.addfile(member, extracted)\n\n        # add o+rw for plain files\n        elif member.isfile() and not member.issym():\n            member.mode = file_permission | member.mode\n            extracted = tar.extractfile(member)\n            fixed_tar.addfile(member, extracted)\n        else:\n            fixed_tar.addfile(member)\n            \n    fixed_tar.close()\n    tar.close()\n\n    # Rename the fixed tar to be the old name\n    os.rename(tmp_tar, tar_file)\nelse:\n    tar.close()\n</code></pre>\n<p>That example is from the original Singularty source code, and there are other examples to:</p>\n<ul>\n<li><a href=\"https://github.com/sylabs/singularity/blob/vault/release-2.6/libexec/python/sutils.py#L153\">Generate New Tar</a></li>\n<li><a href=\"https://github.com/sylabs/singularity/blob/vault/release-2.6/libexec/python/templates.py#L34\">tarinfo template</a></li>\n</ul>\n<p>If you have a specific need or example I\u2019d be happy to help! We can also try outside of Python.</p>",
        "<p>One approach you could take would be to extract files to a temporary location in memory.  Given the size you are working with, the available space on the ram-disk that is mounted by default at <code>/dev/shm</code> should be enough, as long as you make sure to clean these files up after they are analyzed, before extracting the next set.</p>",
        "<p><a class=\"mention\" href=\"/u/jkingsley\">@jkingsley</a>  /dev/shm,  seems like a system specific detail. Is there a more generic name for this?</p>",
        "<p><code>/dev/shm</code> has been a standard feature of linux installs for at least a decade (I don\u2019t actually have an introduction date, but I have seen references as early as 2006).  Unless it was specifically removed for some reason, I would expect it on any modern system.</p>",
        "<p>Rather than extracting the files, you could consider doing your analysis in a language that supports directly manipulating tar files.  For example, python has a <code>tarfile</code> module, which has a streaming mode.  This will allow you to go through and process your files, without having to ever have them reach a disk.</p>",
        "<p><span class=\"mention\">@jkinsley</span> think this <a href=\"https://superuser.com/questions/45342/when-should-i-use-dev-shm-and-when-should-i-use-tmp\">https://superuser.com/questions/45342/when-should-i-use-dev-shm-and-when-should-i-use-tmp</a> covers some of that \u2026 (linux kernal 2.6) \u2026 most common linux distros do have it on by defualt, but it is an optional config.</p>",
        "<p>There is also the tar pipe. Piping it to a filtering tool like grep or sed</p>\n<p>tar xf -O tarfile.tar.gz | sed \u2018regex p\u2019</p>"
    ],
    "215": [
        "<p>I wrote an R script and tested it on my laptop. It finishes 100 iterations in about 1 minute. However I need to run this code for 10,000 iterations, so I submitted my job to run on a cluster. I expected my script to take about 100 times longer (since I use 100 times more iterations), but it looks like it runs much slower than on my local computer. Why? Here is a script I am using:</p>\n<pre><code>x &lt;- matrix(rnorm(10000000), nrow=10000)\nx[sample(1:10000000, 10000, replace=FALSE)] &lt;- NA\n\n  # initialize res \n  res = NULL\n  n = nrow(x)\n  \n  for (i in 1:n) {\n    if ( sum(is.na(x[i,])) &lt; 3 ) res = rbind(res, x[i,])\n  }\n\n  apply(res,1,mean)</code></pre>",
        "<p>rbind() function is very inefficient when used within a large loop.<br>\nYour code dynamically re-allocates (re-addresses) memory in each iteration of the loop. A better approach is to  pre-allocate the memory for the final size.<br>\nHere you  start with an empty matrix and you \u201dgrow\u201d it inside<br>\nthe loop.  During each iteration  of the loop, the computer erases the previous matrix with<br>\ni-1 rows and creates a new matrix with i rows and copies the previous values into it. So with larger values of i this operation is slower and slower.</p>\n<p>Try the following:</p>\n<pre><code>  res = x # initialize res with the size of x\n  k = 0\n  for (i in 1:n) {\n    if (sum(is.na(x[i,]) )&lt; 3) {\n      res[k, ] = x[i,]\n      k = k + 1\n    }\n  }\n  rowMeans(res[1:k,], na.rm=TRUE)</code></pre>"
    ],
    "552": [
        "<p>What is the best way to customize a modulefile (used to specify a particular version of a software) based on some properties of the node? For example, if the node has a GPU, I would like to set the PATH environment variable to point out to the installation directory of the Tensorflow that corresponds to the binaries that handle GPU computations. If however the node does not have GPUs I would like to set the PATH to another directory that contains CPU version of Tensorflow package.</p>",
        "<p>A module file is just a TCL file, so you can use TCL constructs in it. Here I\u2019ve used an \u201cexec\u201d statement to grep the output of lspci and see it finds an NVidia driver. If it does, I\u2019ll set my path accordingly:</p>\n<pre><code>if {[catch {exec /sbin/lspci | grep NVIDIA} results options]} {\n  set gpu_available false\n  append-path PATH /path/to/cpu/tensorflow \n} else {\n  set gpu_available true\n  append-path PATH /path/to/gpu/tensorflow \n}\n\nputs stderr \"Has GPU? $gpu_available\"</code></pre>",
        "<p>Thank you, Ben!<br>\nThis is exactly what I was looking for.<br>\n\u2013Katia</p>"
    ],
    "606": [
        "<p>I have an R script, part of which can be easily converted to run on GPUs. I wrote a C-wrapper script that calls a cuda kernel, but I wonder how I should compile these files in such a way that I can load the resulting shared library into my R script and call my wrapper C function.</p>",
        "<pre><code>#compile cuda code\n\nnvcc -g -G -O2 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_60,code=sm_60 -gencode arch=compute_35,code=sm_35 -I$R_HOME/include -Xcompiler -fpic -c tfbs_cuda.cu -o tfbs_cuda.o\n\n \n\n#compile wrapper code\n\ngcc -std=gnu99 -I$R_HOME/include -fpic -g -O2 -c tfbs_wrapper.c -o tfbs_wrapper.o\n\n \n\n#create shared library\n\nnvcc -shared -Xlinker -L$R_HOME/lib -lR -L$SCC_CUDA_LIB  -o  tfbs_wrapper.so tfbs_wrapper.o tfbs_cuda.o</code></pre>"
    ],
    "921": [
        "<p>Greetings,<br>\nIs there an example of tying Open OnDemand with a virtual machine environment such as VMware, oVirt, RHEVM, OpenStack? We utilize batch connect for our compute environment; however, we would really like to utilize our RHEVM environment for virtual desktops.</p>",
        "<p>There are two integration models for OnDemand and VMs that we have been considering at the moment:</p>\n<ol>\n<li>Use a VM as an optional \u201ccluster\u201d to submit batch connect \u201cjobs\u201d to in order to do interactive work, such as utilizing Jupyter or RStudio for a short period of time, measured in hours.</li>\n<li>Use OnDemand interactive app interface as a way to provision, start up, shut down, and eventually destroy VM images, where the management of the VM might last over a long period of time such as the whole semester for a class</li>\n</ol>\n<p>Which is the model you are primarily interested in? Do you have other models in mind?</p>\n<p>The first has been done before by a site using Slurm and their <a href=\"https://slurm.schedmd.com/elastic_computing.html\" rel=\"nofollow noopener\">cloud bursting feature</a> with AWS.</p>\n<p>We are also looking at possibilities for interfacing directly with cloud environments like OpenStack or AWS and container orchestration like Kubernetes for interactive work, but that is still a work in progress.</p>",
        "<p>What we did in the end was the following. We created an app that is similar to the SSH app that comes with OOD. This custom app calls various backend scripts that is written with ovirt4 python sdk. Using cloud-init within the VM image we can setup websockify and the vncserver. We can then connect to that VM using noVNC through the browser. The upside is that this works and we can load balance user VMs with migration policies. The downside is, it is not plugged into any of the OOD templates and in fact is basically a stand alone app at this point.</p>",
        "<p>Did you mean installation of OnDemand in something like Vagrant? There are a few repos that have those examples, and I assume you would need to customize for your cluster:</p>\n<ul>\n<li><a href=\"https://github.com/OSC/ood-images\" rel=\"nofollow noopener\">https://github.com/OSC/ood-images</a></li>\n<li><a href=\"https://github.com/OSC/ood-images-full\" rel=\"nofollow noopener\">https://github.com/OSC/ood-images-full</a></li>\n</ul>\n<p>For how to integrate into some VM manager, likely you\u2019d want to ask on their repository directly, and (even better) direct them to this issue to answer.</p>",
        "<p>Just to followup on this, for anyone looking for more information about Open OnDemand, our website is <a href=\"http://openondemand.org/\" rel=\"nofollow noopener\">http://openondemand.org/</a></p>\n<p>We also have a very active discussion board at <a href=\"https://discourse.osc.edu/c/open-ondemand\" rel=\"nofollow noopener\">https://discourse.osc.edu/c/open-ondemand</a></p>",
        "<p>We run ood on a vm and use it to jumpstart people on our cluster. The scripts are submitted from the ood vm via slurm and run on our metal compute nodes. We\u2019ve had pretty good luck with it so far. Our power users use the cli though.</p>"
    ],
    "854": [
        "<p>Hi,</p>\n<p>I\u2019m trying to get a singularity container to run using the infiniband network on a cluster I have access to. I can get it to run using MPI fine, but it\u2019s only using TCP/IP and hence the MPI performance is 10x slower than it should be.</p>\n<p>Tracing through where things are going wrong it looks like it\u2019s failing where it\u2019s trying to write to: /dev/infiniband/uverbs0. It looks like it doesn\u2019t have permission to write into there, although such a call works fine for applications run outside singularity (for debugging all I\u2019m running is ibv_devinfo inside and outside singularity and stracing what happens).</p>\n<p>Anyone any ideas why this would happen or what I should do to get around this issue?</p>\n<p>thanks</p>",
        "<p>Hi Adrian,</p>\n<p>Singularity recommendations explicitly says 'To support infiniband the container must support it\". It means that you have to install infiniband libraries and link MPI to them inside the container.</p>\n<p>IMHO, bind-mount external libraries can be a dangerous approach and must be done carefully. We can tell that bind-mounting host libraries inside the container is safe whenever these libraries maintains API/ABI compatibility.</p>\n<p>Can you tell us which library are you overwriting that is the one incompatible (host-container versions)?</p>\n<p>Here I\u2019ve a singularity recipe to install infiniband libraries, It\u2019s old stuff and probable there are more up-to-date recipes anywhere:</p>\n<aside class=\"onebox githubblob\">\n  <header class=\"source\">\n      <a href=\"https://github.com/MSO4SC/Singularity/blob/master/examples/bootstrap_mpi_template.def\" target=\"_blank\" rel=\"nofollow noopener\">github.com</a>\n  </header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://github.com/MSO4SC/Singularity/blob/master/examples/bootstrap_mpi_template.def\" target=\"_blank\" rel=\"nofollow noopener\">MSO4SC/Singularity/blob/master/examples/bootstrap_mpi_template.def</a></h4>\n<pre><code class=\"lang-def\">BootStrap: docker\nFrom: ubuntu:xenial\n#BootStrap: debootstrap\n#OSVersion: xenial\n#MirrorURL: http://us.archive.ubuntu.com/ubuntu/\n\n%setup\n#######################\n# ACTIONS FROM HOST\n# use $SINGULARITY_ROOTFS to refer to container root (/)\n#######################\n\n\n%post\n#######################\n# INSTALL SECTION\n#######################\n\n    #------------------\n    # REQUERIMENTS\n</code></pre>\n\n  This file has been truncated. <a href=\"https://github.com/MSO4SC/Singularity/blob/master/examples/bootstrap_mpi_template.def\" target=\"_blank\" rel=\"nofollow noopener\">show original</a>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Here is a solution in one of the singularity issues:</p>\n<aside class=\"onebox githubissue\">\n  <header class=\"source\">\n      <a href=\"https://github.com/sylabs/singularity/issues/876#issuecomment-323907353\" target=\"_blank\" rel=\"nofollow noopener\">github.com/sylabs/singularity</a>\n  </header>\n  <article class=\"onebox-body\">\n    <a href=\"https://github.com/renganxu\" rel=\"nofollow noopener\">\n<img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/36c9a02eefbbd55dcdcf8d75c3f2b9e48bad2eb9.png\" class=\"thumbnail onebox-avatar\" width=\"420\" height=\"420\">\n</a>\n\n<h4><a href=\"https://github.com/sylabs/singularity/issues/876#issuecomment-323907353\" target=\"_blank\" rel=\"nofollow noopener\">Issue: How to use Infiniband with Singularity</a></h4>\n\n<div class=\"date\" style=\"margin-top:10px;\">\n\t<div class=\"user\" style=\"margin-top:10px;\">\n\topened by <a href=\"https://github.com/renganxu\" target=\"_blank\" rel=\"nofollow noopener\">renganxu</a>\n\ton <a href=\"https://github.com/sylabs/singularity/issues/876#issuecomment-323907353\" target=\"_blank\" rel=\"nofollow noopener\">2017-08-17</a>\n\t</div>\n\t<div class=\"user\">\n\t</div>\n</div>\n\n<pre class=\"content\" style=\"white-space: pre-wrap;\">I am running HPL with Infiniband IBverbs with Singularity container, but I found it is not easy to use. I didn't...</pre>\n\n<div class=\"labels\">\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>Finally, containers are usually built outside of the HPC and libraries/application must be compiled against OpenMPI/PMIx/IB stuff before moving the container to the infrastructure. If you decide to bind-mount host libraries, do not forget to install things before into the container.</p>\n<p>Hope it helps!</p>\n<p>V\u00edctor</p>",
        "<p>In addition, I would like to also post another (debian based) Singularity recipe piece where I install infiniband dependencies:</p>\n<pre><code>...\napt-get install -y dkms infiniband-diags libibverbs* ibacm librdmacm* libmlx4* libmlx5* mstflint libibcm.* libibmad.* libibumad* opensm srptools libmlx4-dev librdmacm-dev rdmacm-utils ibverbs-utils perftest vlan ibutils \n</code></pre>\n<p>\u2026</p>\n<p>Here I\u2019m installing too much things, probably the installation of some of these libraries can be avoided.</p>\n<p>Best,<br>\nV\u00edctor</p>",
        "<p>Hi Victor,</p>\n<p>Thanks, I think the issue I encountered here was a difference between the versions of the infiniband drivers on the host and installed inside the container. Getting the correct infiniband drivers to install in the container is not always possible, i.e.:<br>\n<a href=\"http://www.mellanox.com/page/products_dyn?product_family=26&amp;mtag=linux_sw_drivers\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">http://www.mellanox.com/page/products_dyn?product_family=26&amp;mtag=linux_sw_drivers</a><br>\nThe only available drivers are the latest version and don\u2019t match those installed on the host system. In this case it seems the only way to get the container to use infiniband rather than TCP/IP is to bind the host infiniband drivers.</p>",
        "<p>I should have said, this is Singularity 3.0.3, I\u2019ve installed the infiniband drivers inside the container and strace is showing they are being found. It is likely the infiniband libraries inside the container are not exactly the same version as on the system. At the point I\u2019m getting this error I\u2019ve not yet touched MPI, I\u2019m still just trying to get the infiniband tools working (i.e. ibv_devinfo which should just print out the details information about the infiniband devices I have in the system). ibstat does work, so the container can see the infiniband device is there, but it cannot access it to get detailed information (which I can do outside the container).</p>",
        "<p>This is a response after some discussion from one of the users on the Singularity list, posted with permission, and summarized.</p>\n<hr>\n<p>On our HPC cluster, I bind infiniband related libraries and folders from host to container, I\u2019m able to run <code>ibv_devinfo</code> correctly. Here we first start on the host. <code>LD_LIBRARY_PATH</code> is set as as:</p>\n<pre><code class=\"lang-bash\">$ export LD_LIBRARY_PATH=$MY_LD_LIBRARY_PATH:.:/host/lib:$LD_LIBRARY_PATH\n</code></pre>\n<p>And then we can write a quick testing script.</p>\n<pre><code class=\"lang-bash\">[wang@c17-04 osu-bench]$ cat run-test2.sh \n</code></pre>\n<pre><code class=\"lang-bash\">#!/bin/bash\nimg=/beegfs/work/public/singularity/ubuntu-18.10.simg\nib=/etc/libibverbs.d\nfor lib in /opt/slurm/lib64/lib*.so* /usr/lib64/libosmcomp.so.3* /usr/lib64/libmlx*.so* /usr/lib64/libi40iw-rdmav2.so* /lib64/libib*.so* /usr/lib64/libnl.so*; do\n    ib=\"$lib:/host/lib/$(basename $lib),$ib\"\ndone\nsingularity exec --bind /opt/slurm,/usr/bin/ibv_devinfo,$ib $img ibv_devinfo\n</code></pre>\n<p>Notice how the final command will execute <code>ibv_devinfo</code> to the container, given all the binds are done.<br>\nThis is part of the script above, but I\u2019ll rewrite for clarity:</p>\n<pre><code class=\"lang-bash\">$ singularity exec --bind /opt/slurm,/usr/bin/ibv_devinfo,$ib $img ibv_devinfo\n</code></pre>\n<p>And then to put it all together, here is the output running the script on the host:</p>\n<pre><code class=\"lang-bash\">[wang@c17-04 osu-bench]$ sh run-test2.sh \nhca_id: mlx5_0\n        transport:                      InfiniBand (0)\n        fw_ver:                         12.16.1020\n        node_guid:                      7cfe:9003:0026:9360\n        sys_image_guid:                 7cfe:9003:0026:9360\n        vendor_id:                      0x02c9\n        vendor_part_id:                 4115\n        hw_ver:                         0x0\n        board_id:                       DEL2180110032\n        phys_port_cnt:                  1\n        Device ports:\n                port:   1\n                        state:                  PORT_ACTIVE (4)\n                        max_mtu:                4096 (5)\n                        active_mtu:             4096 (5)\n                        sm_lid:                 194\n                        port_lid:               102\n                        port_lmc:               0x00\n                        link_layer:             InfiniBand\nhca_id: mlx5_0\n        transport:                      InfiniBand (0)\n        fw_ver:                         12.16.1020\n        node_guid:                      7cfe:9003:0026:9360\n        sys_image_guid:                 7cfe:9003:0026:9360\n        vendor_id:                      0x02c9\n        vendor_part_id:                 4115\n        hw_ver:                         0x0\n        board_id:                       DEL2180110032\n        phys_port_cnt:                  1\n\n        Device ports:\n                port:   1\n                        state:                  PORT_ACTIVE (4)\n                        max_mtu:                4096 (5)\n                        active_mtu:             4096 (5)\n                        sm_lid:                 194\n                        port_lid:               102\n                        port_lmc:               0x00\n                        link_layer:             InfiniBand\n</code></pre>\n<p>The setup and details might of course vary by cluster, but this could be a good start for testing.</p>",
        "<p>Thanks Adrian,</p>\n<p>I will take this into account for the next infrastructure I test!</p>\n<p>Best,<br>\nV\u00edctor</p>",
        "<p>Thanks, in the end, for me, this is what I did:</p>\n<p>export SINGULARITY_CONTAINLIBS=/lib64/libmlx5-rdmav2.so,/lib64/libibverbs.so,/lib64/libibverbs.so.1,/lib64/libmlx4-rdmav2.so</p>\n<p>mpirun -x SINGULARITY_CONTAINLIBS   --prefix /lustre/home/z04/adrianj/openmpi/2.1.0 --mca btl openib  --hostfile $PBS_NODEFILE \u2026</p>\n<p>This was after installing the infiniband libraries in the container and building OpenMPI correctly in both places.</p>"
    ],
    "863": [
        "<p>As many of our HPC sites are using SLURM, I wonder if somebody has taken time to write down the meaning of the accounting fields spitted out by SLURM\u2019s <code>sacct</code> command. Its own manual page is very terse:</p>\n<p><a href=\"https://slurm.schedmd.com/sacct.html\" rel=\"nofollow noopener\">https://slurm.schedmd.com/sacct.html</a></p>\n<p>It lists all the available fields but no explanation whatsoever. For example, what is the unit time of \u201cElapsedRaw\u201d field (apparently it is in seconds). What\u2019s the difference between \u201cJobID\u201d and \u201cJobIDRaw\u201d? Things along this line is what I am looking for. I would like to be able to analyze the accounting fields manually. While there exists tools such as XDMOD to provide many aggregate quantities, I would like to be able to do a \u201cdeep drill\u201d into the accounting data directly.</p>",
        "<p>hey <a class=\"mention\" href=\"/u/wirawan0\">@wirawan0</a> did you see this section?</p>\n<p><a href=\"https://slurm.schedmd.com/sacct.html#OPT_ALL\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://slurm.schedmd.com/sacct.html#OPT_ALL</a></p>\n<p>For example, if you look at \u201cElapsed\u201d it shows the format of the time.  And then for JobID vs JobIDRaw:</p>\n<pre><code class=\"lang-auto\">JobID\nThe number of the job or job step. It is in the form: job.jobstep.\n\nJobIDRaw\nIn case of job array print the JobId instead of the ArrayJobId. For non job arrays the output is the JobId in the format job.jobstep.\n</code></pre>\n<p>Are you looking for better clarification than is provided? Here is a nice link to show how to use squeue and sacct for monitoring:</p>\n<p><a href=\"https://wiki.rc.hms.harvard.edu/display/O2/Using+Slurm+Basic#UsingSlurmBasic-MonitoringJobs\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://wiki.rc.hms.harvard.edu/display/O2/Using+Slurm+Basic#UsingSlurmBasic-MonitoringJobs</a></p>\n<p>For example, you can issue this command (and put the comma separated value list of headers you want to include):</p>\n<pre><code class=\"lang-bash\"># get statistics on a completed job\n# you can find all the fields you can specify with the --format parameter by running sacct -e\n# you can specify the width of a field with % and a number, for example --format=JobID%15 for 15 characters\nsacct -j &lt;jobid&gt; --format=JobId,AllocCPUs,State,ReqMem,MaxRSS,Elapsed,TimeLimit,CPUTime,ReqTres\n</code></pre>\n<p>It\u2019s these labels that <a class=\"mention\" href=\"/u/wirawan0\">@wirawan0</a> is asking specifically about, and I\u2019ve reached out to the SLURM team to get some updates on their sacct page. In the meantime, do others have any additional documentation on tricks for monitoring, or custom commands that have worked nicely in the past? Please share your thoughts on this thread!</p>",
        "<p>heyo again <a class=\"mention\" href=\"/u/wirawan0\">@wirawan0</a>! I wanted to let you know that I reached out to our friends at SLURM, and they did some work on that documentation, so things should be a bit more clear now. The changes are represented here: <a href=\"https://github.com/SchedMD/slurm/commit/1a563823285b13a87ac74e7982c1963997491d11\" rel=\"nofollow noopener\">https://github.com/SchedMD/slurm/commit/1a563823285b13a87ac74e7982c1963997491d11</a></p>"
    ],
    "108": [
        "<p>I\u2019ve installed a local Python3 library at <code>/home/$USER/python3lib</code>.  How can I use LMOD to load this library?</p>\n<p><strong>CURATOR:</strong> Grace Wilson Caudill/Scott Valcourt</p>",
        "<p>I think what you might also be asking is how to <em>write</em> a modulefile so that your python program can be loaded with LMOD? Let\u2019s walk through the steps, and the full guide is <a href=\"https://lmod.readthedocs.io/en/latest/015_writing_modules.html\">available here</a>.</p>\n<h2>Write your File</h2>\n<p>The file itself is in a language called \u201clua\u201d and for most, you really just need to prepend to the path to make an executable seen. Here is a simple example: I\u2019m assuming that when you say pyhthon3 library you mean just a module, so we need it seen by <code>$PYTHONPATH</code> (and not a full python installation).</p>\n<pre><code class=\"lang-auto\">help([[\n     Add python modules from /opt/path\n]])\nwhatis(\"Keywords: System, Python\")\nwhatis(\"Description: Python, Modules\")\n\nprepend_path( \"PYTHONPATH\",           \"/opt/path\")\n</code></pre>\n<p>I think for an environment variable you may need to do something like:</p>\n<pre><code class=\"lang-auto\">local username = os.getenv(\"USER\")\nlocal pythonDir  = pathJoin(\"/home\", username, \"pyrhon3lib\")\nprepend_path(\"PYTHONPATH\", pythonDir)\n</code></pre>\n<p>If your module is in some version folder, don\u2019t forget to add that to the path you prepend! Take note there are also functions to <code>setenv</code></p>\n<pre><code class=\"lang-auto\">setenv(\"VARIABLE\", \"value\")\n</code></pre>\n<p>And these are unset when you unload a module. There is also a useful function to append to the path:</p>\n<pre><code class=\"lang-auto\">append_path(\"PATH\", \"/opt/app/bin\")\n</code></pre>\n<p>Check out all the functions <a href=\"https://lmod.readthedocs.io/en/latest/050_lua_modulefiles.html\">here</a>.</p>\n<h2>Put it Somewhere</h2>\n<p>If you are a user adding the file, you can put it anywhere really, then in your <code>.profile</code> add a command to use it:</p>\n<pre><code class=\"lang-auto\">module use $HOME/modules/pythonlib/1.0\n</code></pre>\n<p>If you are an admin, you probably already know how to do this, but <code>$MODULEPATH</code> includes the paths that LMOD can see, so you can add your module there, or still do the above for a custom location (the command above adds it to the same path). For example, here is <code>$MODULEPATH</code> on one of our clusters:</p>\n<pre><code class=\"lang-bash\">$ echo $MODULEPATH\n/share/software/modules/system:/share/software/modules/math:/share/software/modules/devel:/share/software/modules/categories\n</code></pre>\n<p>If we peek into a folder, we see the organization of modules (this is just a subset at the top level)-</p>\n<pre><code class=\"lang-bash\">$ tree /share/software/modules/\nbiology/         physics/       /categories\n</code></pre>\n<p>But how does LMOD know when to look inside physics? This probably varies based on how the resource has it set up (see the docs I\u2019ve linked to read more) but at least for our cluster we have a categories folder (likely added somewhere, I\u2019m not sure where), again with lua files that match each folder at the root, eg:</p>\n<pre><code class=\"lang-bash\">$ tree /share/software/modules/categories\n/share/software/modules/categories\n\u251c\u2500\u2500 biology.lua -&gt; .template\n\u251c\u2500\u2500 chemistry.lua -&gt; .template\n\u251c\u2500\u2500 devel.lua -&gt; .template_sticky\n\u251c\u2500\u2500 labs.lua -&gt; .template\n\u251c\u2500\u2500 math.lua -&gt; .template_sticky\n\u251c\u2500\u2500 physics.lua -&gt; .template\n\u251c\u2500\u2500 README\n\u251c\u2500\u2500 staging.lua\n\u251c\u2500\u2500 system.lua -&gt; .template\n\u2514\u2500\u2500 viz.lua -&gt; .template\n</code></pre>\n<p>and this is the content of a file, which is actually a link to a template, and the only difference is that the name of the file will determine <code>myModuleName()</code> and thus add the complete path in the root folder (e.g., physics)</p>\n<pre><code class=\"lang-bash\">local mroot = os.getenv(\"MODULEPATH_ROOT\")\nlocal mdir  = pathJoin(mroot,myModuleName())\nprepend_path(\"MODULEPATH\", mdir)\n</code></pre>\n<p>And then some physics lua file (for example <code>/share/software/modules/physics/opensees/2.5.0.lua</code> named by version) knows it\u2019s category because:</p>\n<pre><code class=\"lang-auto\">...\nwhatis(\"Category: physics\")\n</code></pre>\n<p>And I\u2019d say it might be good practice to keep this under version control. Now if we are to peek into the physics subfolder, we see a particular organization - did you notice how I used a format of <code>&lt;software-name&gt;/&lt;version&gt;</code> ? That\u2019s done so your future users can load multiple versions, e.g.,</p>\n<pre><code class=\"lang-bash\">module load pythonlib/1.0.0\nmodule load pythonlib/1.2.0\n</code></pre>\n<p>And it also means you can automatically determine the version and name from the path:</p>\n<pre><code class=\"lang-auto\">whatis(\"Name:        \", myModuleName())\nwhatis(\"Version:     \", myModuleVersion())\n</code></pre>\n<p>There is an <a href=\"https://lmod.readthedocs.io/en/latest/060_locating.html\">entire section on that too</a>.</p>\n<h2>Test and Learn More</h2>\n<p>Anyway, there are likely many ways to go about this, and I know so few of the tricks that I\u2019ll stop there! I think your best bet is to keep it simple, and then when you want advanced functionality look to the documentation and other examples online. Finally, a great place to learn is just logging into your clusters, looking at <code>$MODULEPATH</code>, and then inspecting the contents of the folder. Definitely test your module, when you think it\u2019s good:</p>\n<pre><code class=\"lang-bash\">module load pythonlib3\n</code></pre>\n<p>And then as <a class=\"mention\" href=\"/u/sav\">@sav</a> mentioned, you should be able to search with <code>module avail</code> and <code>module spider &lt;term&gt;</code>  It\u2019s really not so bad if it doesn\u2019t work perfectly the first time, just fix up the file (try something different) and try again! You really can\u2019t fail at these things, it comes down to a fancy way for adding/removing from various paths.</p>",
        "<p>To load a local Python3 library module at <code>/home/$USER/python3lib</code> using LMOD, first determine that the module was loaded and is available by entering:</p>\n<pre><code class=\"lang-bash\">$ module avail\n</code></pre>\n<p>If the module appears in the listing, presuming that the module name is python3lib, enter the following command at the command prompt:</p>\n<pre><code class=\"lang-bash\">$ module load python3lib\n</code></pre>",
        "<p><code>$ module avail</code> will show a list of all modules available for loading on the given HPC system.  To see if the module in question is already loaded, use the <code>$ module list</code> command.  This command will tell you which modules are already in your environment.</p>"
    ],
    "126": [
        "<p>I\u2019m trying to run some code with Rscript, but the job is taking longer than the time allowed by the scheduler.<br>\nHow can I use DMTCP to restart jobs that surpass the time limit?</p>\n<p>Here is a very simplified version of my code:</p>\n<pre><code>my_function &lt;- function(curr.seq, weights){\n  \n  # This function takes some time which I simulate here, using system sleep command\n  Sys.sleep (100)\n  \n  return( rnorm(4) )\n}\n  \n\n#simulate input parameters\nset.seed(12345)\nN &lt;- 10000\na.seq &lt;- sapply(1:N, FUN=function(x){paste0(sample(c(\"A\",\"C\",\"G\",\"T\"), 2000, replace=T), collapse=\"\")})\nweights &lt;- c( 0.15,0.1,0.6,0.15)\n\n#initialize matrix to be filled with computed values in the loop\nresult &lt;- matrix(NA, nrow=N, ncol=4)\nfor ( i in 1:N ) {\n  # here I perform a number of intermediate calculations \n  \n  # call function that takes relatively long time to finish\n  result[i,] &lt;- my_function(a.seq[i],  weights)\n  \n  # Since the number of sequences this loop needs to go through is very large, \n  # I would like to add a DMTCP checkpoint here. How do I do this?\n  \n}\n</code></pre>\n<p><strong>CURATOR:</strong>  jpessin1</p>",
        "<p>Scratchpad answer (but has nothing to do with R). By default, the rand_vals program below will use a fixed seed, and generate the same random number sequence each time it starts:</p>\n<pre><code>renfro@gpunode004(job 159188) dmtcp]$ ls\nrand_vals  rand_vals.cpp\n[renfro@gpunode004(job 159188) dmtcp]$ ./rand_vals\nx was 0, x is now 3499211612\nx was 3499211612, x is now 581869302\n^C\n[renfro@gpunode004(job 159188) dmtcp]$ ./rand_vals\nx was 0, x is now 3499211612\nx was 3499211612, x is now 581869302\n^C\n[renfro@gpunode004(job 159188) dmtcp]$\n</code></pre>\n<p>If the program is launched with dmtcp_launch, it can checkpoint its memory on a specified interval (here, 2 seconds). Nothing will look any different on first launch, since the program will start from scratch again:</p>\n<pre><code>[renfro@gpunode004(job 159188) dmtcp]$ dmtcp_launch --interval 2 ./rand_vals\nx was 0, x is now 3499211612\nx was 3499211612, x is now 581869302\n...\nx was 3922919429, x is now 949333985\nx was 949333985, x is now 2715962298\n^C\n[renfro@gpunode004(job 159188) dmtcp]$\n</code></pre>\n<p>One difference now is that dmtcp has written some memory state to the .dmtcp files in the folder:</p>\n<pre><code>[renfro@gpunode004(job 159188) dmtcp]$ ls\nckpt_rand_vals_757608755a1fd79a-40000-447e04b492543.dmtcp     rand_vals\ndmtcp_restart_script_757608755a1fd79a-40000-447e00e0b99a8.sh  rand_vals.cpp\ndmtcp_restart_script.sh\n</code></pre>\n<p>If the program is restarted via dmtcp_restart, it can load the last saved state, and not start from scratch:</p>\n<pre><code>[renfro@gpunode004(job 159188) dmtcp]$ dmtcp_restart --interval 2 ckpt_rand_vals_757608755a1fd79a-40000-447e04b492543.dmtcp\n[41415] mtcp_restart.c:589 restorememoryareas:\n  error restoring brk: 0\n[40000] NOTE at processinfo.cpp:372 in restoreHeap; REASON='Area between saved_break and curr_break not mapped, mapping it now'\n     _savedBrk = 6443008\n     curBrk = 6467584\nx was 949333985, x is now 2715962298\n...</code></pre>"
    ],
    "242": [
        "<p>How do I search for which environment modules are available?</p>",
        "<p>You can use either <strong>module avail matlab</strong> or <strong>module spider matlab</strong>, as discussed in the other posts. Also note, thanks to the node from <a class=\"mention\" href=\"/u/mk42\">@mk42</a> that <code>module spider</code> is not available with <a href=\"http://modules.sourceforge.net/\">Environment Modules</a>. From the <a href=\"https://lmod.readthedocs.io/en/latest/135_module_spider.html\">Lmod page,</a> you can quickly understand the difference:</p>\n<blockquote>\n<p>The module spider command is reports all the modules that can be loaded on a system. In a flat module layout system, the  <em>module avail</em>  and  <em>module spider</em>  return similar information. In a hierarchical system,  <em>module spider</em>  returns all the modules that are possible where as  <em>module avail</em>  only reports modules that can be loaded directly.</p>\n</blockquote>\n<p>So my preference tends to be for spider, because I want to know all possible. And spider is more fun a command to type <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=6\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> They return slightly different output, and I\u2019ll show the differences:</p>\n<pre><code>$ module spider matlab\n\n----------------------------------------------------------------------------\n  matlab:\n----------------------------------------------------------------------------\n    Description:\n      MATLAB (matrix laboratory) is a multi-paradigm numerical computing\n      environment and fourth-generation programming language.\n\n     Versions:\n        matlab/R2017a\n        matlab/R2017b\n        matlab/R2018a\n\n----------------------------------------------------------------------------\n  For detailed information about a specific \"matlab\" module (including how to load the modules) use the module's full name.\n  For example:\n\n     $ module spider matlab/R2018a\n----------------------------------------------------------------------------\n</code></pre>\n<p>module spider matlab shows you the specific versions of matlab available, and how to ask for more details for one. For example:</p>\n<pre><code>$ module spider matlab/R2018a\n\n----------------------------------------------------------------------------\n  matlab: matlab/R2018a\n----------------------------------------------------------------------------\n    Description:\n      MATLAB (matrix laboratory) is a multi-paradigm numerical computing\n      environment and fourth-generation programming language.\n\n    Properties:\n      Restricted access\n\n    You will need to load all module(s) on any one of the lines below before the \"matlab/R2018a\" module is available to load.\n\n      math\n</code></pre>\n<p>module avail on the other hand will do a good job to show you (almost the same) information but in a different format, and whether you have access or not (restricted).</p>\n<pre><code>$ module avail matlab\n\n--- math -- numerical libraries, statistics, deep-learning, computer science ---\n   matlab/R2017a (r)    matlab/R2017b (r)    matlab/R2018a (r,D)\n\n  Where:\n   D:  Default Module\n   r:  Restricted access\n\n  &gt;&gt; For more information about using software on Sherlock, please refer to \n  &gt;&gt; https://www.sherlock.stanford.edu/docs/software\n</code></pre>\n<p>I suspect you would see different output depending on the cluster, and you may have preference for one or the other in terms of formatting.</p>",
        "<p>Assuming you are talking about <a href=\"https://sourceforge.net/projects/modules/\" rel=\"nofollow noopener\">Environment Modules</a> (or the newer <a href=\"http://lmod.readthedocs.io/en/latest/\" rel=\"nofollow noopener\">Lmod</a>)</p>\n<p>Easiest way is to use the following command (note this will list all available modules)</p>\n<pre><code>module avail\n</code></pre>\n<p>To refine it further (note that Environment Modules is case sensitive by default):</p>\n<pre><code>module avail MATLAB</code></pre>",
        "<p><code>module spider</code> is not available with <a href=\"http://modules.sourceforge.net/\" rel=\"nofollow noopener\">Environment Modules</a>.</p>",
        "<p>With environment modules, <code>module avail &lt;modulename&gt;</code>  only matches from the front of the target module, for more general search pipe to grep ex. <code>module avail 2&gt;&amp;1 | grep &lt;searchterm&gt;</code></p>",
        "<p>As a supplement to <a class=\"mention\" href=\"/u/mhanby\">@mhanby</a>\u2019s answer: while <code>module avail</code> will show you all the modules that are currently available <em>to the module command</em>, some sites have their module trees set up so that modules only become visible/available once you\u2019ve loaded their pre-requisites.</p>\n<p>In these cases you may have to find the module tree directory where the modulefiles are stored, and search it manually.</p>"
    ],
    "943": [
        "<p>I\u2019m having problems running mpi4py, can anyone help with a basic example? Thank you!</p>",
        "<p>Indeed, mpi4py (and MPI itself) can be remarkably complicated!  Although you don\u2019t actually need a scheduler, you at least need a working MPI implementation (like OpenMPI), with an mpi4py that has been built against your MPI implementation[1].</p>\n<p>So, providing a simple example Python script is one thing, but you still need a working mpi4py.  So, I set up a GitHub repo that has an example Python script, as well as instructions (targeted for Ubuntu bionic) on how to get the example up and running.  For people with SLURM environments, I also include an example batch script!</p>\n<p>Have a look: <a href=\"https://github.com/akkornel/mpi4py\" rel=\"nofollow noopener\">https://github.com/akkornel/mpi4py</a></p>\n<p>[1]: \u201cMPI\u201d is not actually a product, it\u2019s a standard.  It defines an API (in C and Fortran), for MPI implementations to implement (OpenMPI is one example of an MPI implementation).  The code which does MPI stuff (in this case, mpi4py) needs to be built using the MPI implementation\u2019s header files, and run with the MPI implementation\u2019s libraries.  Note also that MPI came about before pkg-config was a thing, so MPI implementations provide wrapper scripts (<code>mpicc</code>, etc.) that call the actual tools (like <code>cc</code>) with the appropriate MPI options.</p>",
        "<p>It is hard to answer without knowing more details about what problems you are experiencing. It would be helpful to know what OS you are running, if you want to run mpi4py on an HPC system, if you are using a scheduler like SLURM, do you have a working installation of MPI like OpenMPI for example?</p>",
        "<p>Thanks <a class=\"mention\" href=\"/u/nrapstine\">@nrapstine</a> and welcome to AskCI! I was very non-specific / general on purpose, because I wanted to get different scenarios for using it.</p>",
        "<p>Understood <a class=\"mention\" href=\"/u/vsoch\">@vsoch</a>. I use mpi4py in two scenarios.</p>\n<ol>\n<li>On a supercomputer that already has OpenMPI or MPICH installed. So, I simply load the appropriate mpi module. Then, create/activate a conda environment where I want mpi4py installed and pip install it. Submit a job to a scheduler on a distributed partition that runs my python script. For example, in my slurm script, I would have:</li>\n</ol>\n<p>module load mpi python/anaconda3<br>\nsource activate myenv<br>\nsrun --mpi=pmi2 python hello_world.py</p>\n<ol start=\"2\">\n<li>On my local machine which runs Mac OS. I first installed OpenMPI then pip installed mpi4py in a conda environment and can run the same python script with</li>\n</ol>\n<p>source activate myenv<br>\nmpirun -np 4 python hello_world.py</p>"
    ],
    "73": [
        "<p>Spark is typically run atop HDFS in a Hadoop cluster (with name node, data nodes, \u2026). How do I run Spark on a typical HPC environment equipped with a job scheduler, parallel filesystem, and high-performance network fabric?</p>\n<p><strong>CURATOR:</strong> Kristina Plazonic KrisP</p>",
        "<p>There is a remote direct memory access (RDMA) for Apache Spark package developed by Network-Based Computing Laboratory at OSU to run Spark on HPC. Visit <a href=\"http://hibd.cse.ohio-state.edu/\">http://hibd.cse.ohio-state.edu/</a> for more details.</p>"
    ],
    "553": [
        "<p>The earliest versions of Tensorflow could be built to support the nodes with or without GPUs, but starting from version r1.2 we have to build 2 separate versions of the tensorflow. Is there something we are missing. Is it still possible to build Tensorflow in such a way that would work in both environments - with and without GPUs (without creating 2 separate sets of binary files)?</p>"
    ],
    "92": [
        "<p>I submit a job in a slurm cluster and all output and error messages go into the same file. Is there a way I can separate the error messages from the output?</p>",
        "<p><strong>ORIGINAL AUTHOR of this ANSWER</strong>: toreliza</p>\n<p>With SLURM, the default stdout and stderr are directed to the same file.  The file has a .out extension and the filename is dependent on the job ID and array index, if applicable.  The default can be changed in the preamble of the SLURM submit script (the \u2018top\u2019 part where \u2018<span class=\"hashtag\">#SBATCH</span>\u2019 is used).  Below is a code fragment showing a redirect of stderr (<code>-e</code>) separately from a redirect of stdout (<code>-o</code>).  The <code>%j</code> will be replaced by the <code>SLURM_JOB_ID</code>.</p>\n<pre><code class=\"lang-auto\">#SBATCH -e slurm-%j.err\n#SBATCH -o slurm-%j.out\n</code></pre>"
    ],
    "30": [
        "<p>What\u2019s a good way to find out ahead of time that my program might overrun the scheduler time limit, so I can plan to save state periodically?</p>\n<p><strong>CURATOR:</strong> Katia Oleinik</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>If the program contains a large loop, then running this loop just for a few iterations might provide you with a rough idea of how much time is spent for each iteration.  Or, if the input dataset/system can be reduced to a smaller subset, then the wallclock time for this small subset can provide some clue about how much time might be needed for the whole dataset.  When adding checkpoints to your program (to save the state) make sure you space them in a reasonable way, i.e. do not create a checkpoint too often - it will slow done the overall performance of your program.</p>"
    ],
    "238": [
        "<p>My mpi job requires more memory than is allocated in my current node configuration. What tricks can I use to reduce memory footprint without restructuring the code?</p>\n<p><strong>CURATOR:</strong> toreliza</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>A good approach to running a job with minimal <code>#SBATCH</code> variables in the submit script preamble is to include the options for number of tasks and cpus per task; below is an example:</p>\n<pre><code class=\"lang-bash\">#SBATCH --ntasks=8\n#SBATCH --cpus-per-task=2\n</code></pre>\n<p>This is because the ntasks option tells the slurm controller the maximum number of tasks to be run, and lets the controller allocate the appropriate resources. Adding the <code>--cpus-per-task</code> option lifts the default of one cpu per task, allowing more than one task per node to launch.</p>\n<p>To illustrate the above, let\u2019s use a specific scenario. Suppose the job is being submitted on 4 nodes, each node has 16 core and total RAM of 4 GB. Attempting to submit the job to the cluster results in an error that indicates that not enough memory is allocated for the job to execute successfully.</p>\n<p>The above setup (I will use SLURM notation) implies that the preamble of the submit script includes:</p>\n<pre><code class=\"lang-bash\">#SBATCH --nodes=4\n</code></pre>\n<p>Already the total amount of memory available for allocation is restricted (to the total available to four nodes). If the job needs more than 16 GB of RAM, it will not run.</p>\n<p>Let\u2019s include some options that might also be part of the script:</p>\n<pre><code class=\"lang-bash\">#SBATCH --ntasks=16\n</code></pre>\n<p>With four nodes and a default of one task per node, clearly resources are not sufficient.</p>\n<p>Let\u2019s add <code>#SBATCH --cpus-per-task=4</code></p>\n<p>Now four tasks per node are allowed, and with four nodes, 16 total tasks are at least possible. As long as each task does not require more than 1 GB of memory, the job can run. ((4 GB / node) / (4 tasks / node) = 1GB / task.)</p>\n<p>Let\u2019s say, however, that each task requires 2GB to run. We can either request more nodes (8), or fewer cpus per task (2) (and therefore fewer tasks overall-8). This resolution relies on the restraints of the current configuration being lifted (i.e., more than four nodes are available).</p>\n<p>Alternatively, if we had not specified the restriction of (four nodes), and just requested the number of tasks and the number of cpus per task, the scheduler would be free to allocate the most appropriate configuration and number of resources to satisfy the job\u2019s memory requirements.</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>Depending on the range of compute resources available, there are two main approaches to resolve the memory issue.  If the job is constrained by the current resource configuration (there are no more nodes available, for example), varying options that affect the amount of memory consumed by these resources can result in a workable rebalance of memory usage.   If there are resources such that the current configuration can be expanded, a good strategy is to specify only <code>ntasks</code> and <code>cpus-per-task</code> in the submit script preamble.  This allows the scheduler the flexibility to efficiently allocate cluster resources to satisfy memory requirements, while optimizing time spent in the queue and  time spent running the calculation.</p>"
    ],
    "504": [
        "<p>One of the researchers is trying to run multiple LAMMPS jobs on a node on our cluster where a job uses 1 core.</p>\n<p>mpirun -np 1 lmp_mpi &lt; Project.txt7 &gt; output_7_1.txt</p>\n<p>However, as the user submits multiple jobs that are similar:</p>\n<p>\u2026</p>\n<p>mpirun -np 1 lmp_mpi &lt; Project.txt7 &gt; output_7_1.txt</p>\n<p>mpirun -np 1 lmp_mpi &lt; Project.txt7 &gt; output_8_1.txt</p>\n<p>\u2026</p>\n<p>and number of LAMMPS jobs running on a node increases, instances are using less than 100% CPU usage/job which is ultimately causing all the simulations to slow down.</p>\n<p>Here\u2019s the CPU usage of each of the simulations on one of the compute nodes using top command:</p>\n<p>PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND<br>\n22037 username      20   0  598632 101664   1196 R  <strong>33.2</strong>  0.1   8082:11 lmp_mpi</p>\n<p>22332 username       20   0  597292 100796   1196 R  <strong>33.2</strong>  0.1   8076:26 lmp_mpi</p>\n<p>22345 username       20   0  596560 101572   1196 R  <strong>33.2</strong>  0.1   8084:15 lmp_mpi</p>\n<p>I am have tried multiple options with MPI and Slurm like --exclusive option and trying to set --cpus-per-task --ntasks-per-node parameters but still see the same results.</p>\n<p>Is this error caused because of how much I/O processing LAMMPS takes? If so, can we reduce the verbosity of LAMMPS ?</p>\n<p>How can we get past this error?</p>\n<p><strong>System information:</strong></p>\n<p>CentOS 7</p>\n<p>Slurm Scheduler</p>\n<p>LAMMPS version - lammps-16Feb16</p>\n<p>MPI Version - openmpi-1.8/gcc</p>\n<p>Each of our compute nodes has either 20-cores / 24-cores and each core can run 1 process.</p>\n<p>Here\u2019s the complete job script of one of the simulations:</p>\n<p>#######################</p>\n<p>#!/usr/bin/env bash</p>\n<p><span class=\"hashtag\">#SBATCH</span> --job-name=Sim-8</p>\n<p><span class=\"hashtag\">#SBATCH</span> --partition=debug.q</p>\n<p><span class=\"hashtag\">#SBATCH</span> --mem=1G</p>\n<p><span class=\"hashtag\">#SBATCH</span> --export=ALL</p>\n<p><span class=\"hashtag\">#SBATCH</span> --nodelist=mrcd08</p>\n<p>module load lammps16</p>\n<p>mpirun -np 1 lmp_mpi &lt; Project.txt7 &gt; output_7_1.txt</p>\n<p>#########################</p>\n<p><strong>Sarvani Chadalapaka</strong></p>\n<p>HPC Administrator</p>\n<p>University of California Merced, Office of Information Technology</p>",
        "<p>It seems like the jobs are not binding to the correct core assigned by SLURM, but overloading cores.</p>\n<p>In order for the job submission to run, the script had to be changed from</p>\n<p>mpirun -np 1 lmp_mpi &lt; Project.txt7 &gt; output_7_1.txt</p>\n<p>to</p>\n<p>srun --hint=nomultithread lmp_mpi &lt; Project.txt7 &gt; output_18_1.txt</p>\n<p>From <a href=\"https://slurm.schedmd.com/cpu_management.html#Example10\">Slurm documentation</a>, --hint=nomultithread srun option causes Slurm to allocate only one thread from each core to this job.</p>\n<p><strong>Sarvani Chadalapaka</strong></p>\n<p>HPC Administrator</p>\n<p>University of California Merced, Office of Information Technology</p>"
    ],
    "225": [
        "<p>I am running my tensorflow script on the cluster and it gets aborted with the message that I am using 6 cores when my job requested only 1. But I do not have any parallelization in my code. I use standard tensorflow functions and everything runs fine on my local machine. How do I fix this issue on the cluster?</p>\n<p><strong>Curator</strong>: Katia</p>",
        "<p>TensorFlow does indeed use multiple CPU cores by default and all cores are wrapped in cpu:0. Following has an example to run TensorFlow on a single core.<br>\n<aside class=\"onebox stackexchange\">\n  <header class=\"source\">\n      <a href=\"https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core\" target=\"_blank\" rel=\"nofollow noopener\">stackoverflow.com</a>\n  </header>\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/6278213/jan-sch%c3%bctte-engel\" target=\"_blank\" rel=\"nofollow noopener\">\n    <img alt=\"jan sch&amp;#252;tte-engel\" src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/f5a937d697552b45f206b247512f849f79981e20.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n  </a>\n<h4>\n  <a href=\"https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core\" target=\"_blank\" rel=\"nofollow noopener\">How can I run Tensorflow on one single core?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>tensorflow, core</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/6278213/jan-sch%c3%bctte-engel\" target=\"_blank\" rel=\"nofollow noopener\">\n    jan sch&amp;#252;tte-engel\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/38187808/how-can-i-run-tensorflow-on-one-single-core\" target=\"_blank\" rel=\"nofollow noopener\">03:08PM - 04 Jul 16 UTC</a>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>",
        "<p>From my experience, you still need to request 2 CPU cores when you set intra_op_parallelism_threads=1 and inter_op_parallelism_threads=1. It looks like with this setup there is still a master python script that uses 1 core and then the tf.Session() will use another one.</p>"
    ],
    "414": [
        "<p>What is a Science DMZ?</p>",
        "<p>A Science DMZ (short for DeMilitarized Zone) is a scalable network design model for optimizing science data transfers. The Science DMZ is a portion of the network, built at or near the campus or laboratory\u2019s local network perimeter, that is designed such that the equipment, configuration, and security policies are optimized for high-performance scientific applications rather than for general-purpose business systems or \u201centerprise\u201d computing.</p>\n<p>Developed by ESnet engineers, the Science DMZ model addresses common network performance problems encountered at research institutions by creating an environment that is tailored to the needs of high performance science applications, including high-volume bulk data transfer, remote experiment control, and data visualization.</p>\n<p>The Science DMZ is scalable, incrementally deployable, and easily adaptable to incorporate high performance and advanced technologies such as 100 Gigabit Ethernet services, virtual circuits, and software-defined networking capabilities.</p>\n<p>A Science DMZ integrates four key concepts into a unified whole that together serve as a foundation for this model. These include:</p>\n<ul>\n<li>A network architecture explicitly designed for high-performance applications, where the science network is distinct from the general-purpose network;</li>\n<li>The use of dedicated systems for data transfer;</li>\n<li>Performance measurement and network testing systems that are regularly used to characterize the network and are available for troubleshooting; and</li>\n<li>Security policies and enforcement mechanisms that are tailored for high performance science environments.</li>\n</ul>\n<p>A good resource for all things Science DMZ-related is the <a href=\"http://ES.NET\">ES.NET</a> website at <a href=\"https://fasterdata.es.net/science-dmz/\">https://fasterdata.es.net/science-dmz/</a>.</p>"
    ],
    "214": [
        "<p>How can one determine the amount of RAM a node has in an HPC environment?</p>",
        "<p>The best way is to consult your site\u2019s documentation.</p>\n<p>On SLURM, one can do this in two steps:</p>\n<ol>\n<li>\n<p>invoke <code>sinfo</code> to see the list of nodes and their states</p>\n</li>\n<li>\n<p>invoke <code>srun</code> to run the <code>free</code> command on the desired compute node. For example, for node named <code>r001</code>, invoke: <code>srun -w r001 free</code>.</p>\n</li>\n</ol>\n<p>Here is a real example from PSC Bridges supercomputer:</p>\n<pre><code>$ sinfo\nPARTITION  AVAIL  TIMELIMIT  NODES  STATE NODELIST\nRM*           up 2-00:00:00      1 drain* r242\nRM*           up 2-00:00:00      1   comp r400\nRM*           up 2-00:00:00      1  drain r668\nRM*           up 2-00:00:00      9   resv r[405-412,670]\nRM*           up 2-00:00:00    702  alloc r[006-241,243-399,401-404,413-667,669,671-719]\nRM-shared     up 2-00:00:00     21    mix r[720-721,733-747,749-752]\nRM-shared     up 2-00:00:00      3  alloc r[723-724,748]\nRM-shared     up 2-00:00:00      9   idle r[722,725-732]\n...\n</code></pre>\n<p>The nodes under \u201calloc\u201d, \u201cdrain\u201d, \u201cresv\u201d states cannot be reached, so let\u2019s try to see the free memory of r720 (it is on the non-default partition <code>RM-shared</code> so we have to specify that):</p>\n<pre><code>srun -p RM-shared -w r720 free\n              total        used        free      shared  buff/cache   available\nMem:      131734464    13434632   107366248      560604    10933584   116069696\nSwap:      17591292     2375984    15215308\n</code></pre>\n<p>Looks like we have 128GB of total RAM. That matches what is said on its manual page, here (r720 is one of the regular memory nodes): <a href=\"https://www.psc.edu/bridges/user-guide/system-configuration\">https://www.psc.edu/bridges/user-guide/system-configuration</a> .</p>",
        "<p>In GridEngine Family systems you can pull up what the Queue Scheduler is using with <code>qhost</code>.</p>",
        "<p>If you are inspecting directly and need more details than <code>free</code> gives, most systems will let you run other tools like <code>lshw</code> on the job node as well.</p>",
        "<p>The method is dependent on the resource manager or scheduler in use at your site. With Slurm you can quickly see this in the output of</p>\n<blockquote>\n<p>scontrol show node $NODENAME</p>\n</blockquote>\n<p>Replace $NODENAME with the actual name of the node you\u2019re interested in. You may leave the node name off and get a listing that includes all nodes.</p>"
    ],
    "104": [
        "<p>When I start MATLAB on a remote server the interaction is very poor. The menu opens very slow and there is delay during typing. How can I improve it?</p>",
        "<p>If you can generate the calculations and/or output that you need without the GUI, there are some options that will prevent that overhead from initiating:</p>\n<pre><code class=\"lang-auto\">$ matlab -nodesktop -nosplash -nodisplay &lt;command&gt;\n</code></pre>\n<pre><code class=\"lang-bash\">-nodesktop\n</code></pre>\n<p>will stop the GUI from loading;</p>\n<pre><code class=\"lang-bash\">-nosplash\n</code></pre>\n<p>will keep the Matlab logo from loading;</p>\n<pre><code class=\"lang-bash\">-nodisplay\n</code></pre>\n<p>will prevent use of X11 (X11 may be required in which case, don\u2019t use this option).</p>",
        "<p>**ANSWER:**Depending on the cluster there are normally some ways to improve performance of GUI-based programs on a remote server.<br>\nThis includes VNC, NX, X2go and a few others.<br>\nAsk system administrator which one is available on your cluster.</p>\n<p>There are a number of webpages explaining <em>remote desktop</em> environment:<br>\nfor example:  <a href=\"http://training.nectar.org.au/package07/sections/remoteDesktop.html\">http://training.nectar.org.au/package07/sections/remoteDesktop.html</a></p>"
    ],
    "263": [
        "<p>I have a piece of software that will, every few minutes or so, need to write data to disk.  This is a slow process, and I would like to offload it to a secondary thread, rather than pausing my entire program while data is written.</p>\n<p>Would it be better to structure this as a single worker thread that does its work, then pauses and waits for the next piece of work, or as multiple threads, where each time work needs to be done a new thread is spawned?</p>",
        "<p>If I understand correctly, you are looking at using treading to reclaim  processor time that would otherwise be lost to waiting on I/o (writing to disk); you are asking how maintaining a constant pool of threads compares to ad hoc (creating and destroying threads per use)?</p>\n<p>This probably comes down to balancing \u2018good code\u2019 verses the overhead cost of creating threads.  \u2013 Common wisdom on threads suggest keeping a thread-pool specificity to avoid the overhead of creating new treads \u2013  However in situations like this the spawning overhead (typically a few microseconds) is likely negligible compare to the hardware/disk write situation you are trying to address.</p>\n<p>Another consideration is the system and hardware you are writing to/with. Having multiple concurrent writes may negatively effect your write speed (or cause other problematic behaviour).</p>"
    ],
    "431": [
        "<p>I am currently trying to set up SmrtAnalysis V2.2.0 for a client.  This software appears to be very intertwined.  It is clear that it was designed to be run as a server that forwards the jobs out to the scheduler.  Especially since they completely re-did the software and jumped from V2.3 to V5.0 where they re-branded the name to smrtlink.  I have tried running both V2.2 and V2.3 and they both have the same result.  Here is the guide to installing the software.  I have followed these a few times and I get the same results everytime.</p>\n<p><a href=\"https://smrt-analysis.readthedocs.io/en/latest/SMRT-Analysis-Software-Installation-v2.2.0/\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://smrt-analysis.readthedocs.io/en/latest/SMRT-Analysis-Software-Installation-v2.2.0/</a></p>\n<p>I am not sure if this is allowed, but being that it is meant to be run as a server the output uses an extension not allowed (.html).  Here is a public dropbox link to the data.</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/b55b0e80a4a533be00e26d30756cb9b860ad76b1.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://www.dropbox.com/sh/j251vvgv4fhu48a/AADOKd5BuHQZe23XYNe5SdC3a?dl=0\" target=\"_blank\" rel=\"nofollow noopener\">Dropbox</a>\n  </header>\n  <article class=\"onebox-body\">\n    <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/9a849e977ef6747f481af60c94714d2181f70b94.png\" class=\"thumbnail onebox-avatar\" width=\"200\" height=\"200\">\n\n<h3><a href=\"https://www.dropbox.com/sh/j251vvgv4fhu48a/AADOKd5BuHQZe23XYNe5SdC3a?dl=0\" target=\"_blank\" rel=\"nofollow noopener\">smrtanalysis</a></h3>\n\n<p>Shared with Dropbox</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>The main thing that stands out to me is in the smrtanalysis/outputs/log/master.log.  There is a line:</p>\n<p>[DEBUG] 2018-08-01 16:15:09,960 [SMRTpipe.pbpy.io.MetaAnalysisXml load 114] No header found in /home/brandon/projects/dilay/tests/outputs/input.xml. Unable to load jobId</p>\n<p>This is particularly confusing since this xml is generated using a command built into the software and it does parse the xml for the three files successfully.</p>\n<p>[DEBUG] 2018-08-01 16:15:09,960 [SMRTpipe.pbpy.io.MetaAnalysisXml _parseRef 587] Successfully parsed run:0000000-0000 to run 0000000-0000<br>\n[DEBUG] 2018-08-01 16:15:09,960 [SMRTpipe.pbpy.io.MetaAnalysisXml _parseRef 587] Successfully parsed run:0000000-0001 to run 0000000-0001<br>\n[DEBUG] 2018-08-01 16:15:09,960 [SMRTpipe.pbpy.io.MetaAnalysisXml _parseRef 587] Successfully parsed run:0000000-0002 to run 0000000-0002</p>\n<p>This appears to be the outcome of some other issue causing it, but even the log doesn\u2019t have any history of another issue.  There aren\u2019t any errors and the program thinks it runs successfully, however it doesn\u2019t appear to do any arithmetic due to the jobid missing.</p>",
        "<p>If you\u2019re intent on using the 2 series of the pacbio smrt SW, good luck.  It\u2019s awful.  Here\u2019s the module file + embedded installation notes for the 2.3 version</p>\n<p><a href=\"http://moo.nac.uci.edu/~hjm/smrtanalysis-2.3.0p5-install.notes\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">http://moo.nac.uci.edu/~hjm/smrtanalysis-2.3.0p5-install.notes</a></p>\n<p>For the 5 series of smrtanalysis, it\u2019s hugely easier, if not transparently so.  Here\u2019s my notes on the installation:</p>\n<pre><code>## The installation is quite a bit smoother now.  The installation \n## package that PacBio supplies is esentially complete, albeit bloated with\n## all kinds of code duplications that we already have. However, it's not worth\n## the space saving to take it apart and symlink our own bits in.\n## Some notes: \n## 1 - Install AS the smrtanalysis user, after having checked that the dir \n##      permissions still allow you to do so.\n## 2 - Download the latest versio from &lt;http://www.pacb.com/devnet/&gt;\n## 3 - make sure the dirs \"data_root\" and \"jobs_root\" already exist.\n## 4 - export SMRT_ROOT='/data/apps/smrtanalysis/XXXXX.XXXX' (wherever you installed it)\n## 4 - run the installer.\n</code></pre>\n<p>We use the environment modules system so if you want our entire module file, be happy to supply it, tho we don\u2019t generally make them public since some of them reference internal information.</p>",
        "<p>Not sure if this us useful, but</p>\n<ul>\n<li>\n<p>There is some discussion of the error message</p>\n<p><code>No header found in input.xml. Unable to load jobId</code></p>\n<p>here</p>\n<p><a href=\"http://seqanswers.com/forums/showpost.php?p=96806&amp;postcount=8\">http://seqanswers.com/forums/showpost.php?p=96806&amp;postcount=8</a></p>\n</li>\n<li>\n<p>The thread then continues with an example PacBio command line .xml sample at</p>\n<p><a href=\"http://seqanswers.com/forums/showpost.php?p=96819&amp;postcount=9\">http://seqanswers.com/forums/showpost.php?p=96819&amp;postcount=9</a></p>\n</li>\n</ul>\n<p>Maybe there are some PacBIO command line experts on <a href=\"http://ask.cyberinfrastructure.org\">ask.cyberinfrastructure.org</a> who can provide more suggestions?</p>",
        "<p>I definitely recommend switching to smrt-link.  If you really need to run smrt-analysis for some temporary data conversion or something, here\u2019s a link to an ansible playbook I used to set it up at the time we were running it, that may give some clues about a difference during the install procedure:</p>\n<aside class=\"onebox githubgist\">\n  <header class=\"source\">\n      <a href=\"https://gist.github.com/baberlevi/995ce3b934b707fa776273049b77429c\" target=\"_blank\" rel=\"nofollow noopener\">gist.github.com</a>\n  </header>\n  <article class=\"onebox-body\">\n    <h4><a href=\"https://gist.github.com/baberlevi/995ce3b934b707fa776273049b77429c\" target=\"_blank\" rel=\"nofollow noopener\">https://gist.github.com/baberlevi/995ce3b934b707fa776273049b77429c</a></h4>\n<h5>smrt-analysis.yml</h5>\n<pre><code class=\"YAML\">- name: Configure smrt-analysis.las.iastate.edu\n  hosts: smrt-analysis.las.iastate.edu\n  user: root\n  connection: smart\n\n  vars_files:\n    - ../vars/ISU/globals.yml\n    - ../vars/directories.yml\n\n  environment:</code></pre>\nThis file has been truncated. <a href=\"https://gist.github.com/baberlevi/995ce3b934b707fa776273049b77429c\" target=\"_blank\" rel=\"nofollow noopener\">show original</a>\n\n<p>\n</p>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "<p>At IU we have SMRT link v.5.0 installed, we haven\u2019t worked with PacBio data as much as we\u2019d like so we haven\u2019t run into the error you mentioned.</p>\n<p>If you are looking for an alternative, once the Pacbio sequences format is converted to fastq using SMRT link, you can use Canu (<a href=\"https://canu.readthedocs.io/en/latest/quick-start.html\" rel=\"nofollow noopener\">https://canu.readthedocs.io/en/latest/quick-start.html</a>) for trimming, correcting and assembing the reads.</p>",
        "<p>UPDATE</p>\n<p>Sorry, it has been a while.  I have made progress.  It appears that the grunt of the issue before was the RS_Modification_Detection.1.xml.  I recieved a new one from PacBio but running into a new issue altogether.  It runs for roughly 15 minutes and then errors out.  Here is a drop box with the inputs and outputs much like before, and the terminal output below if anyone has seen this error or knows another thing to try.</p>\n<p><a href=\"https://www.dropbox.com/s/vayfzmj8h0zyk6e/smrtanalysisattempt.zip?dl=0\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://www.dropbox.com/s/vayfzmj8h0zyk6e/smrtanalysisattempt.zip?dl=0</a></p>\n<p>Question for those running smrtlink 5.0 in an HPC environment :  How would you suggest your users go about using it given environment modules.  Would they open an interactive session, run smrtlink in a singularity container, and than forward the port, or open a browser using x11 forwarding?</p>\n<pre><code class=\"lang-nohighlight\">brandon@node0:dilay/inputs $ ./test.sh \n\n[INFO] 2018-09-17 09:38:59,059 Successfully found 3 files in xml:/home/brandon/projects/dilay/tests/outputs/input.xml\n\n[INFO] 2018-09-17 09:38:59,441 smrtpipe.py running on node0\n\n[INFO] 2018-09-17 09:38:59,441 SMRT Analysis 2.3.0 / SMRTpipe 1.87.139483\n\n[INFO] 2018-09-17 09:39:00,086 Process id 7466\n\n[INFO] 2018-09-17 09:39:05,601 Starting task://Anonymous/P_Fetch/toFofn\n\n[INFO] 2018-09-17 09:39:05,602 task P_Fetch.toFofn successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:39:05,602 Workflow Completion Status 1/44 in (            2%) tasks completed.\n\n[INFO] 2018-09-17 09:39:10,608 Starting task://Anonymous/P_GenomicConsensus/writeContigList\n\n[INFO] 2018-09-17 09:39:10,608 Starting task://Anonymous/P_ModificationDetection/writeContigList\n\n[INFO] 2018-09-17 09:39:10,608 Starting task://Anonymous/P_Fetch/adapterRpt\n\n[INFO] 2018-09-17 09:39:10,608 Starting task://Anonymous/P_Filter/subreads.plsFofn.Scatter\n\n[INFO] 2018-09-17 09:39:10,608 Starting task://Anonymous/P_Fetch/overviewRpt\n\n[INFO] 2018-09-17 09:39:10,609 task P_GenomicConsensus.writeContigList successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 4 slots.\n\n[INFO] 2018-09-17 09:39:10,609 Workflow Completion Status 2/44 in (            4%) tasks completed.\n\n[INFO] 2018-09-17 09:39:10,609 task P_ModificationDetection.writeContigList successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 3 slots.\n\n[INFO] 2018-09-17 09:39:10,609 Workflow Completion Status 3/44 in (            6%) tasks completed.\n\n[INFO] 2018-09-17 09:39:10,610 task P_Filter.subreads.plsFofn.Scatter successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 2 slots.\n\n[INFO] 2018-09-17 09:39:10,610 Workflow Completion Status 4/44 in (            9%) tasks completed.\n\n[INFO] 2018-09-17 09:39:11,263 task P_Fetch.overviewRpt successfully completed (1.00 sec (0.02 min)). freed 1 slots, using 1 slots.\n\n[INFO] 2018-09-17 09:39:11,263 Workflow Completion Status 5/44 in (         . 11%) tasks completed.\n\n[INFO] 2018-09-17 09:39:16,267 Starting task://Anonymous/P_Filter/filter_001of003\n\n[INFO] 2018-09-17 09:39:16,267 Starting task://Anonymous/P_Filter/filter_002of003\n\n[INFO] 2018-09-17 09:39:16,267 Starting task://Anonymous/P_Filter/filter_003of003\n\n[INFO] 2018-09-17 09:39:22,001 task P_Fetch.adapterRpt successfully completed (15.00 sec (0.25 min)). freed 1 slots, using 6 slots.\n\n[INFO] 2018-09-17 09:39:22,001 Workflow Completion Status 6/44 in (         . 13%) tasks completed.\n\n[INFO] 2018-09-17 09:39:32,009 task P_Filter.filter_001of003 successfully completed (20.00 sec (0.33 min)). freed 2 slots, using 4 slots.\n\n[INFO] 2018-09-17 09:39:32,010 Workflow Completion Status 7/44 in (         . 15%) tasks completed.\n\n[INFO] 2018-09-17 09:39:37,015 Starting task://Anonymous/P_Filter/subreads_001of003\n\n[INFO] 2018-09-17 09:39:37,016 task P_Filter.filter_003of003 successfully completed (21.00 sec (0.35 min)). freed 2 slots, using 3 slots.\n\n[INFO] 2018-09-17 09:39:37,016 Workflow Completion Status 8/44 in (         . 18%) tasks completed.\n\n[INFO] 2018-09-17 09:39:37,017 task P_Filter.filter_002of003 successfully completed (21.00 sec (0.35 min)). freed 2 slots, using 1 slots.\n\n[INFO] 2018-09-17 09:39:37,017 Workflow Completion Status 9/44 in (        .. 20%) tasks completed.\n\n[INFO] 2018-09-17 09:39:42,025 Starting task://Anonymous/P_Filter/subreads_002of003\n\n[INFO] 2018-09-17 09:39:42,026 Starting task://Anonymous/P_Filter/filter.summary.Gather\n\n[INFO] 2018-09-17 09:39:42,026 Starting task://Anonymous/P_Filter/filter.rgnFofn.Gather\n\n[INFO] 2018-09-17 09:39:42,026 Starting task://Anonymous/P_Filter/subreads_003of003\n\n[INFO] 2018-09-17 09:39:42,842 task P_Filter.filter.summary.Gather successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 4 slots.\n\n[INFO] 2018-09-17 09:39:42,842 Workflow Completion Status 10/44 in (        .. 22%) tasks completed.\n\n[INFO] 2018-09-17 09:39:42,843 task P_Filter.filter.rgnFofn.Gather successfully completed (0.00 sec (0.00 min)). freed 1 slots, using 3 slots.\n\n[INFO] 2018-09-17 09:39:42,843 Workflow Completion Status 11/44 in (        .. 25%) tasks completed.\n\n[INFO] 2018-09-17 09:39:47,852 Starting task://Anonymous/P_FilterReports/statsRpt\n\n[INFO] 2018-09-17 09:39:47,852 Starting task://Anonymous/P_FilterReports/loadingRpt\n\n[INFO] 2018-09-17 09:39:47,852 Starting task://Anonymous/P_Control/align\n\n[INFO] 2018-09-17 09:39:47,853 Starting task://Anonymous/P_Filter/subreadSummary\n\n[INFO] 2018-09-17 09:39:54,334 task P_FilterReports.loadingRpt successfully completed (5.00 sec (0.08 min)). freed 1 slots, using 13 slots.\n\n[INFO] 2018-09-17 09:39:54,334 Workflow Completion Status 12/44 in (        .. 27%) tasks completed.\n\n[INFO] 2018-09-17 09:40:01,351 task P_FilterReports.statsRpt successfully completed (15.00 sec (0.25 min)). freed 1 slots, using 12 slots.\n\n[INFO] 2018-09-17 09:40:01,351 Workflow Completion Status 13/44 in (        .. 29%) tasks completed.\n\n[INFO] 2018-09-17 09:40:43,308 task P_Filter.subreadSummary successfully completed (55.00 sec (0.92 min)). freed 1 slots, using 11 slots.\n\n[INFO] 2018-09-17 09:40:43,309 Workflow Completion Status 14/44 in (       ... 31%) tasks completed.\n\n[INFO] 2018-09-17 09:40:48,316 Starting task://Anonymous/P_FilterReports/subreadRpt\n\n[INFO] 2018-09-17 09:40:55,025 task P_FilterReports.subreadRpt successfully completed (7.00 sec (0.12 min)). freed 1 slots, using 11 slots.\n\n[INFO] 2018-09-17 09:40:55,025 Workflow Completion Status 15/44 in (       ... 34%) tasks completed.\n\n[INFO] 2018-09-17 09:41:10,504 task P_Filter.subreads_003of003 successfully completed (90.00 sec (1.50 min)). freed 1 slots, using 10 slots.\n\n[INFO] 2018-09-17 09:41:10,504 Workflow Completion Status 16/44 in (       ... 36%) tasks completed.\n\n[INFO] 2018-09-17 09:41:20,514 task P_Filter.subreads_001of003 successfully completed (104.00 sec (1.73 min)). freed 1 slots, using 9 slots.\n\n[INFO] 2018-09-17 09:41:20,514 Workflow Completion Status 17/44 in (       ... 38%) tasks completed.\n\n[INFO] 2018-09-17 09:41:25,520 task P_Filter.subreads_002of003 successfully completed (106.00 sec (1.77 min)). freed 1 slots, using 8 slots.\n\n[INFO] 2018-09-17 09:41:25,520 Workflow Completion Status 18/44 in (      .... 40%) tasks completed.\n\n[INFO] 2018-09-17 09:41:30,532 Starting task://Anonymous/P_Filter/subreads.subreads.Gather\n\n[INFO] 2018-09-17 09:41:30,533 Starting task://Anonymous/P_Filter/subreads.subreadFastq.Gather\n\n[INFO] 2018-09-17 09:41:31,631 task P_Filter.subreads.subreads.Gather successfully completed (3.00 sec (0.05 min)). freed 1 slots, using 9 slots.\n\n[INFO] 2018-09-17 09:41:31,632 Workflow Completion Status 19/44 in (      .... 43%) tasks completed.\n\n[INFO] 2018-09-17 09:41:37,645 task P_Filter.subreads.subreadFastq.Gather successfully completed (7.00 sec (0.12 min)). freed 1 slots, using 8 slots.\n\n[INFO] 2018-09-17 09:41:37,646 Workflow Completion Status 20/44 in (      .... 45%) tasks completed.\n\n[INFO] 2018-09-17 09:46:35,807 task P_Control.align successfully completed (409.00 sec (6.82 min)). freed 8 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:46:35,807 Workflow Completion Status 21/44 in (      .... 47%) tasks completed.\n\n[INFO] 2018-09-17 09:46:40,810 Starting task://Anonymous/P_Control/summaryCSV\n\n[INFO] 2018-09-17 09:46:40,811 Starting task://Anonymous/P_ControlReports/statsJsonReport\n\n[INFO] 2018-09-17 09:46:40,811 Starting task://Anonymous/P_Control/updateRgn\n\n[INFO] 2018-09-17 09:46:41,645 task P_Control.summaryCSV successfully completed (1.00 sec (0.02 min)). freed 1 slots, using 2 slots.\n\n[INFO] 2018-09-17 09:46:41,645 Workflow Completion Status 22/44 in (     ..... 50%) tasks completed.\n\n[INFO] 2018-09-17 09:46:42,274 task P_ControlReports.statsJsonReport successfully completed (2.00 sec (0.03 min)). freed 1 slots, using 1 slots.\n\n[INFO] 2018-09-17 09:46:42,274 Workflow Completion Status 23/44 in (     ..... 52%) tasks completed.\n\n[INFO] 2018-09-17 09:46:42,275 task P_Control.updateRgn successfully completed (4.00 sec (0.07 min)). freed 1 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:46:42,275 Workflow Completion Status 24/44 in (     ..... 54%) tasks completed.\n\n[INFO] 2018-09-17 09:46:47,282 Starting task://Anonymous/P_Mapping/align\n\n[INFO] 2018-09-17 09:46:47,282 Starting task://Anonymous/P_Control/noControlSubreads\n\n[INFO] 2018-09-17 09:47:58,759 task P_Control.noControlSubreads successfully completed (73.00 sec (1.22 min)). freed 1 slots, using 8 slots.\n\n[INFO] 2018-09-17 09:47:58,760 Workflow Completion Status 25/44 in (     ..... 56%) tasks completed.\n\n[INFO] 2018-09-17 09:52:21,299 task P_Mapping.align successfully completed (333.00 sec (5.55 min)). freed 8 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:52:21,299 Workflow Completion Status 26/44 in (     ..... 59%) tasks completed.\n\n[INFO] 2018-09-17 09:52:26,303 Starting task://Anonymous/P_Mapping/sort\n\n[INFO] 2018-09-17 09:52:27,043 task P_Mapping.sort successfully completed (0.00 sec (0.00 min)). freed 8 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:52:27,044 Workflow Completion Status 27/44 in (    ...... 61%) tasks completed.\n\n[INFO] 2018-09-17 09:52:32,049 Starting task://Anonymous/P_Mapping/repack\n\n[INFO] 2018-09-17 09:52:32,708 task P_Mapping.repack successfully completed (0.00 sec (0.00 min)). freed 8 slots, using 0 slots.\n\n[INFO] 2018-09-17 09:52:32,709 Workflow Completion Status 28/44 in (    ...... 63%) tasks completed.\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_MappingReports/statsJsonReport\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_ModificationDetection/computeModifications\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_Mapping/samBam\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_Mapping/covGFF\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_GenomicConsensus/callVariantsWithConsensus\n\n[INFO] 2018-09-17 09:52:37,717 Starting task://Anonymous/P_Mapping/unmapped\n\n[ERROR] 2018-09-17 09:52:37,718 *** Failed task task://Anonymous/P_Mapping/samBam\n\n[ERROR] 2018-09-17 09:52:37,718 *** Failed task task://Anonymous/P_Mapping/covGFF\n\n[ERROR] 2018-09-17 09:52:37,718 *** Failed task task://Anonymous/P_GenomicConsensus/callVariantsWithConsensus\n\n[ERROR] 2018-09-17 09:52:37,718 *** Failed task task://Anonymous/P_ModificationDetection/computeModifications\n\n[ERROR] 2018-09-17 09:52:37,718 *** Failed task task://Anonymous/P_MappingReports/statsJsonReport\n\n[INFO] 2018-09-17 09:52:44,080 Found 5 failed tasks.\n\n[INFO] 2018-09-17 09:52:44,080 task samBam FAILED \n\n[INFO] 2018-09-17 09:52:44,080 task computeModifications FAILED \n\n[INFO] 2018-09-17 09:52:44,080 task covGFF FAILED \n\n[INFO] 2018-09-17 09:52:44,081 task callVariantsWithConsensus FAILED \n\n[INFO] 2018-09-17 09:52:44,081 task statsJsonReport FAILED \n\nTraceback (most recent call last):\n\n  File \"/home/brandon/module/programs/smrtanalysis/2.3.0/install/smrtanalysis_2.3.0.140936/redist/python2.7/lib/python2.7/site-packages/SMRTpipe/engine/SmrtPipeWorkflow.py\", line 634, in execute\n\n    raise WorkflowError(_e_msg)\n\nWorkflowError: task://Anonymous/P_Mapping/samBam Failed task://Anonymous/P_ModificationDetection/computeModifications Failed task://Anonymous/P_Mapping/covGFF Failed task://Anonymous/P_GenomicConsensus/callVariantsWithConsensus Failed task://Anonymous/P_MappingReports/statsJsonReport Failed\n\nFailed smrtpipe version v1.87.139483 with exit code -1 in 826.66 seconds (13.78 minutes)\n\nbrandon@node0:dilay/inputs $\n\n</code></pre>"
    ],
    "67": [
        "<p>I need to login to the cluster many times a day and transfer some files using the scp command.<br>\nHow can I save my password so I do not need to enter it every time I login to the cluster?<br>\nI\u2019ve heard that there is a way to use \u201cpasswordless\u201d login.</p>\n<p><strong>CURATOR:</strong> Katia Oleinik</p>",
        "<p><strong>ANSWER:</strong> As katia said, this will be very site dependent.  And answers might vary<br>\ndepending on whether you are refering to passwordless ssh between the<br>\nlogin nodes and the compute nodes (on which you have a job running), or to<br>\npasswordless ssh between assorted workstations you use and the login nodes of<br>\nthe HPC cluster.</p>\n<p>Most sites probably have some mechanism already set up for the former, as many<br>\nschedulers use a passwordless ssh to initiate jobs on the compute nodes on your<br>\nbehalf.  Therefore, I am focussing on the latter case.</p>\n<p>I would expect that most sites which allow for passwordless ssh from arbitrary<br>\nworkstations to the login nodes use ssh\u2019s builtin public key authentication<br>\nmethod.  Basically, you generate an asymmetric key pair, and copy the \u201cpublic\u201d<br>\nkey to the login nodes of the HPC cluster (if the login nodes share a common<br>\nhome directory, you should only need to copy the public key to a single<br>\nlogin node) and is \u201cactivated\u201d.  The \u201cprivate\u201d key stays on your workstation.<br>\nAfter this, any user in possession of a copy of the private can login to the<br>\nHPC cluster as you \u2014 PROTECT YOUR PRIVATE KEY!.</p>\n<p>There are many websites with detailed instructions on how to do this, e.g.<br>\n<a href=\"http://www.ssh.com/ssh/public-key-authentication\" class=\"onebox\" target=\"_blank\">http://www.ssh.com/ssh/public-key-authentication</a><br>\n<a href=\"https://kb.iu.edu/d/aews\" class=\"onebox\" target=\"_blank\">https://kb.iu.edu/d/aews</a></p>\n<p>Basically,</p>\n<ol>\n<li>Generate the public/private key pair on your workstation with a command like<br>\n\u201cssh-keygen -t rsa\u201d</li>\n<li>Copy the public key to the login node(s), either with a command like<br>\n\u201cssh-copy-id YOUR_USERNAME@LOGIN_NODE_HOSTNAME\u201d or using scp.</li>\n<li>If you used something like scp for the former step, you need to manually<br>\nappend the contents of the id_rsa.pub public key file to ~/.ssh/authorized_keys<br>\non the login node.</li>\n</ol>",
        "<p><strong>ANSWER:</strong> This would depend on the cluster\u2026<br>\nThe Shared Computing Cluster at Boston University does not allow for this.<br>\nWe can give some general guidance about creating public and private keys (there are quite a few webpages talking about this out there), but my guess every cluster has its own rules and recommendations.</p>",
        "<p>I can answer the question reflected in the title (which is slightly different from the post itself) but I\u2019d guess a user might look here for both. For easier ssh, a trick I use for our Stanford clusters, along with a script that can help you to set it up. If you look in the \u201chosts\u201d folder of the <a href=\"https://github.com/vsoch/forward/tree/master/hosts\">forward tool here</a>, you\u2019ll see simple scripts to set up a configuration.</p>\n<h2>Where does a configuration go?</h2>\n<p>You have a  folder, <code>.ssh</code> in your $HOME that is like a safe keeping bucket for credentials. This is where you could find public and private keys, along with a file called <code>~/.ssh/config</code> where you can write named configurations for each resource you connect to.</p>\n<h2>How can I generate one?</h2>\n<p>For example, let\u2019s look at <a href=\"https://github.com/vsoch/forward/blob/master/hosts/sherlock_ssh.sh\">this script</a> for the Sherlock cluster.</p>\n<pre><code class=\"lang-bash\">wget https://raw.githubusercontent.com/vsoch/forward/master/hosts/sherlock_ssh.sh\n</code></pre>\n<p>Make it executable</p>\n<pre><code class=\"lang-bash\">chmod u+x sherlock_ssh.sh\n</code></pre>\n<p>And run it. The one thing it will ask us for is our username:</p>\n<pre><code class=\"lang-bash\">./sherlock_ssh.sh\nSherlock username &gt; pancake\n</code></pre>\n<pre><code class=\"lang-auto\">Host sherlock\n    User pancake\n    Hostname sh-ln05.stanford.edu\n    GSSAPIDelegateCredentials yes\n    GSSAPIAuthentication yes\n    ControlMaster auto\n    ControlPersist yes\n    ControlPath ~/.ssh/%l%r@%h:%p\n</code></pre>\n<p>You\u2019ll see it spits out the configuration to the command line after I enter my username, so the portion from the top at \u201cHost: sherlock\u201d to the bottom you would want to add to <code>~/.ssh/config</code>. If that file doesn\u2019t even exist for you, then you can just pipe into it directly.</p>\n<pre><code class=\"lang-bash\">/bin/bash sherlock_ssh.sh &gt; ~/.ssh/config\n</code></pre>\n<h2>What do the components mean?</h2>\n<p>As mentioned in other threads, the configuration itself is going to vary based on your cluster! For example, sherlock has (or at the time of the writing has) 8 login nodes. So the script itself starts by selecting a random number between 1 and 8, and that becomes your node. The reason I chose to do this is so I can issue multiple commands in a row but only need to authenticate for one session from a terminal. Here is what the script looks like:</p>\n<pre><code class=\"lang-bash\">#!/bin/bash\n#\n# Sherlock cluster at Stanford\n# Prints an ssh configuration for the user, selecting a login node at random\n# Sample usage: bash sherlock_ssh.sh\necho\nread -p \"Sherlock username &gt; \"  USERNAME\n\n# Randomly select login node from 1..4\nLOGIN_NODE=$((1 + RANDOM % 8))\n\necho \"Host sherlock\n    User ${USERNAME}\n    Hostname sh-ln0${LOGIN_NODE}.stanford.edu\n    GSSAPIDelegateCredentials yes\n    GSSAPIAuthentication yes\n    ControlMaster auto\n    ControlPersist yes\n    ControlPath ~/.ssh/%l%r@%h:%p\"\n</code></pre>\n<p>The <a href=\"https://www.cyberciti.biz/faq/create-ssh-config-file-on-linux-unix/\">Control</a>* and <a href=\"https://en.wikipedia.org/wiki/Generic_Security_Services_Application_Program_Interface\">GSSAPI</a>* parameters (perhaps someone can add more comment on these) help with enduring the session and also security, and tis would vary based on your cluster. I would also do a good search for ssh configurations and look at all the cool things you can set up!</p>\n<h2>How do I use it?</h2>\n<p>Once it\u2019s set up, the cool part is you can interact with your resource just via the host name, the first name (Host: sherlock). So for example, I can issue commands in a row (and only need to authenticate for the first one).</p>\n<pre><code class=\"lang-bash\">$ ssh sherlock ls\n$ ssh sherlock \"ls SCRIPT\"\nbash\nbrainbehavior\nmatlab\npython\nR\n</code></pre>\n<h2>How do I have multiple?</h2>\n<p>Have multiple just comes down to adding another (named) host in the file! For example:</p>\n<pre><code class=\"lang-bash\">Host sherlock\n    User pancakes\n    Hostname sh-ln06.stanford.edu\n    GSSAPIDelegateCredentials yes\n    GSSAPIAuthentication yes\n    ControlMaster auto\n    ControlPersist yes\n    ControlPath ~/.ssh/%l%r@%h:%p\n\nHost farmshare\n    User peas\n    Hostname rice.stanford.edu\n    GSSAPIDelegateCredentials yes\n    GSSAPIAuthentication yes\n    ControlMaster auto\n    ControlPersist yes\n    ControlPath ~/.ssh/%l%r@%h:%p\n</code></pre>"
    ],
    "456": [
        "<p>Has anyone tried and / or does anyone have experience with running clients that have both GPFS and CephFS? One mount point will be CephFS served over a 100Gb Ethernet connection. A second mount point will be GPFS served over an IB network connection. We are hoping to ward off potential gotchas.</p>",
        "<p>Is CephFS running RHEL? Because there\u2019s this\u2026</p>\n<p><a href=\"https://www-01.ibm.com/support/docview.wss?uid=ibm10887213&amp;myns=s033&amp;mynp=OCSTXKQY&amp;mync=E&amp;cm_sp=s033-\" rel=\"nofollow noopener\">https://www-01.ibm.com/support/docview.wss?uid=ibm10887213&amp;myns=s033&amp;mynp=OCSTXKQY&amp;mync=E&amp;cm_sp=s033-</a><em>-OCSTXKQY-</em>-E</p>",
        "<p>More GPFS fun for the crew.</p>"
    ],
    "72": [
        "<p>Before scheduling a job using Slurm, is there a way to check if the allocated compute node has the required filesystem mounted and accessible?</p>\n<p><strong>CURATOR:</strong> Raminder Singh</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>Your best bet is probably to enable node health checks.  There is a built in facility for this in Slurm (although you need to provide the actual checks, but there are some packages available).</p>\n<p>Basically, in Slurm config, you can set</p>\n<ul>\n<li>\n<p>HealthCheckProgram  \u2014 to the path of a health check program to use</p>\n</li>\n<li>\n<p>HealthCheckInterval \u2014 how often the health check should run on each node (in seconds)</p>\n</li>\n<li>\n<p>HealvthCheckNodeState \u2013 comma separated list of states (or ANY for any state) specifying which node states should run the checks.</p>\n</li>\n</ul>\n<p>The HealthCheckProgram should run whatever checks you want, and do what is desired if the health checks fail (typically place the node in the DRAIN state with an explanation of why).  By placing the node in the DRAIN state, no new jobs will be placed on the node until an administrator fixes the problem and UNDRAINs the node.  Any job currently running on the node will be allowed to complete.  One can choose other, more drastic actions if desired.</p>\n<p>As stated, Slurm has built-in support for running node health checks, but you are responsible for providing the health check code.  However, there are some packages out there.  You might wish to look at the <a href=\"https://github.com/mej/nhc\">Warewulf/LBNL node health check package</a>; this is a reliable, flexible framework.  You need to provide a config file listing which mount points you want to check, etc.</p>",
        "<p>A useful thing to be aware of with applying  <a href=\"https://github.com/mej/nhc\" rel=\"nofollow noopener\">Warewulf/LBNL node health check package</a> to the specific task of <code>... check that all mount points are in place, and mark a node out of service if a mount point is missing ....</code> is how to handle filesystem checks that can deadlock.</p>\n<p>Some filesystems (for example NFS mounts) can (and do) lock in a so-called</p>\n<blockquote>\n<p>uninterruptible sleep</p>\n</blockquote>\n<p>. When this happens the process making a health check can deadlock and will not report back.</p>\n<p>The <a href=\"https://github.com/mej/nhc\" rel=\"nofollow noopener\">Warewulf/LBNL node health check package</a> implements something called <code>Detached Mode</code> to handle this. This mode is usually used in a way that does not 100% fulfill the notion of <em>checking exactly before a job is scheduled</em>. Instead it is used to check periodically via the Slurm</p>\n<pre><code>HealthCheckProgram=COMMANDNAME\nHealthCheckInterval=TIMEINSECONDS\n</code></pre>\n<p>setting mentioned in this answer.</p>\n<p>If the health check fails then the node is marked so that it no longer accepts subsequent jobs. Jobs that arrive and are dispatched to a node in between a <code>Detached Mode</code> health check that passes and <code>Detached Mode</code> health check that fails, will still be launched. This is usually preferable to executing a health check that might deadlock as part of a Slurm prolog.</p>"
    ],
    "106": [
        "<p>I want to transfer data from my workstation (laptop) to an HPC machine and vice versa.  The resource has a Globus endpoint available. How can I use the Globus endpoint to transfer inputs to the cluster and results back to my workstation for further analysis?</p>\n<p><strong>CURATOR:</strong> Raminder Singh</p>",
        "<p>Since your HPC resource already has a Globus endpoint, just make your workstation a Globus Personal Connect endpoint:</p>\n<ol>\n<li>login to <a href=\"http://globus.org\" rel=\"nofollow noopener\">globus.org</a>\n</li>\n<li>on the left hand menu, select \u201cEndpoints\u201d</li>\n<li>in the upper right, click \u201cCreate new endpoint\u201d, then select \u201cGlobus Connect Personal\u201d and follow the instructions from there.</li>\n</ol>\n<p>Once you have your workstation set up as a personal endpoint, use the web portal at <a href=\"http://Globus.org\" rel=\"nofollow noopener\">Globus.org</a> to select both your HPC endpoint and your Personal Connect endpoint to initiate a data transfer between them.</p>",
        "<p>A Globus endpoint  is used in similar fashion as you would use an FTP site. Globus endpoints can be either Private or Public. For Private endpoints you will need to have an account and the applicable user permissions granted, on those endpoints. For Public endpoints you can transfer data to and from without having an account or being granted user permissions on those endpoints.</p>\n<p>Step 1: GO to <a href=\"https://www.globusid.org/\">https://www.globusid.org/</a><br>\nand create a Globus account<br>\nStep 2:  Log in to Globus<br>\nStep 3:  Create an endpoint on your institution\u2019s local Data Transfer Node (DTN)<br>\nStep 4:   Activate endpoint(endpoints are active for typically 24 hrs)<br>\nStep 5:   Transfer Files from a DTN at <a href=\"http://Globus.org\">Globus.org</a><br>\nexample of a Globus Public DTN is:<br>\n&gt; ESnet Read-Only Test DTN at New York&gt;</p>\n<p>(Select DTN for file transfer \u2013 push or pull) \u2013 depending on need and your permissions on DTN</p>\n<p>Points to Note:<br>\nThe Institution MUST have a DTN, for the Globus tool to be useful<br>\nA Domain Name (DN) on the Globus endpoint must be shared between collaborating DTNs.<br>\nGlobus back-end ties in with Microsoft Active Directory using LDAP for authentication with your institution\u2019s local DTN.</p>\n<p>Local DTN Parameters needed to create endpoint:</p>\n<p><strong>Host: DTN01.universityname.edu</strong><br>\n<strong>DN: /C=US/O=Globus Consortium/OU=Globus Connect Service/CN=0aba6458-2418-11e6-bfeb-22000b1701d1</strong><br>\n<strong>Control Port: 2811</strong></p>"
    ],
    "169": [
        "<p>There are a few R parallel packages I found that allow me to parallelize my loop - mclapply and parallel+foreach are most popular in my group. Which approach is most efficient in an HPC environment,<br>\nfor using a single node with a large number of cores?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p><strong>Comment</strong> Are you asking about \u201cstandard R\u201d methods that work well in a typical (or specific) HPC environment? Or taking advantage of the special set up, i.e. using other methods like MPI or MQ\u2019s?</p>",
        "<p>I am mostly interested in running R within an HPC environment, parallelizing over multiple cores on the same node. Is there any difference in performance (or memory usage) using mclappy() vs parallel loop using foreach()?  I did not find any measurable difference while some people suggest otherwise.</p>",
        "<p>The answer to this may vary depending on local conditions (version, build tools, etc), sharing arrangement on the node and how the program is coded.</p>\n<p><i> The best thing to do is to test it.</i><br>\nTo get the time info is <code>time</code></p>\n<p>I\u2019d recommend picking a small test case for what you\u2019re doing.</p>\n<p>If you call it test1.R test2.R\u2026:</p>\n<blockquote>\n<p><code>module load myFavoriteREnvironment</code><br>\n<code>time $(Rscript test1.R) &gt; test1.time</code><br>\n<code>time $(Rscript test2.R) &gt; test2.time</code></p>\n</blockquote>\n<p>each .time will have \u201cuser\u201d, \u201creal\u201d and \u201csys\u201d times</p>\n<p>\u201cuser\u201d is probably what you want, it\u2019s user experienced or wall clock time.</p>\n<p>\u201creal\u201d is the time spent running the program, summed for all processes</p>\n<p>\u201csys\u201d is time spent by the system on other things (startup, shutdown, wait to read or write data etc.)</p>"
    ],
    "168": [
        "<p>Which R packages can I use to parallelize my code on an HPC cluster? Are there any packages that allow parallelization over multiple nodes?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>I am not very familiar with them, but there are a few packages in R which can do parallelization using MPI, and therefore should be able to parallelize over multiple nodes.</p>\n<p>Rmpi I believe is the package which provides the underlying, low-level MPI support for R.</p>\n<p>However, I believe most people find the snow package to be higher level/more user friendly.  I believe snow leverages Rmpi to allow parallelization across nodes, but might also be usable without Rmpi (i.e. using OpenMP for parallelization only within a node).  There is also a doSNOW package which builds on snow and provides a parallel loop function.</p>\n<p>When using snow with MPI, a couple of potential gotchas:</p>\n<ol>\n<li>\n<p>The mpirun command for snow based R codes should typically use -np 1 \u2014 typically snow spawns its own workers.  You still need to tell the scheduler to allocate the correct number of cores.</p>\n</li>\n<li>\n<p>Most snow based R code will at some point invoke the makeCluster function, which takes a parameter indicating the size of the \u201ccluster\u201d to create.  Usually, one wants this to be one less than the number of cores requested from the scheduler, as the main task, which spawns the other tasks, is already consuming one core.</p>\n</li>\n</ol>\n<p>I.e., if you are telling makeCluster to create a cluster of 100 workers,<br>\nyou should request 101 cores from Slurm or whatever scheduler you are using.<br>\nIf by mistake you request the same number (e.g. 100) from both the scheduler<br>\nand the makeCluster command, there will be one core oversubscribed which<br>\ngenerally will cause issues.  Typically, I see the R script reporting an<br>\nerror about an insufficient number of \u201cslots\u201d being available, and just hanging<br>\n(doing nothing but not dying til the job is killed).</p>",
        "<p>The relevant R packages are listed and described in the HPC task view, available at <a href=\"https://cran.r-project.org/web/views/HighPerformanceComputing.html\">https://cran.r-project.org/web/views/HighPerformanceComputing.html</a>. You can contribute to this list at <a href=\"https://github.com/eddelbuettel/ctv-hpc\">https://github.com/eddelbuettel/ctv-hpc</a> if you find something missing or incomplete.</p>"
    ],
    "265": [
        "<p>I have a portion of a calculation which turns a triplet of double-precision coordinates (x,y,z), into an integer index.  To do this, I am using an integer cast, of the form <code>int cx = (int)(x/dx);</code>.  In testing, however, this seems much slower than I would expect; mere division is much faster.</p>\n<p>Is there a reason why this operation takes so long?  Is there a way of making it faster?</p>"
    ],
    "448": [
        "<p>I have a virtual machine image in openstack.  It is running ubuntu.  I used it in a class about a year ago, but I have forgotten the password, and even the user name (but I do remember they were chosen to be secure).  I also remember that the ubuntu user was removed and root logins were disabled, specifically to make the machine hard to attack.  I can launch the machine and get the login prompt, but I can\u2019t sign in without credentials.  What can I do?</p>",
        "<p>I found the solution!  When launching the image, there\u2019s a \u201cPost-Creation\u201d tab that lets you specify a script to run after the machine is launched, see below<br>\n<div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/ad7dcacd28c11623be9063f04937499bab297151.png\" data-download-href=\"https://ask.cyberinfrastructure.org/uploads/default/ad7dcacd28c11623be9063f04937499bab297151\" title=\"Screen Shot 2018-08-28 at 3.47.03 PM.png\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/ad7dcacd28c11623be9063f04937499bab297151_2_690x277.png\" alt=\"03%20PM\" width=\"690\" height=\"277\" srcset=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/ad7dcacd28c11623be9063f04937499bab297151_2_690x277.png, https://ask.cyberinfrastructure.org/uploads/default/original/1X/ad7dcacd28c11623be9063f04937499bab297151.png 1.5x, https://ask.cyberinfrastructure.org/uploads/default/original/1X/ad7dcacd28c11623be9063f04937499bab297151.png 2x\" data-small-upload=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/ad7dcacd28c11623be9063f04937499bab297151_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2018-08-28 at 3.47.03 PM.png</span><span class=\"informations\">719\u00d7289 22.9 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>If you pick direct input, you can type (or paste) a shell script into a text box and have it run once when the machine is launched.  I had it create a user called temporary and a password called temporary.  The password must be changed on the first login.  The user has sudo rights, so can view which user accounts exist, change passwords to a known value, look at files, or whatever.</p>\n<p>#!/bin/bash<br>\nUSERNAME=\u2018temporary\u2019<br>\nPASSWORD=\u2018temporary\u2019</p>\n<p>useradd -m -U -G adm,dialout,cdrom,floppy,sudo,audio,dip,video,plugdev,netdev -s /bin/bash $USERNAME<br>\necho \u201c$USERNAME:$PASSWORD\u201d | chpasswd<br>\nchage -d 0 $USERNAME</p>",
        "<p>Remember not to apply the following directly to your VM! Test it first on a clone or a backup image before applying it to your production VM.</p>\n<p>It depends on your installation, but in general you should be able to do this by booting into rescue mode (you can select this as the machine is booting up). This will give you a shell, remount the file system with read/write (it\u2019s read only at this point). Then you will be able to edit the shadow file and delete root/user hashed password and reboot.</p>"
    ],
    "258": [
        "<p>Some of my large GAMESS calculations are failing due to insufficient memory after waiting in the queue for days.  I\u2019d like to calculate the amount of memory I need before submitting so I can be sure my jobs don\u2019t fail.</p>",
        "<p>Unlike some programs, GAMESS requires the user to specify exactly how much memory will be used in the input file as MWORDS and MEMDDI.</p>\n<p>MWORDS is RAM per MPI rank.</p>\n<p>MEMDDI is distributed memory for distributed parallel methods (MP2 for example).</p>\n<p>GAMESS provides a \u201cCheck Run\u201d (EXETYP=CHECK) option that you can use to see how much memory is required before submitting a production simulation.</p>"
    ],
    "367": [
        "<p>Hi all,</p>\n<p>We have recently upgraded to using Torque with cgroups.  We have been happy with the use of cgroups in general however, I have recently found that MPI process affinity usually does nothing to improve run times and sometimes slows down certain MPI applications.  I assume this is due to process affinity interfering with cgroups(?).</p>\n<p>My question is, since the MPI versions we support here at W&amp;M (IntelMPI, Mvapich2 and OpenMPI) all have some sort of process binding by default, do you somehow disable MPI process affinity system-wide, do you simply warn your users to investigate the effect of process affinity, or do you not see any effect of processes affinity + cgroups.</p>\n<p>Just wondering what the common wisdom is since most google searching and looking at the MPI websites don\u2019t seem to address effects of cgroups and</p>\n<p>Thanks for any information that can be shared.</p>\n<p>Regards,</p>\n<p>Eric</p>",
        "<p>Actually, upon further research:</p>\n<ol>\n<li>\n<p>cgroups is not really involved, the effect of affinity seems to happen outside of Torque.</p>\n</li>\n<li>\n<p>The effect of process affinity seems to be minor for other codes I have tested.  I guess the one benchmark (lu-mz from the NASA parallel benchmark suite:  <a href=\"https://www.nas.nasa.gov/publications/npb.html\" rel=\"nofollow noopener\">https://www.nas.nasa.gov/publications/npb.html</a>) seems to be quite sensitive to affinity a process placement.</p>\n</li>\n<li>\n<p>Also, I have found one of our sub-cluster which seems to yield much better run times without process affinity enforced however however, this doesn\u2019t happen on any other machines in our cluster.  Probably something sub-optimal about the configuration.</p>\n</li>\n</ol>\n<p>So, the bottom line seems to be that each code needs to be tested separately to determine whether it benefits from process affinity or not.  Also, the cgroups being involved was an assumption / confusion on my part.</p>\n<p>Eric</p>"
    ],
    "98": [
        "<p>When running a storage intensive MPI job that uses an Isilon Storage system for scratch (working storage), are there any I/O bottlenecks that can be avoided?</p>\n<p>Are there any clear ways of identifying them when they happen?</p>\n<p><strong>CURATOR:</strong> jpessin1</p>",
        "<p>This would depend on the MPI job\u2019s use of storage. If the MPI job uses parallel I/O to a single file, you are out of luck. As far as I know, Isilon\u2019s NFS implementation knows nothing about parallel I/O (stuck at NFS 4.0 I believe) so whatever the app falls back to would be how it does I/O.</p>\n<p>If the MPI job has a serial step which collects and writes as a single process, then it\u2019s effectively the same as any other job where you just want to optimize single-node I/O. Making sure the MPI job is the only job running on the node is probably enough to allow a single node to saturate the connection to the isilon cluster, which is probably theoretically peaked at 1 GB/s.</p>\n<p>If the MPI job processes all do read/write but with each process having its own file for writing, then you\u2019ll probably get decent load balancing for free if you have enough nodes in the Isilon cluster and are using smartconnect.</p>\n<p>To look for I/O bottlenecks, I typically check the node(s) doing the I/O and watch with dstat, iostat or iotop. If things are slower than I\u2019d expect (compared to what a <code>dd if=/dev/zero of=/path/to/isilon</code> will do) then the next place to look is to strace or otherwise check the app to see how it is writing. One really common mistake I see is people writing a script with a loop which opens file, writes a line, closes file. The Isilon metadata slowness really shows up in that kind of access. In general with the Isilon avoiding metadata access and writing large blocks seems to help.</p>",
        "<p>\u201ca script with a loop which opens file, writes a line, closes file. The Isilon metadata slowness really shows up in that kind of access. <em>In general with the Isilon avoiding metadata access and writing large blocks seems to help</em>\u201d \u2013 Awesome insight!</p>"
    ],
    "75": [
        "<p>What is the process for contributing cycles to the Open Science Grid?</p>\n<p><strong>CURATOR:</strong> jpessin1</p>",
        "<p>Hi Jacob</p>\n<p>Great question. To my knowledge, there are two options available.  If you want to  contribute cycles by allowing more than 500 jobs at a time, it is a good idea to set up HTCondor-CE. See more details here at <a href=\"http://opensciencegrid.org/docs/compute-element/htcondor-ce-overview/\" rel=\"nofollow noopener\">http://opensciencegrid.org/docs/compute-element/htcondor-ce-overview/</a><br>\nThe other is a light weight approach based on an account and SSH key set up.<br>\nHere is a good starting doc for the OSG managed services <a href=\"https://support.opensciencegrid.org/support/solutions/articles/12000025149-osg-managed-services\" rel=\"nofollow noopener\">https://support.opensciencegrid.org/support/solutions/articles/12000025149-osg-managed-services</a></p>\n<p>Bala</p>\n<p>Bala Desinghu, PhD<br>\nSenior Scientist<br>\nOffice of Advanced Research Computing<br>\nRutgers University</p>"
    ],
    "912": [
        "<p>If I have a JOBID=12345 of a running job, what is the command to attach to that job so that I can run top on the compute node so that I can get an idea of the resources being used?</p>",
        "<p>To attach to a running job (job $JOBID)</p>\n<pre><code class=\"lang-auto\">srun --pty --jobid $JOBID /bin/bash\n</code></pre>\n<p>This will run inside the cgroup (CPU, RAM etc.) of the running job.</p>\n<p>If you want to see the processes you can run top directly via</p>\n<pre><code class=\"lang-auto\">srun --pty --jobid $JOBID  top\n</code></pre>\n<p>For jobs with multiple nodes you need first find the node you want to attach to via</p>\n<pre><code class=\"lang-auto\">scontrol show job $JOBID |grep NodeList\n</code></pre>\n<p>Then use the <code>-w</code> switch to specify the node ($NODE)</p>\n<pre><code class=\"lang-auto\">srun --pty --jobid $JOBID -w $NODE /bin/bash\n</code></pre>",
        "<p>Alternatively, our cluster has the <a href=\"https://slurm.schedmd.com/pam_slurm_adopt.html\" rel=\"nofollow noopener\">pam_slurm_adopt</a> module installed that lets users just ssh from the submit host to any node they have a job running on.</p>"
    ],
    "599": [
        "<p>A new XSEDE user asks: Is there a way to install Python 2.7 and specific Python packages to the Comet computing environment, and to analyze data using this software?</p>\n<p>Also, what is the best place to store data long-term (when using Comet), and what is the best place to store data that is currently being analyzed?</p>",
        "<p>I think the answer I just wrote up here would be helpful: <a href=\"https://ask.cyberinfrastructure.org/t/do-you-have-bioinformatic-specific-script-examples-to-share/597/2\">Do you have bioinformatic specific script examples to share?</a></p>\n<ul>\n<li>You would install python 2.7 for each application that is needed via containers, so you work reproducibly.</li>\n<li>The storage for data might be oasis? Not sure, but seems like a data place <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=6\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> For \u201ccurrently being analyzed\u201d I don\u2019t know the answer, but I\u2019d look for something called <code>$SCRATCH</code> (temporary for user, purged every N months depending on the cluster) or <code>$LOCAL_SCRATCH</code> (temporary for intermediate files for a job).</li>\n</ul>",
        "<p>Thank you for your help, especially to pointing out the bioinformatic examples. I\u2019ll pass this info along to the researcher <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/smiley.png?v=6\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"><br>\n~ Cyd</p>"
    ],
    "77": [
        "<p>Docker is getting used to containerize applications. Is there a good way to run Docker containers on HPC?</p>\n<p><strong>CURATOR:</strong> Raminder Singh</p>",
        "<p>Docker is not used on many HPC sites due to security concerns. That is primarily because Docker can be misused by a regular user to obtain superuser access.</p>\n<p>However, alternative container runtimes do exist which try to avoid the security issue and offer similar features. As an added bonus they usually support importing existing Docker images. Conversion of images becomes trivial.</p>\n<p>You can find more information here:</p>\n<p>Singularity<br>\n<a href=\"https://www.sylabs.io/docs/\" class=\"onebox\" target=\"_blank\">https://www.sylabs.io/docs/</a></p>\n<p>Shifter<br>\n<a href=\"https://www.nersc.gov/research-and-development/user-defined-images\" class=\"onebox\" target=\"_blank\">https://www.nersc.gov/research-and-development/user-defined-images</a></p>",
        "<p>Singularity can be used to run docker containers or to create custom containers for HPC (shared) clusters without providing root access to the users. Visit <a href=\"https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/\">https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/</a> for more details.</p>"
    ],
    "35": [
        "<p>Sometimes when I run a SLURM job, I receive the following message in my stderr file: \u201cslurmstepd: error: Exceeded step memory limit at some point\u201d.  What does this mean?  Should I be worried about this? How do I avoid getting this error?</p>\n<p><strong>CURATOR:</strong> Scott Yockel</p>",
        "<p><strong>ANSWER:</strong> This error indicates that at some point, your job (or a task in your job) used more<br>\nmemory than was allocated to it, and Slurm killed your job.</p>\n<p>You can use the sacct cmd to find the maximum resident memory size (MaxRSS)<br>\nfor any task in your job; see <a href=\"https://researchcomputing.cyberinfrastructure.org/t/how-can-i-use-slurms-sacct-command-to-show-memory-usage-statistics-for-a-job-that-i-am-running/38\">How can I use SLURM\u2019s sacct command to show memory usage statistics for a job that I am running?</a><br>\nfor more details.</p>\n<p>In the simple case that your job just needs a bit more memory than you requested,<br>\nyou can try increasing the amount of memory that you request.  This is usually<br>\nspecified in slurm with either the --mem-per-cpu=MEMSIZE or --mem=MEMSIZE<br>\nparameters to sbatch; the former sets the memory per allocated CPU core, the latter<br>\nsets the memory required per node.  Usually it the memory per allocated CPU core<br>\nmakes more sense to set.  In either case, MEMSIZE is amount of memory in MB.</p>\n<p>You should try to do an estimate of how much memory your code will need to ensure<br>\nthat you are not hitting a memory leak which will consume however much memory<br>\nyou throw at the job (and requires fixing the code).</p>",
        "<p><strong>AC COMMENT:</strong> The answer by payerle to this question does, indeed, address the issue in detail, however for the question itself to be StackExchange-ready it needs further work in the following ways:</p>\n<ol>\n<li>first, the person asking the question should follow the guidance at: <a href=\"https://math.stackexchange.com/help/how-to-ask\">https://math.stackexchange.com/help/how-to-ask</a>\n</li>\n</ol>\n<blockquote>\n<p><em>\u201cHave you thoroughly searched for an answer before asking your question? Sharing your research helps everyone. Tell us what you found and why it didn\u2019t meet your needs. This demonstrates that you\u2019ve taken the time to try to help yourself, it saves us from reiterating obvious answers, and above all, it helps you get a more specific and relevant answer!\u201d</em></p>\n</blockquote>\n<p>By simply copy-pasting this question title into a google search: <a href=\"https://www.google.com/search?q=My+job+died+with+a+%E2%80%9Cslurmstepd%3A+error%3A+Exceeded+step+memory+limit+at+some+point%E2%80%9D+please+help&amp;oq=My+job+died+with+a+%E2%80%9Cslurmstepd%3A+error%3A+Exceeded+step+memory+limit+at+some+point%E2%80%9D+please+help\">https://www.google.com/search?q=My+job+died+with+a+\u201cslurmstepd%3A+error%3A+Exceeded+step+memory+limit+at+some+point\u201d+please+help&amp;oq=My+job+died+with+a+\u201cslurmstepd%3A+error%3A+Exceeded+step+memory+limit+at+some+point\u201d+please+help</a></p>\n<p>The first few search results yield some good hits:</p>\n<ul>\n<li><a href=\"https://bugs.schedmd.com/show_bug.cgi?id=3214\">https://bugs.schedmd.com/show_bug.cgi?id=3214</a></li>\n<li><a href=\"https://stackoverflow.com/questions/45993739/slurmstepd-error-exceeded-step-memory-limit-at-some-point\">https://stackoverflow.com/questions/45993739/slurmstepd-error-exceeded-step-memory-limit-at-some-point</a></li>\n<li><a href=\"https://unix.stackexchange.com/questions/361418/possible-effects-of-slurmstepd-error-exceeded-step-memory-limit-at-some-point\">https://unix.stackexchange.com/questions/361418/possible-effects-of-slurmstepd-error-exceeded-step-memory-limit-at-some-point</a></li>\n</ul>\n<p>In the StackExchange community, it\u2019s often the case that there are several good answers to a question, rather than a single good answer\u2014 depending on how specific the question is, and whether or not it actually has a single solution or not.  Given that a google search reveals several different answers, those could be referenced by another person to answer the question in addition to what payerle has posted.</p>"
    ],
    "87": [
        "<p>In my job script when I\u2019m using the following options, what are the differences between each of them?<br>\n<code>#PBS -l select=8:ncpus=8:mpiprocs=8</code></p>\n<p><strong>CURATOR:</strong> Scott Yockel</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>The line <code>#PBS -l select=8:ncpus=8:mpiprocs=8</code>, controls how the system allocates processor cores for your MPI jobs.</p>\n<pre><code class=\"lang-auto\">select=# -- allocate # separate nodes\nncpus=# -- on each node allocate # cpus (cores)\nmpiprocs=# -- on each node allocate # cpus (of the ncpus allocated) to MPI\n</code></pre>\n<p>By varying the above, you can control how cpu resources are allocated, The above example allocates 64 cores all of which are for use by MPI (8 nodes with 8 cpus on each node).</p>\n<p>If, for example, your program is hybrid MPI/OPENMP program that runs 8 MP threads on 4 mpi control processes, you would use something like: <code>#PBS -l select=4:ncpus=12:mpiprocs=4</code>.</p>"
    ],
    "38": [
        "<p>I want to find out how much memory my jobs are using on a cluster that uses the SLURM scheduler.  When I run the sacct command, the output does not include information about memory usage.  The <a href=\"https://slurm.schedmd.com/sacct.html\" rel=\"nofollow noopener\">man page for sacct</a>, shows a long and somewhat confusing array of options, and it is hard to tell which one is best.</p>\n<p><strong>CURATOR:</strong>  John Goodhue</p>",
        "<p><strong>ANSWER:</strong> This will do the trick: <code>sacct --format=\"CPUTime,MaxRSS\"</code></p>",
        "<p>ANSWER: It\u2019s useful to know that SLURM uses RSS (Resident set size) to indicate memory-related options.  The man page lists four fields that one can specify with the \u201cformat\u201d option that might be of use:</p>\n<p>AveRSS \u2013 Average resident set size of all tasks in job<br>\nMaxRSS \u2013 Maximum resident set size of all tasks in job<br>\nMaxRSSNode \u2013 The node on which the maxrss occurred<br>\nMaxRSSTask  \u2013 The task ID where the maxrss occurred</p>\n<p>For example,</p>\n<pre><code class=\"lang-auto\">sacct --format=\"AveRSS,MaxRSS,MaxRSSNode\"\n</code></pre>\n<p>Will display the Average and Maximum memory footprint for all tasks in your currently running jobs, and the nodes on which the maximum memory footprints occurred.</p>",
        "<p>CLARIFICATION: Can you tell us more about what you want to learn from the memory</p>",
        "<p>ANSWER: Here is an output if job ID is supplied:</p>\n<pre><code class=\"lang-auto\">login002 koleinik &gt; sacct -o MaxRSS -j 129086\n    MaxRSS\n----------\n\n     1284K\n</code></pre>\n<p>If jobID is not known, one can specify the date range:</p>\n<pre><code class=\"lang-auto\">login002 koleinik &gt; sacct -S2017-01-01-00:00 -E2018-03-26-10:15  -o jobid,start,end,state,MaxRSS\n       JobID               Start                 End      State     MaxRSS\n------------ ------------------- ------------------- ---------- ----------\n4901635      2017-11-11T13:09:40 2017-11-11T13:09:43     FAILED\n4901635.bat+ 2017-11-11T13:09:40 2017-11-11T13:09:43     FAILED     33664K\n4901636      2017-11-11T13:17:32 2017-11-11T13:17:35     FAILED\n4901636.bat+ 2017-11-11T13:17:32 2017-11-11T13:17:35     FAILED     36628K\n4901638      2017-11-11T13:54:33 2017-11-11T13:54:37     FAILED\n4901638.bat+ 2017-11-11T13:54:33 2017-11-11T13:54:37     FAILED     36844K\n4901639      2017-11-11T13:56:12 2017-11-11T13:58:13 CANCELLED+\n4901639.bat+ 2017-11-11T13:56:12 2017-11-11T13:58:20  CANCELLED 133404464K\n</code></pre>",
        "<p>ANSWER: There\u2019s a StackOverflow Q&amp;A on this topic at:</p>\n<aside class=\"onebox stackexchange\">\n  <header class=\"source\">\n      <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">stackoverflow.com</a>\n  </header>\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/1701545/user1701545\" target=\"_blank\" rel=\"nofollow noopener\">\n    <img alt=\"user1701545\" src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/423372a6f150fa0ddcd08764ed398d8f44791e20.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n  </a>\n<h4>\n  <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">Find out the CPU time and memory usage of a slurm job</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>slurm</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/1701545/user1701545\" target=\"_blank\" rel=\"nofollow noopener\">\n    user1701545\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">04:35PM - 03 Jun 14 UTC</a>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n"
    ],
    "122": [
        "<p>What is a \u201cBurst Buffer\u201d and how is it different from other filesystems such as Lustre or GPFS?</p>\n<p><strong>CURATOR:</strong> Grace Wilson Caudill/Scott Valcourt</p>",
        "<p>Burst buffers are a name given to intermediate layers of custom software and hardware that sit between an I/O source (e.g. an application writing to some files) and an I/O end-point (e.g. a Lustre file system). Typically a burst buffer will stage and/or rearrange I/O requests from an application so that it writes to the final end-point file system in large, contiguous chunks. To make this work, the burst buffer system employs some form of high-speed intermediate storage (for example non-volatile RAM or SSD) and application I/O is transparently written to this intermediate layer.</p>\n<p>Application code that has bursty (i.e. intermittent in time) I/O, especially with small files, can see effective I/O performance increases from burst buffer technologies. The high-speed buffer layer allows the application to progress through I/O rapidly, while the burst buffer system software has time during I/O free phases to move bytes from the burst buffer to the main storage.</p>\n<p>Burst buffer technologies are most commonly developed as integrated solutions together with parallel storage backend systems. There is at least one backend storage-agnostic burst buffer experiment under development - see <a href=\"https://github.com/LLNL/burstfs\">https://github.com/LLNL/burstfs</a></p>"
    ],
    "158": [
        "<p>I am working in a large Linux cluster. All our data is stored in a project space.  My input (text) file is very large and  the values that I need to read in are located in 3 large groups. I need to read a single value from each group and perform some analysis. So my program performs many \u201cseek\u201d - type operations to read the data that needs to be processed. I benchmarked my application and it looks like this seek/read operation is the bottleneck in my code. How I can improve the performance of this job?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p>The best approach in this case is to open this file 3 times and store 3 file handlers. The values that need to be read from the first group would use the first file handle, for the second value - the second etc.<br>\nThis way you will avoid the seek operation and the reading will be performed sequentially.<br>\nDepending on the size of your file you can also try to first move this input file to the scratch directory local to the compute node where your job executes - this may improve the IO speed.</p>"
    ],
    "903": [
        "<p>I was browsing <a href=\"https://code.nasa.gov/\" rel=\"nofollow noopener\">https://code.nasa.gov/</a> and heard that there is an interesting story behind the development of TASC, the \u201cTool for Analysis of Surface Cracks\u201d <a href=\"https://software.nasa.gov/software/MFS-33082-1\" rel=\"nofollow noopener\">https://software.nasa.gov/software/MFS-33082-1</a>. I\u2019m generally interested in stories about the development of open source projects, and was curious if anyone had details, along with how this software might be useful for our community. Thanks!</p>",
        "<p>So I\u2019m late with my story. In my immediate academic lineage, the primary author of TASC is PhD student <span class=\"hashtag\">#1</span>, and I\u2019m PhD student <span class=\"hashtag\">#3</span>. Its origins are somewhat given in <a href=\"https://www.sciencedirect.com/science/article/pii/S0013794414000551\" rel=\"nofollow noopener\">Allen and Wells: Interpolation methodology for elastic\u2013plastic <em>J</em>-integral solutions for surface cracked plates in tension</a>.</p>\n<p>The basic situation is that determining when cracks will grow at all (or when the cracked structure will just fracture entirely) gets more intractable as the crack geometry, the applied stresses, and the material properties get more complex. Two-dimensional crack geometries (edge cuts, center slits) are easier than three-dimensional geometries (surface cracks or corner cracks, as if you\u2019d stuck your thumbnail into a block of clay); constant states of tension are easier than bending (where part of the crack is in tension, and other parts are in compression); brittle materials are easier than ones that can withstand substantial permanent deformation under increasing stress; etc.</p>\n<p>So the applicable <a href=\"https://www.astm.org/Standards/E2899.htm\" rel=\"nofollow noopener\">ASTM standard</a> (press release <a href=\"https://www.astm.org/cms/drupal-7.51/newsroom/new-astm-fatigue-standard-will-enable-fracture-toughness-testing\" rel=\"nofollow noopener\">here</a>) encompasses semi-elliptical surface cracks in tension or in bending, and for flat plates where the plate behavior is brittle (purely linear elastic behavior) or where substantial deformation can occur under increasing stress (elastic-plastic behavior).</p>\n<p>For linear elastic materials, there are handbook solutions for certain crack behavior derived from curve fits for a wide range of semi-elliptical surface crack shapes and sizes, for both tension and bending. For elastic-plastic materials, there are no such curve fits. The default way to calculate this crack behavior would be to make a purpose-built finite element model of the cracked plate for any arbitrary geometry and material. These models would generally have to be recalculated from scratch if the geometry or material changed.</p>\n<p>So PhD student <span class=\"hashtag\">#1</span> worked up a method to make a database of numerical solutions for the same range of surface crack geometry (20 normalized shapes and sizes) and a wide range of elastic-plastic materials (30 normalized materials) for plates in uniform tension. That\u2019s 600 solutions in the solution space, and solutions for intermediate values can be interpolated among the 600 solutions as needed. All of this is detailed in the first link above.</p>\n<p>As PhD student <span class=\"hashtag\">#1</span> is a regular engineer, and not a professional software developer, he wrote up an interpolation code and GUI in MATLAB, and that\u2019s <a href=\"https://software.nasa.gov/software/MFS-33082-1\" rel=\"nofollow noopener\">TASC</a>. He had prior experience with MATLAB, could avoid reinventing wheels, and there are ways to make standalone executables in MATLAB that don\u2019t require a MATLAB installation to run. A different developer might have picked numpy, scipy, and some other Python GUI library.</p>\n<p>PhD student <span class=\"hashtag\">#3</span> (me) had a bit more software development experience and a few mental quirks that led to a <strong>lot</strong> of MATLAB code cleanup and a database of 600 finite element models for surface cracks in bending. That database covers the same range of crack geometry and materials as the original TASC tension database, and the models were mostly programmatically generated and evaluated. That development is generally documented in chapters 3-5 of <a href=\"https://github.com/mikerenfro/phd/tree/master/dissertation\" rel=\"nofollow noopener\">my dissertation</a> (still have to get all the Python automation code uploaded this summer). The still-in-testing TASC code for both tension and bending is in <a href=\"https://github.com/mikerenfro/tasc\" rel=\"nofollow noopener\">one of my Github repositories</a>.</p>"
    ],
    "236": [
        "<p>Modules created to handle multiple versions of compilers, tools, drivers and libraries on a shared cluster need to be presented in a manner that promotes efficient loading to the user\u2019s environment.  Interdependence is prevalent among individual modules; for a given application, for example, the user may need specific libraries and compiler environments to successfully execute a calculation. What are the most effective ways to handle these?</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>I would suggest using LMOD, this is TACC\u2019s environment module system.  LMOD forces those dependencies, whether it is compilers or libraries, to be loaded first before you can see the software that is available with those combinations. This eliminates the issue of having the wrong library in your path when running software linked to it.  As they put it \"Lmod is a Lua based module system that easily handles the MODULEPATH Hierarchical problem. \"<br>\n<a href=\"https://www.tacc.utexas.edu/research-development/tacc-projects/lmod\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://www.tacc.utexas.edu/research-development/tacc-projects/lmod</a><br>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://github.githubassets.com/favicon.ico\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://github.com/TACC/Lmod\" target=\"_blank\" rel=\"nofollow noopener\">GitHub</a>\n  </header>\n  <article class=\"onebox-body\">\n    <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/cc375130eb5189af66ef2d6a7b047ac355d397e1.jpeg\" class=\"thumbnail onebox-avatar\" width=\"400\" height=\"400\">\n\n<h3><a href=\"https://github.com/TACC/Lmod\" target=\"_blank\" rel=\"nofollow noopener\">TACC/Lmod</a></h3>\n\n<p>Lmod: An Environment Module System based on Lua, Reads TCL Modules, Supports a Software Hierarchy - TACC/Lmod</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>As syockel stated, LMOD is a good solution.</p>\n<p>Alternatively, we have had success with standard (Tcl) modules using .modulerc files.  We would use<br>\nmultiple paths in the module tag name, specifying the compiler, MPI libs, etc. the package depended<br>\non.  Modulerc files would then be used to detect what if any compiler/MPI lib, etc. loaded and default the module path accordingly.  E.g., for package foo version 1.2.3 built with gcc/6.1.0 and openmpi/1.10.2 and netcdf/4.4.1.1, we might have the following modules:</p>\n<p>foo/1.2.3/netcdf/4.4.1.1/gcc/6.1.0/openmpi/1.10.2 and<br>\nfoo/netcdf/4.4.1.1/gcc/6.1.0/openmpi/1.10.2/1.2.3<br>\n(these would typically either be symlinks to each other, or more typically tiny stub files (just defining<br>\nvariables for versions of foo, netcdf, compiler, mpi) which then include a common module file for all<br>\n\u201cfoo\u201d modules)</p>\n<p>The .modulercs under foo and foo/1.2.3 would default to netcdf.<br>\nThe .modulercs under foo/netcdf, foo/1.2.3/netcdf would default to the version of netcdf previously loaded (and if none previously loaded, get the most recent in the directory)<br>\nThe .modulercs under the netcdf/4.4.1.1 dirs would default to the compiler family (e.g. gcc)<br>\nThe .modulercs under the netcdf/4.4.1.1/gcc dirs would default to the gcc version.<br>\nThe .modulercs under netcdf/4.4.1.1/gcc/6.1.0 would default to the MPI family<br>\nThe .modulercs under netcdf/4.4.1.1/gcc/6.1.0/openmpi to the OpenMPI version previously loaded.</p>\n<p>As the modulercs to default on family or version of compiler, MPI, netcdf, etc. are used for many packages, and are identical, these can all be symlinks to a stock modulerc.select_compiler_family, etc script in an utilities directory.</p>\n<p>This approach offers some more flexibility in some respects than the lmod approach (e.g. one could use .modulerc files to default simd support levels based on hostname),  but is also more work to maintain.  It also does not support \u201cmodule swap\u201d well, and requires a patch to the old Tcl modulefiles code (there was a bug present in many versions that always evaluated .modulerc files<br>\nin \u201cload\u201d mode \u2014 this would cause errors re compiler/app mismatches in the .modulerc files to get displayed during module avail, etc).  And although it looks like someone started supporting Tcl<br>\nmodules once again, I am not sure that all of this works with the new updates.</p>\n<p>In short, we have used the above successfully, but I expect we will be switching to Lmod for our next cluster.  But if anyone wants more detail on the above, feel free to contact me.</p>"
    ],
    "200": [
        "<p>I know that my cluster has some gpus and a mix of hardware bought at different times and having different processors. How do I make sure that slurm allocates my job to specific nodes, for example, a specific node with a gpu?</p>\n<p><strong>CURATOR</strong>: Kristina Plazonic</p>",
        "<p>There are a number of options you can request with <code>salloc</code>, <code>srun</code> or <code>sbatch</code> that indicate which nodes or resources you would like to use. For example:</p>\n<ul>\n<li>\n<code>nodelist</code> = list of nodes where to run e.g. <code>--nodelist=mynodename1,mynodename2</code>\n</li>\n<li>\n<code>nodefile</code> = like <code>nodelist</code> but you specify the file with a list of nodes e.g. <code>--nodefile=mynodefilelist.txt</code>\n</li>\n<li>\n<code>constraint</code> = list of features that need to be present on the node\n<ul>\n<li>e.g. <code>--constraint=pascal</code> - and this can be a boolean expression like<br>\n<code>--constraint=\"pascal|tesla\"</code> or <code>--constraint=\"pascal&amp;skylake\"</code>\n</li>\n</ul>\n</li>\n</ul>\n<p>For example, your command might be:<br>\nsrun -N 1 -n 1 -c 2 --nodelist=mynodename1,mynodename2  --constraint=pascal myscript.sh</p>"
    ],
    "223": [
        "<p>I am running an MPI job using 8 nodes with 16 cores each. When I execute <code>qstat -u username</code> command it shows only the master node. How can I view all the nodes that are used for my job?</p>\n<p><strong>Curator</strong>: Katia</p>",
        "<p>This will not give you the precise answer if you have multiple, multiple node MP jobs running, but will give you all the nodes that all your jobs are running on:</p>\n<p><a href=\"http://moo.nac.uci.edu/~hjm/qbetta\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">http://moo.nac.uci.edu/~hjm/qbetta</a></p>\n<p>It\u2019s a fast and dirty perl script that merges the output of \u2018qstat -s r\u2019 and \u2018qhost -h (host) -q\u2019 and does some dirty math on the result to show which nodes are under/overloaded.</p>\n<p>grep the result for anything you want (usually hostnames or usernames).</p>\n<p>Here\u2019s a stanza of output.  takes no option - just grep for what you want.</p>\n<pre><code>Shows most of the info shown from 'qhost -q' and 'qstat -s r' but in one\nline.  Also shows whether a node is over (+) or under(-) loaded.  At the end\nof each line is the status of all Qs that use this node.  Only compute nodes\nare shown in this output.\n           under/    CPUs           RAM        (Assigned/Total)\nHOSTNAME    over  USED/TOTAL     USED/TOTAL    Queue    v  [flags] users,jobs\ncompute-1-10    64.06 /  64      3.5G / 126.2G  free64(64/64) vturlo,64  tw(0/64) \ncompute-1-11    64.03 /  64      3.9G / 126.2G  free64(64/64) vturlo,64  tw(0/64) \ncompute-1-12  - 27.01 /  64      1.8G / 126.2G  free64(0/64)[S] tw(24/64) frankes,24  \ncompute-1-13  -  0.05 /  64      3.8G / 252.4G  \ncompute-1-14  -  0.53 /  24      7.2G /  94.7G  free24i(0/24)[S] gpu(3/24) staimour,2  yoshitom,1  \ncompute-1-2   -  3.99 /  64      3.9G / 252.4G  abio(0/64) free64(64/64) jfarran,61  vojh1,3  sf(0/64) \ncompute-1-3     64.04 /  64      6.2G / 252.4G  free64(64/64) meganjm1,64  \ncompute-1-4     64.07 /  64      4.2G / 252.4G  air(0/32) chem(0/32) free64(64/64) vturlo,64  \n</code></pre>\n<p>To run it, you\u2019ll also need <a href=\"http://moo.nac.uci.edu/~hjm/scut\" rel=\"nofollow noopener\">scut</a></p>",
        "<p>qstat by default tries for easy reading - and limits output to one line per, but there are several way to customize the output.  <code>$ man qstat</code> or<br>\n<a href=\"http://gridscheduler.sourceforge.net/htmlman/htmlman1/qstat.html\" class=\"onebox\" target=\"_blank\">http://gridscheduler.sourceforge.net/htmlman/htmlman1/qstat.html</a><br>\nhas number of options for outputs.</p>\n<p>In this case the <code>-g</code> flag might do the trick, add  <code>-g t</code>  and it will give the info one line per process/processor and a bit more info.</p>\n<p>For example if you want to keep a snapshot of this for later parsing:<br>\n<code>$ qstat -g t -u username &gt;&gt; myQstatOutput</code></p>\n<p>as explained by the man page</p>\n<blockquote>\n<p>With -g t parallel jobs are displayed verbosely in a one line per parallel job task fashion. By  default, parallel job tasks are displayed in a single line. Also with the -g t option, the function of each parallel task is displayed, rather than the jobs slot amount (see section OUTPUT FORMATS).</p>\n</blockquote>\n<p>** <strong>EDIT:</strong>  Additionally <code>qhost -j</code> will give you jobs by host set.<br>\nBoth can be select jobs by user name with the -u flag.</p>"
    ],
    "119": [
        "<p>We\u2019re looking into buying hardware optimized for running amber, what hardware or specifications should we be paying attention to?<br>\n<strong>CURATOR:</strong> jpessin1</p>",
        "<p>For local setups Amber\u2019s hardware pages <a href=\"http://ambermd.org/intel/index.htm\">http://ambermd.org/intel/index.htm</a> &amp;<br>\n<a href=\"http://ambermd.org/gpus/index.htm#supported_gpus\">http://ambermd.org/gpus/index.htm#supported_gpus </a> are a good start.</p>",
        "<p>Other considerations: in general it is recommended to run Amber on GPU-accelerated nodes, for best performance.  Should one have access to CPU-only nodes, suggestions are not to oversubscribe nodes; running one MPI task per core gives maximum performance (i.e., set ntasks-per-core=1). <strong>Curator:</strong> jpessin1</p>",
        "<p>The Amber GPU pages have been updated, <a href=\"http://ambermd.org/GPUSupport.php\" rel=\"nofollow noopener\">http://ambermd.org/GPUSupport.php</a>. Specific GPU hardware is at: <a href=\"http://ambermd.org/GPUHardware.php\" rel=\"nofollow noopener\">http://ambermd.org/GPUHardware.php</a>. Basically most nVIDIA GPUs are excellent, however if you go to relatively old GPUs, newer versions of Amber do not work. Definitely one would want the latest Amber, Amber18 for both CPU and GPU performance updates. Amber is one of the fastest MD codes on GPUs but does not scale terribly well across multiple GPUs unless you have NVLINK and definitely not at all across multiple nodes, on both the CPU and GPU. However, there are a variety of ensemble methods, such as replica exchange MD, that can very efficiently take advantage of multiple GPUs or CPUs. Finally, depending on your nVIDIA EULA adherence tolerance level, the commodity GPU cards-- such as the 1080TI-- perform really well. For more information, e-mail the Amber mailing list or peruse the archive on <a href=\"http://ambermd.org\" rel=\"nofollow noopener\">ambermd.org</a>. Note also that some of the XSEDE sights have GPU nodes, including bridges, comet, x-stream, and others.</p>"
    ],
    "266": [
        "<p>I am preparing to rebuild a compute cluster, and am deciding whether to go with a stateless or a stateful configuration for it.</p>\n<p>What are the relative benefits and drawbacks of each approach?</p>",
        "<p>Maybe these examples will help you.</p>\n<p>Here is a <strong>stateless</strong> installation on a compute node:</p>\n<pre><code class=\"lang-auto\">[root@compute-1-14 ~]# df -h\nFilesystem      Size  Used Avail Use% Mounted on\ntmpfs           3.9G  692M  3.3G  18% /\ndevtmpfs        3.9G     0  3.9G   0% /dev\ntmpfs           3.9G     0  3.9G   0% /dev/shm\ntmpfs           3.9G  8.9M  3.9G   1% /run\ntmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup\ntmpfs           797M     0  797M   0% /run/user/0\n10.2.1.1:/opt/ohpc/pub  1.9T   63G  1.8T   4% /opt/ohpc/pub\n</code></pre>\n<p>Here is a <strong>stateful</strong> installation on a compute node:</p>\n<pre><code class=\"lang-auto\">[root@compute-1-14 ~]# df -h\nFilesystem              Size  Used Avail Use% Mounted on\n/dev/sda3               147G  1.8G  138G   2% /\ndevtmpfs                3.9G     0  3.9G   0% /dev\ntmpfs                   3.9G     0  3.9G   0% /dev/shm\ntmpfs                   3.9G   17M  3.9G   1% /run\ntmpfs                   3.9G     0  3.9G   0% /sys/fs/cgroup\n/dev/sda1               463M   45M  395M  11% /boot\n10.2.1.1:/opt/ohpc/pub  1.9T   63G  1.8T   4% /opt/ohpc/pub\ntmpfs                   798M     0  798M   0% /run/user/0\n</code></pre>\n<p>As you see above, in the stateless case, the operating system doesn\u2019t use the local hard drives while in stateful case, the operating system is mounted on the local hard drive.<br>\nFrom the computing efficiency standpoint:</p>\n<p>If the compute node has a local disk memory to use:<br>\nIf for any application, there are temporary files to be written on a temporary location, or there are certain software packages to be installed locally on the node, the <strong>stateful</strong> case will be more efficient as it doesn\u2019t require reading/writing from a network-mounted device.</p>\n<p>On the other hand, if the compute node doesn\u2019t have local disk memory to use, <strong>stateless</strong> would be the best option.</p>\n<p>Arash</p>",
        "<p>I had to look up the terms stateless and stateful in the context of cluster computing. I think I\u2019m understanding that you mean diskless (on compute nodes), is that correct?</p>\n<p>If so, one of the advantage of having a disk drive in each compute node is the ability to use that local disk drive for local scratch per compute node, for temporary files that won\u2019t need to move to any global filesystem by the end of the run.</p>\n<p>We see only a modest number of users needing that \u2013 most don\u2019t produce much in the way of temporary files during a run \u2013 but our ATLAS high energy physics group uses the local drive all the time: they produce GB per run, but only retain MB at the end of the run.</p>",
        "<p>We just started using a stateless configuration on our system, and as the sysadmin, it has been very helpful to be able to reboot misbehaving nodes and have a completely fresh install of the compute node image handed out by the headnode. Our equipment is hand-me-down and has been temperamental so this saves me a lot of time and headaches.</p>"
    ],
    "858": [
        "<p>We are using our local campus cluster for research in our group. We have multiple students using it to run data analysis on top of shared datasets. During this we discovered issues. Despite the last major upgrade of the cluster Linux system from SL6 to SL7 there are still issues with what is available on the system and how it works. We have found:</p>\n<p>When I use scikit-learn with python3.6 module loaded, mkl.so and svx.so libraries are missing which prevent its use.</p>\n<p>It seems that there is no easy way of enabling/installing git LFS:</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/ff4f18962d6f6182cb8e833f6a8c2924efc37cdb.png\" class=\"site-icon\" width=\"48\" height=\"48\">\n      <a href=\"https://git-lfs.github.com/\" target=\"_blank\" rel=\"nofollow noopener\">Git Large File Storage</a>\n  </header>\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/362;\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/78c473616aba09fb9797613165c0fd9fd9ec5224.png\" class=\"thumbnail\"></div>\n\n<h3><a href=\"https://git-lfs.github.com/\" target=\"_blank\" rel=\"nofollow noopener\">Git Large File Storage</a></h3>\n\n<p>Git Large File Storage (LFS) replaces large files such as audio samples, videos, datasets, and graphics with text pointers inside Git, while storing the file contents on a remote server like GitHub.com or GitHub Enterprise.</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n\n<p>We are using it to distribute datasets. Is there a way for us to compile and install git LFS? And since it seems this could be used by a wider audience beyond just our group, what would be required to install it system wide on a shared campus cluster running SL7?</p>",
        "<p>I would be careful about advocating for Git LFS. If your cluster has a hosted service, great, but for the average user \u201cGit LFS\u201d means a free tier offered by one of GitHub, Bitbucket, GitLab. The free tiers not only place a limit on the upper file size, but also limit the total size and bandwidth that can be used. It can work for (small amounts) of large data, but in no way is a good suggestion for substantial datasets that we are likely to see with HPC. I\u2019ve had this opinion based on my own usage, and didn\u2019t stumble on an article that articulated the same concerns until today.</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/8c7390150cd0078e967a18c7663581b9b334d239.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://towardsdatascience.com/why-git-and-git-lfs-is-not-enough-to-solve-the-machine-learning-reproducibility-crisis-f733b49e96e8?gi=c8461d3b8681\" target=\"_blank\" title=\"10:05PM - 30 April 2019\" rel=\"nofollow noopener\">Towards Data Science \u2013 30 Apr 19</a>\n  </header>\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:573/500;\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/3067fc658baa81c9290467c303f38425847650c4.jpeg\" class=\"thumbnail\"></div>\n\n<h3><a href=\"https://towardsdatascience.com/why-git-and-git-lfs-is-not-enough-to-solve-the-machine-learning-reproducibility-crisis-f733b49e96e8?gi=c8461d3b8681\" target=\"_blank\" rel=\"nofollow noopener\">Why Git and Git-LFS is not enough to solve the Machine Learning...</a></h3>\n\n<p>Some claim the machine learning field is in a crisis due to software tooling that\u2019s insufficient to ensure repeatable processes. The\u2026</p>\n\n  <p><span class=\"label1\">Reading time: 13 min read</span>\n    </p>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "<p><a class=\"mention\" href=\"/u/aculich\">@aculich</a> this also seems like it\u2019s a minor issue with libraries, and you probably have a solution in mind - and were posting the question to share.  What did you learn?</p>"
    ],
    "259": [
        "<p>My GAMESS geometry optimization did not converge before my hitting my wall time limit.  Instead of restarting all the time, I would like to try and string together a series of optimizations together to increase my job throughput.</p>",
        "<p>Orbitals and coordinates from each geometry step during a GAMESS calculation are stored in the .dat file.  The most efficient way to string many calculations together is to script the reading of the $VEC and $DATA groups from the .dat file for restarts, and then placing a dependency hold on each job after the first.</p>\n<p>I would also recommend knowing how many geometry steps complete each 6 hours or so (depending on your scheduler queue resource limitations), so you can minimize the amount of wall time requested and maximize the number of jobs you have processed through the queue over the course of a week.</p>\n<p>Refer to the specific $VEC, $DATA, and method specific restart data (for example, coupled cluster has an option IREST in $CCINP for restart of the CC calculation step) for more information.</p>\n<p>As with all questions related to GAMESS, there are method specific keywords and options that may be relevant.  Please provide more details about your specific calculation if possible (e.g. chemical system, QM method)</p>"
    ],
    "662": [
        "<p>There is a long list of questions that are asking about something called GAMESS, for example:</p>\n<ul>\n<li><a href=\"https://ask.cyberinfrastructure.org/t/is-there-a-way-to-reduce-the-amount-of-disk-files-gamess-uses-or-even-run-the-calculations-entirely-in-ram/261\" class=\"inline-onebox\">Is there a way to reduce the amount of disk files GAMESS uses, or even run the calculations entirely in RAM?</a></li>\n<li><a href=\"https://ask.cyberinfrastructure.org/t/does-gamess-benefit-from-running-calculations-on-multiple-compute-nodes-if-so-what-methods-scale-the-best-across-many-compute-nodes-on-a-cluster/262\" class=\"inline-onebox\">Does GAMESS benefit from running calculations on multiple compute nodes? If so, what methods scale the best across many compute nodes on a cluster?</a></li>\n<li><a href=\"https://ask.cyberinfrastructure.org/t/how-many-mpi-ranks-should-i-request-for-a-gamess-calculation/260\" class=\"inline-onebox\">How many MPI ranks should I request for a GAMESS calculation?</a></li>\n<li><a href=\"https://ask.cyberinfrastructure.org/t/how-can-i-restart-my-gamess-calculation-and-resubmit/259\" class=\"inline-onebox\">How can I restart my GAMESS calculation and resubmit?</a></li>\n<li><a href=\"https://ask.cyberinfrastructure.org/t/how-can-i-determine-how-much-memory-i-need-before-submitting-my-gamess-calculation/258\" class=\"inline-onebox\">How can I determine how much memory I need before submitting my GAMESS calculation?</a></li>\n</ul>\n<p>Can anyone tell me what exactly GAMESS is? I\u2019d like to know a good definition, use cases in HPC, and alternatives to it. Thank you!</p>",
        "<p>GAMESS is a computational chemistry software package developed by Gordon research group at Iowa State University. This is the website of the project:</p>\n<p><a href=\"https://www.msg.chem.iastate.edu/gamess/\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://www.msg.chem.iastate.edu/gamess/</a></p>\n<p>It is written in Fortran, and it is capable of running massively parallel.</p>\n<p>This is the summary of the capabilities of the software, from the authors\u2019 website:</p>\n<blockquote>\n<p>GAMESS is a program for <em>ab initio</em> molecular quantum chemistry. Briefly, GAMESS can compute SCF wavefunctions ranging from RHF, ROHF, UHF, GVB, and MCSCF. Correlation corrections to these SCF wavefunctions include Configuration Interaction, second order perturbation Theory, and Coupled-Cluster approaches, as well as the Density Functional Theory approximation. Excited states can be computed by CI, EOM, or TD-DFT procedures. Nuclear gradients are available, for automatic geometry optimization, transition state searches, or reaction path following. Computation of the energy hessian permits prediction of vibrational frequencies, with IR or Raman intensities. Solvent effects may be modeled by the discrete Effective Fragment potentials, or continuum models such as the Polarizable Continuum Model. Numerous relativistic computations are available, including infinite order two component scalar relativity corrections, with various spin-orbit coupling options. The Fragment Molecular Orbital method permits use of many of these sophisticated treatments to be used on very large systems, by dividing the computation into small fragments. Nuclear wavefunctions can also be computed, in VSCF, or with explicit treatment of nuclear orbitals by the NEO code.</p>\n</blockquote>\n<p>It is distributed as source code, but not an open source project (i.e. no source code distribution to outside parties). You need to request access to the source code from the authors and get your request approved. Please see here for the full license terms:</p>\n<p><a href=\"https://www.msg.chem.iastate.edu/gamess/License_Agreement.html\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://www.msg.chem.iastate.edu/gamess/License_Agreement.html</a></p>",
        "<p><a class=\"mention\" href=\"/u/srpruitt\">@srpruitt</a> Can you please help us out with this one? Thank you!</p>",
        "<p>I haven\u2019t heard about this model (closed source with contact + permission) - what kind of LICENSE does it have?</p>"
    ],
    "276": [
        "<p>I have a set of jobs that dies without an error message - how can I tell if it is the job itself, the scheduler (I\u2019m on an SGE cluster), or both?</p>\n<p>If it is from the job how can I get more info for troubleshooting?</p>",
        "<p>This is a partial answer, covering SLURM job scheduler. When a job is killed due to time-out, it will have this kind of error message at (or near) the very last of the output file (stderr file, if you use <code>-e</code> option):</p>\n<pre><code>slurmstepd: error: *** JOB 8841014 ON coreV2-22-017 CANCELLED AT 2019-03-08T11:30:03 DUE TO TIME LIMIT ***\n</code></pre>\n<p>Here is an example job that will time out:</p>\n<pre><code>#!/bin/bash                                                                                                                                                                            \n# 20190308                                                                                                                                                                             \n# Test SLURM                                                                                                                                                                           \n# Demo for a job that will timeout                                                                                                                                                     \n\n# For 1 task                                                                                                                                                                           \n#SBATCH -n 1                                                                                                                                                                           \n\n# Job name                                                                                                                                                                             \n#SBATCH -J Timeout                                                                                                                                                                     \n#SBATCH -t 00:01:00                                                                                                                                                                    \n#SBATCH -o %x.o%j                                                                                                                                                                      \n## Additional switches may need to be specified on your system                                                                                                                         \n\necho \"Start date: $(date)\"\necho\necho \"Sleeping\"\nset -x\nsleep 10m\n</code></pre>\n<p>The output is:</p>\n<pre><code class=\"lang-nohighlight\">Start date: Fri Mar  8 11:28:49 EST 2019                                                                                                                                               \n\nSleeping                                                                                                                                                                               \n+ sleep 10m                                                                                                                                                                            \nslurmstepd: error: *** JOB 8841014 ON coreV2-22-017 CANCELLED AT 2019-03-08T11:30:03 DUE TO TIME LIMIT ***\n</code></pre>"
    ],
    "125": [
        "<p>What is the InCommon Federation and how can I use it to simplify authentication and access control for an HPC Cluster?</p>",
        "<p>InCommon is operated by Internet2 and provides a common framework for trusted shared management of access to online systems or services.  Their site provides ample background <a href=\"https://www.incommon.org/federation/basics.html\">https://www.incommon.org/federation/basics.html</a></p>\n<p>One important feature is that it gives end-users the ability to have SAML compliant single-sign-on (SSO) capabilities.  An end user could use their host institutional identity management provider to authenticate, and that trusted identity is sent the other online systems or services, without the need for locally managed identity.  Or, in short, you can login to remote sites with your local credentials.</p>\n<p>If you were to setup and allow InCommon connections to your own HPC service, you would no longer have to manage the authentication credentials of external users.  You would just manage the access that accounts could have via a linked local account.  So if they leave their institution, then they would also loose their access to your local HPC service.</p>",
        "<p>One means for enabling federated login for HPC resources is CI-Logon: <a href=\"https://www.cilogon.org/\" rel=\"nofollow noopener\">https://www.cilogon.org/</a> which provides the integration with SAML as well as attribute management through Internet2\u2019s COmanage software.</p>"
    ],
    "201": [
        "<p>I want to be able to list nodes in a slurm-managed cluster with specific features - how many cores, which processor, how much memory, does it have gpu, what are the available features. How do I do that?</p>\n<p><strong>CURATOR</strong>: Kristina Plazonic KrisP</p>",
        "<p><strong>ANSWER:</strong> Short answer is the following:</p>\n<pre><code>sinfo -o \"%20N  %10c  %10m  %25f  %10G \"\n</code></pre>\n<p>You can see the options of <code>sinfo</code> by doing <code>sinfo --help</code>. In particular <code>sinfo -o</code> specifies the format of the output, and the options above are short for</p>\n<ul>\n<li>\n<code>N</code> = node name</li>\n<li>\n<code>c</code> = number of cores</li>\n<li>\n<code>m</code> = memory</li>\n<li>\n<code>f</code>  = features, often it will be the architecture or type of associated gpu</li>\n<li>\n<code>G</code> = gres type and number, e.g. <code>gpu:2</code>\n</li>\n</ul>\n<p>The <code>%20</code> means 20 characters for this field. For example, for easy import to a Confluence page, you would want to separate fields with <code>|</code>, and so your command would be<br>\nsinfo -o \u201c|%20N | %10c | %10m | %25f | %10G|\u201d</p>",
        "<p>+1! And here is an example of the output above:</p>\n<pre><code>$ sinfo -o \"%20N  %10c  %10m  %25f  %10G \"\nNODELIST              CPUS        MEMORY      AVAIL_FEATURES             GRES       \nsh-01-[01-36],sh-02-  16          64000+      CPU_GEN:IVB,CPU_SKU:E5-26  (null)     \nsh-03-01,sh-07-[25-3  16          64000+      CPU_GEN:HSW,CPU_SKU:E5-26  (null)     \nsh-101-[01-58,61-72]  20          128000+     CPU_GEN:BDW,CPU_SKU:E5-26  (null)     \nsh-112-01             56          3072000     CPU_GEN:BDW,CPU_SKU:E5-46  (null)     \nsh-02-[13-14]         32          1536000     CPU_GEN:SNB,CPU_SKU:E5-46  (null)     \nsh-112-[02-03],sh-11  32          512000+     CPU_GEN:BDW,CPU_SKU:E5-26  (null)     \nsh-09-[03-05],sh-13-  16          64000+      CPU_GEN:IVB,CPU_SKU:E5-26  gpu:8      \nsh-112-[04,06-07],sh  20          256000+     CPU_GEN:BDW,CPU_SKU:E5-26  gpu:4      \nsh-113-[12-14],sh-11  20          256000      CPU_GEN:BDW,CPU_SKU:E5-26  gpu:4      \nsh-09-[01-02]         16          256000      CPU_GEN:IVB,CPU_SKU:E5-26  gpu:8      \nsh-112-05,sh-113-08   20          256000      CPU_GEN:BDW,CPU_SKU:E5-26  gpu:4      \nsh-17-29,sh-27-[21,3  16          128000+     CPU_GEN:HSW,CPU_SKU:E5-26  gpu:8      \nsh-103-[25-36],sh-10  24          191000+     CPU_GEN:SKX,CPU_SKU:5118,  (null)     \nsh-09-[07-10]         16          64000       CPU_GEN:IVB,CPU_SKU:E5-26  gpu:4      \nsh-15-[01-08],sh-16-  16          128000+     CPU_GEN:IVB,CPU_SKU:E5-26  gpu:8      \nsh-17-12,sh-25-23     48          1536000     CPU_GEN:HSW,CPU_SKU:E7-48  (null)     \nsh-17-[23-28]         32          256000      CPU_GEN:HSW,CPU_SKU:E5-26  (null)     \nsh-28-10              20          256000      CPU_GEN:HSW,CPU_SKU:E5-26  (null)     \nsh-112-[08-12],sh-11  20          128000+     CPU_GEN:BDW,CPU_SKU:E5-26  gpu:4      \nsh-112-[13-17],sh-11  20          256000+     CPU_GEN:BDW,CPU_SKU:E5-26  gpu:8      \nsh-114-[01-04]        20          256000      CPU_GEN:BDW,CPU_SKU:E5-26  gpu:4      \nsh-15-[09-10],sh-19-  16          128000      CPU_GEN:HSW,CPU_SKU:E5-26  gpu:8      \nsh-18-[01-10]         24          96000       CPU_GEN:HSW,CPU_SKU:E5-26  (null)     \nsh-18-11              28          128000      CPU_GEN:HSW,CPU_SKU:E5-26  (null) \n</code></pre>\n<p>If you want to do a custom format, take a look at the formatting <a href=\"https://slurm.schedmd.com/sinfo.html#SECTION_EXAMPLES\">examples and options</a> for sinfo on this page.</p>\n<p>One thing I always had a hard time with (and I don\u2019t have a good answer beyond looking at cluster-specific documentation) is \u201cWhat in the heck do the features actually mean?\u201d The best I could find is to poke around and look at the slurm configurtation file at /etc/slurm/slurm.conf. I think it\u2019s non standard (and not found across clusters) because our cluster admin is a badass. but it helped explain the feature listed by sinfo.</p>\n<pre><code># -- Nodes --------------------------------------------------------------------\n\n# &gt;&gt; Nodes features\n#\n# -- CPU features\n#   * CPU_GEN: CPU generation: SNB|IVB|HSW|BDW|SKX|CNL\n#   * CPU_SKU: CPU model     : E5-2640v2\n#   * CPU_FRQ: CPU frequency : 2.60GHz\n#\n# -- GPU features\n#   * GPU_GEN: GPU generation: KPL|MXW|PSC|VLT\n#   * GPU_BRD: GPU brand     : GEFORCE|TESLA\n#   * GPU_SKU: GPU model     : TITAN_{BLACK,X,Xp}|TESLA_{K{20,80},P40,P100}\n#   * GPU_MEM: GPU memory    : 8GB\n#   * GPU_CC:  GPU Compute Capability : 3.5|3.7|6.1\n\n# &gt;&gt; Weights\n#\n# * Nodes with lower weight will be selected first.\n# * Nodes with more memory or GRES are given a higher weight, so they're\n#   selected last and saved for jobs that really need it\n# * Nodes with more recent CPU generation will be selected first to give the\n#   best performance\n#\n#   Weight mask: 1 | #GRES | Memory | #Cores | CPUgen | 1\n#       prefix is to avoid octal conversion\n#       suffix is to avoid having null weights\n#\n#   Values:\n#       #GRES   none: 0   Memory   64 GB: 0   #Cores  16: 0  CPUgen  ???: 3\n#              1 GPU: 1            96 GB: 1           20: 1          CNL: 4\n#              2 GPU: 2           128 GB: 2           24: 2          SKX: 5\n#              3 GPU: 3           192 GB: 3           28: 3          BDW: 6\n#              4 GPU: 4           256 GB: 4           32: 4          HSW: 7\n#              6 GPU: 5           384 GB: 5           48: 5          IVB: 8\n#              8 GPU: 6           512 GB: 6           56: 6          SNB: 9\n#             10 GPU: 7          1024 GB: 7\n#             16 GPU: 8          1534 GB: 8\n#                                3072 GB: 9\n</code></pre>\n<p>All that said, knowing that \u201cHSU\u201d is a kind of CPU generation doesn\u2019t really help me much. I would never know how or when it is appropriate to ask for these features. Does anyone else have thoughts on this?</p>"
    ],
    "950": [
        "<p>We have static documentation for our Group on GitHub Pages, and it\u2019s a known fact that even private repos produce static content that is public:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/684de2ead4df4449ea27c65ceca1442da329169b.png\" data-download-href=\"https://ask.cyberinfrastructure.org/uploads/default/684de2ead4df4449ea27c65ceca1442da329169b\" title=\"image.png\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/684de2ead4df4449ea27c65ceca1442da329169b_2_690x136.png\" alt=\"image\" width=\"690\" height=\"136\" srcset=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/684de2ead4df4449ea27c65ceca1442da329169b_2_690x136.png, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/684de2ead4df4449ea27c65ceca1442da329169b_2_1035x204.png 1.5x, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/684de2ead4df4449ea27c65ceca1442da329169b_2_1380x272.png 2x\" data-small-upload=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/684de2ead4df4449ea27c65ceca1442da329169b_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">image.png</span><span class=\"informations\">1386\u00d7274 28.2 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>I\u2019m curious what kinds of strategies other groups have used to authenticate an entire, or part of, a private repo? For our use case, we would ideally want SAML (single sign on) sort of deal.</p>\n<p>It looks like there is something called <a href=\"https://github.com/benbalter/jekyll-auth\" rel=\"nofollow noopener\">jekyll-auth</a> that we could use for (some kind of auth) but the dependency is building with Heroku (which we don\u2019t do).</p>",
        "<p>Here is an <a href=\"http://kinlane.com/2013/10/15/securing-site-that-runs-on-github-pages-with-json-backend-in-private-repository/\" rel=\"nofollow noopener\">example</a> using GitHub credentials, grabbing the content from a private repository, which would work if we didn\u2019t want to use SAML (which we do).</p>",
        "<p>It seems to me like however you try to do this, you\u2019ll end up having to host <em>something</em> behind the authentication regime you want \u2013 and if that\u2019s SAML, that implies at least a slightly sophisticated backend, I think?</p>\n<p>In such a situation, you might not be gaining anything from involving GitHub Pages at all.</p>",
        "<p><a class=\"mention\" href=\"/u/iki\">@iki</a> this is a good point! The benefits of having docs on GitHub come down to community contribution. Within our group, if the docs are hosted on a private server, it might still be a bit of a hassle to get access to change them. Having them on GitHub means that if I\u2019m a user or a member of the hosting group and I see something missing or off, I can open an issue or pull request. Or I can ask a question! This is possible to do given a custom deployment (to an external server) but it\u2019s much easier to just push to the master branch and have it magically appear on GitHub pages  <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<p>So - what about a server existing solely for the SAML auth bit? Do you think that could be possible (and if you have an idea how, please share!)</p>",
        "<p>It would definitely be worth a try, because we don\u2019t have a solution at the moment! If the repo is public, then the docs are freely browsable via GitHub? What does the Shibboleth protect?</p>\n<p>I would love to take a look at what you have set up, and see if we can customize it for the private case. The one issue that comes to mind (given a private repo) is that if a user wants to contribute, he/she couldn\u2019t easily open a PR. But I wonder if it comes down to git pulls anyway, if there could be a public and private repo that are served alongside one another?</p>",
        "<p>I thought about this a bit, but I can\u2019t think of a reasonable way to do this that keeps the documentation strictly within GitHub Pages.</p>\n<p>We have our (new, still under construction) documentation in a normal public repo (<a href=\"https://github.com/UCL-RITS/mkdocs-rc-docs\" rel=\"nofollow noopener\">https://github.com/UCL-RITS/mkdocs-rc-docs</a>) and deployed automatically via a simple cronjob running a slightly fancier version of <code>git pull</code> on an Apache server. Would this sort of option, with a private repo, Deploy Keys, and a standard Apache Shibboleth setup, work for you? It\u2019s significantly more complex, but I\u2019m not seeing any sensible ways to make it simpler while maintaining the SAML component.</p>"
    ],
    "814": [
        "<p>If I\u2019m interested in being a research software engineer (RSE) in the United States, and I want a team to work with and learn from on challenging problems, what universities or national labs could offer me this, along with a reasonably competitive salary?</p>",
        "<p>The number of dedicated groups of RSEs are growing at both national labs and universities.  Here\u2019s a partial list of organizations with RSEs: <a href=\"https://us-rse.org/rse-groups/\" rel=\"nofollow noopener\">https://us-rse.org/rse-groups/</a>.</p>",
        "<p><a class=\"mention\" href=\"/u/iancosden\">@IanCosden</a> this is a great resource! Thank you, and welcome to the AskCI community! <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/smiley.png?v=9\" title=\":smiley:\" class=\"emoji\" alt=\":smiley:\"></p>",
        "<p>Princeton University has a growing <a href=\"https://researchcomputing.princeton.edu/software-engineering\" rel=\"nofollow noopener\">Research Software Engineering Group</a> that works across disciplines. They are a very collaborative group of talented people. They are currently looking to fill a couple of positions:</p>\n<ul>\n<li><a href=\"https://main-princeton.icims.com/jobs/9378/research-software-engineer/job\" rel=\"nofollow noopener\">Research Software Engineer in Politics and Sociology</a></li>\n<li><a href=\"https://main-princeton.icims.com/jobs/9275/research-software-engineer/job\" rel=\"nofollow noopener\">Research Software Engineer in Molecular Biology</a></li>\n</ul>"
    ],
    "149": [
        "<p>I have several hundred small jobs to run on a shared system with a queue scheduler.<br>\nWhat are the relevant factors to optimize for highest throughput?</p>\n<p><strong>CURATOR: John Goodhue</strong></p>",
        "<p>For shared systems with a range of usage type, highest throughput generally comes from having fewer, and more easily met job requirements.  Generally this means asking for as few cores as possible (ideally 1), with as little memory as possible.</p>\n<p>Array jobs are usually great for managing this (see the instructions of the specific batch scheduler for details).</p>\n<p>If the job requirements are very divergent, say for example the memory requirements range from 100MB to 10GB, and this is determinable from the input files, it may help to batch them in smaller groups by range.</p>\n<p>Note that pushing these limits is often not considered \u2018good\u2019 use of the resource, there is a point at which the time and resources used to start and end the job become a major part of the usage, reducing the overall efficiency of the machine etc.  A common compromise is to batch the jobs, so while they still request minimal resources several run sequentially within a task.</p>"
    ],
    "207": [
        "<p>I am trying to install R package SAIGE in my home directory on the cluster and I am getting an error:<br>\n/lib64/libc.so.6: version not found. I have no problem installing this package on my desktop computer. What do I do wrong?</p>",
        "<p>Is this the precise error you are getting - it is always best to copy the relevant text here - but it sounds as if you are trying to install a precompiled/binary R package (as opposed to compiling it from source) and that it was compiled on an operating system that is newer then what the cluster is running. If so you should compile it from source. This is almost always achieved with <code>install.packages()</code> command in R.</p>\n<p>The SAIGE installation instructions say<br>\n<code>R CMD INSTALL SAIGE_0.XX_R_x86_64-pc-linux-gnu.tar.gz</code><br>\nbut that means that the binary provided in the tarball is tied to the architecture of the machine on which the binary was build before packaging.</p>\n<p>NOTE: I will expand upon this answer when I get more time.</p>",
        "<p>This problem often occurs, when this package is being installed using binaries into Linux  environment running Centos6. The source code for this package is not available. There is some work around possible - like installing it within a container (i.e. singularity with Centos7) if it is available on the system.</p>"
    ],
    "838": [
        "<p>I\u2019m applying for an NSF grant, which I haven\u2019t done in some time.  I\u2019m aware that data management plans are now required by most funding agencies, and have found the relevant section of the PAPPG (PAPPG Chapter II.C.2.j) that outlines DMP policy and expected content.  The program under which my work falls has additional requirements, stating in summary:</p>\n<p>\u2018[The data] must be deposited in a national, public data repository that publishes its contents to a higher-level data aggregator that facilitates data discovery, which should be registered with an international body that promotes best practices in data archiving and curation.\u2019  The description suggests <a href=\"http://www.re3data.org\" rel=\"nofollow noopener\">www.re3data.org</a> as the international body, and also offers some specific repositories.  It also gives <a href=\"http://www.dataone.org\" rel=\"nofollow noopener\">www.dataone.org</a> as an aggregator.</p>\n<p>While all of these inclusions are helpful, it\u2019s not clear if any of them provide all mandated services and meet all mandated requirements.  Does anyone have experience in a similar context?  Does anyone know of a repository that meets all of the described demands?</p>",
        "<p>I\u2019ve found the requirements you mentioned in this solicitation: <a href=\"https://www.nsf.gov/pubs/2019/nsf19528/nsf19528.htm\" rel=\"nofollow noopener\">https://www.nsf.gov/pubs/2019/nsf19528/nsf19528.htm</a></p>\n<p>The repositories specifically mentioned in this solicitation may or may not take your specific data, as each one (i.e., ICPSR &amp; Arctic Data Center) only collects certain types of research data.</p>\n<p>One repository that fits the requirements is Dataverse (hosted at Harvard - free to use by anyone - general public, all purpose repository). Dataverse gives all public datasets a DOI. The metadata for each dataset is sent to DataCite - \u201ca high-level aggregator that facilitates discovery\u201d.</p>\n<p>It is registered with <a href=\"http://re3data.org\" rel=\"nofollow noopener\">re3data.org</a>: <a href=\"https://www.re3data.org/repository/r3d100010051\" rel=\"nofollow noopener\">https://www.re3data.org/repository/r3d100010051</a></p>",
        "<p>This is really interesting and the first time I\u2019ve seen this specific requirement.  Could you share the program?  An appropriate repository will be dependent on the specific field and type of data you\u2019re collecting.</p>\n<p>I\u2019d argue that any repository that is listed in <a href=\"http://re3data.org\" rel=\"nofollow noopener\">re3data.org</a> and mints DataCite DOIs (this sub-search <a href=\"https://www.re3data.org/search?query=&amp;pidSystems%5B%5D=DOI\" rel=\"nofollow noopener\">https://www.re3data.org/search?query=&amp;pidSystems[]=DOI</a> ) or is a member of DataOne would qualify.</p>",
        "<p>It\u2019s a CNH2 grant: FOA 19528.<br>\nThank you for your replies!</p>"
    ],
    "33": [
        "<p>What tools are available on HPC clusters to help manage a large number of very small independent jobs (a few seconds each) of varying length and with some order dependencies as a single workflow?</p>\n<p><strong>CURATOR:</strong> Jack Smith</p>",
        "<p><strong>ANSWER:</strong> What you are looking for is something called a \u201cPilot Job\u201d.  It\u2019s like a scheduler within a scheduler, where you submit a single batch job that requests (reserves) a fixed set of resources (max cores, max cputime, etc.) like any other batch job, but then that job spawns smaller jobs from within to make the best use of resources it has reserved.  It\u2019s also sometimes called a \u201cBig Job\u201d.</p>\n<p>One tool for managing such pilot jobs is RADICAL Pilot (<a href=\"http://radical-cybertools.github.io/radical-pilot/index.html\">http://radical-cybertools.github.io/radical-pilot/index.html</a>) from the the RADICAL group at Rutgers.  It\u2019s based on SAGA (Simple APIs for Grid Applications), also developed by the RADICAL GROUP, which is a Python framework capable of spawning and managing multiple tasks (from single-threaded to MPI) with conditional workflows and staging of data between tasks.</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>There are several ways to manage interjob dependencies there are many tool kits like RADICAL mentioned by Jacks9. Or drmaa.</p>\n<p>Sometimes the answer is just to launch a batch job from within a job. In the top job you can have a script that will run a job-array, wait for it to finish, then run the next job-array.</p>"
    ],
    "205": [
        "<p>I asked our System Administrator to install Docker so I could run some containers I downloaded from the web. However, I was told that it is not secure to install Docker on our cluster. What is the problem with it and is there any alternative?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p>Docker containers need root privileges for full functionality which is not suitable for a shared HPC environment.<br>\nSingularity is a container solution for HPC and it allows working with containers as a regular user. Docker containers may be imported to run via Singularity. Visit <a href=\"https://singularity.lbl.gov/docs-docker\">https://singularity.lbl.gov/docs-docker</a> to create a singularity image from the docker container. You should talk to your system admin to install singularity on compute nodes.</p>",
        "<p>A slight elaboration on Raminder\u2019s answer: while a Docker container requires root access to create and deploy, Singularity needs root privileges for installation but containers can be created without root access.  A Singularity user is at the same level inside and outside of a Singularity container.</p>",
        "<p>In addition to ave responses, Singularity also runs within the same PID thread, meaning, containers will run as the user, within the confines of the resource manager\u2019s purview, and compatible with MPI and GPUs.</p>"
    ],
    "857": [
        "<p>We have our own small research group small cluster called groupcluster, but we have also begun using the main shared campus cluster. Sometimes we ssh into our groupcluster from the campus cluster, but we also want to use github from the campus cluster.</p>\n<p>Yesterday I set up ssh keys for github by placing the private key in my <code>~/.ssh</code> folder under the name <code>id_rsa</code>. I sent the public key, <code>~/.ssh/id_rsa.pub</code> to github. Everything worked fine then. Today after logging into the campus cluster when I tried to pull from git I got a \u201cPermission denied (publickey) error.\u201d After viewing the ssh log with the <code>-v</code> option I noticed ssh was using the groupcluster keys so I sent <code>~/.ssh/groupcluster.pub</code> over to github and now it seems to be working.</p>\n<p>The question is this\u2026</p>\n<p>What is the correct procedure for setting ssh keys up to interface with github and servers outside of the campus cluster?</p>",
        "<p>I would recommend a separate key pair for every machine you use to connect to Github - that makes it unnecessary to copy private keys between machines. So it sounds to me like you\u2019ve set everything up properly, except it\u2019s a bit odd that your groupcluster key is actually called groupcluster.pub. I would have expected a separate id_rsa and id_rsa.pub on each machine.</p>"
    ],
    "851": [
        "<p>There has been a lot of excitement around the first picture of a black hole (and rightfully so!) and I\u2019ve been trying to nail down the specifics of the compute infrastructure that was used (e.g., HPC? Machines? How much memory?) There was a mention of the amount of data used (in the Terabytes, I believe) but I couldn\u2019t find any spec for how it was processed, and where. I can imagine given all the GUI and image processing needed, maybe they did it on local machines and waited it out. However, I can also imagine there was a lot of computation needed to generate the image, which would do well on a supercomputer.</p>\n<p>I did find this post on reddit with a link to all the papers: <a href=\"https://www.reddit.com/r/HPC/comments/bcndgt/imaging_a_blackhole/\" rel=\"nofollow noopener\">https://www.reddit.com/r/HPC/comments/bcndgt/imaging_a_blackhole/</a>, and notably, the third link talks about the data pipelines.</p>\n<p>If anyone has a hint, or knows someone out there that could answer this question, the nerdlings of AskCI want to know!</p>",
        "<p>Hey V,</p>\n<p>here is the link to one of the codes used on GitHub (<a href=\"https://github.com/achael/eht-imaging\" rel=\"nofollow noopener\">https://github.com/achael/eht-imaging</a>), which also includes all kinds of references, maybe something is hidden in there.</p>\n<p>In news articles they mention that they had 5 Petabytes of Raw data (1,000 pounds), which was transported using planes to two locations, one in Germany and one in  Massachusetts (<a href=\"https://www.inverse.com/article/54833-m87-black-hole-photo-data-storage-feat\" rel=\"nofollow noopener\">https://www.inverse.com/article/54833-m87-black-hole-photo-data-storage-feat</a> and <a href=\"https://motherboard.vice.com/en_us/article/597m7q/reddits-data-hoarders-are-freaking-out-over-all-that-black-hole-data\" rel=\"nofollow noopener\">https://motherboard.vice.com/en_us/article/597m7q/reddits-data-hoarders-are-freaking-out-over-all-that-black-hole-data</a>). They even had to wait for summer to get some drives from the South Pole.</p>\n<p>As far as I understand it, they needed to do a lot of simulations to train their algorithms. According to the first article above some of this preprocessing was done on GPU resources of University of Arizona.</p>\n<p>There is also a TED talk explaining the general idea: <a href=\"https://www.ted.com/talks/katie_bouman_what_does_a_black_hole_look_like#t-708480\" rel=\"nofollow noopener\">https://www.ted.com/talks/katie_bouman_what_does_a_black_hole_look_like#t-708480</a></p>\n<p>Best,<br>\nRichard</p>",
        "<p>Hi Vanessa<br>\nTo elaborate on Richard\u2019s point, one of our clusters at the University of Arizona was obtained through an NSF MRI grant and was used partly for simulating black holes, particularly Sagittarius A*, the one at the middle of the Milky Way galaxy (ours).  Their simulated images are remarkably similar to the published image we saw.<br>\nI spoke recently to Junhan Kim who spent his last three Arizona winters in the balmy Antarctic summer (it was still warmer in Arizona) running the telescope and collecting data.<br>\nChris</p>",
        "<p>Thanks <a class=\"mention\" href=\"/u/rberger\">@rberger</a>! I got a helpful response on Reddit too (the original post I linked) and I\u2019ll summarize here:</p>\n<ul>\n<li>Details of correlators are in paper II: 1000 cores with 25Gbps connectors.</li>\n<li>Supercomputers are mentioned in paper III: including the following direct quote:</li>\n</ul>\n<blockquote>\n<p>the simulations were performed in part on the SuperMUC cluster at the LRZ in Garching, on the LOEWE cluster in CSC in Frankfurt, and on the HazelHen cluster at the HLRS in Stuttgart.</p>\n</blockquote>\n<p>Wow, 1,000 pounds\u2026 of data. I need a few minutes to really take that in.</p>",
        "<p>That sounds like an amazing story <a class=\"mention\" href=\"/u/chrisreidy\">@Chrisreidy</a> - there are some amazing stories in there! Maybe we could hear them some day?</p>",
        "<p>Also just for posterity and record - there were a <em>ton</em> of open source projects that helped with the project, there is more discussion here on Twitter:</p>\n<aside class=\"onebox twitterstatus\">\n  <header class=\"source\">\n      <a href=\"https://twitter.com/matplotlib/status/1116477991763218432\" target=\"_blank\" rel=\"nofollow noopener\">twitter.com</a>\n  </header>\n  <article class=\"onebox-body\">\n    <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/ff36ad6c555cd1518e3a5abf1976e7f4431b5a85.jpeg\" class=\"thumbnail onebox-avatar\" width=\"240\" height=\"240\">\n<h4>\n  <a href=\"https://twitter.com/matplotlib/status/1116477991763218432\" target=\"_blank\" rel=\"nofollow noopener\">\n    Matplotlib (matplotlib)\n  </a>\n</h4>\n\n<div class=\"tweet\">Congrats! As many people have noted, the image was processed with the help of matplotlib and many other Python libraries helpfully cited in the paper (https://t.co/iUvfDYdNUI) https://t.co/PtV6uWFdfE</div>\n\n<div class=\"date\">\n  <a href=\"https://twitter.com/matplotlib/status/1116477991763218432\" target=\"_blank\" rel=\"nofollow noopener\">4:07 PM - 11 Apr 2019</a>\n    <span class=\"like\">\n      <svg viewbox=\"0 0 512 512\" width=\"14px\" height=\"16px\" aria-hidden=\"true\">\n        <path d=\"M462.3 62.6C407.5 15.9 326 24.3 275.7 76.2L256 96.5l-19.7-20.3C186.1 24.3 104.5 15.9 49.7 62.6c-62.8 53.6-66.1 149.8-9.9 207.9l193.5 199.8c12.5 12.9 32.8 12.9 45.3 0l193.5-199.8c56.3-58.1 53-154.3-9.8-207.9z\"></path>\n      </svg> 1.6K\n    </span>\n    <span class=\"retweet\">\n      <svg viewbox=\"0 0 640 512\" width=\"14px\" height=\"16px\" aria-hidden=\"true\">\n        <path d=\"M629.657 343.598L528.971 444.284c-9.373 9.372-24.568 9.372-33.941 0L394.343 343.598c-9.373-9.373-9.373-24.569 0-33.941l10.823-10.823c9.562-9.562 25.133-9.34 34.419.492L480 342.118V160H292.451a24.005 24.005 0 0 1-16.971-7.029l-16-16C244.361 121.851 255.069 96 276.451 96H520c13.255 0 24 10.745 24 24v222.118l40.416-42.792c9.285-9.831 24.856-10.054 34.419-.492l10.823 10.823c9.372 9.372 9.372 24.569-.001 33.941zm-265.138 15.431A23.999 23.999 0 0 0 347.548 352H160V169.881l40.416 42.792c9.286 9.831 24.856 10.054 34.419.491l10.822-10.822c9.373-9.373 9.373-24.569 0-33.941L144.971 67.716c-9.373-9.373-24.569-9.373-33.941 0L10.343 168.402c-9.373 9.373-9.373 24.569 0 33.941l10.822 10.822c9.562 9.562 25.133 9.34 34.419-.491L96 169.881V392c0 13.255 10.745 24 24 24h243.549c21.382 0 32.09-25.851 16.971-40.971l-16.001-16z\"></path>\n      </svg> 347\n    </span>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "<p>I found another good link on the TACC site about how Stampede and Jetstream contributed! <a href=\"https://www.tacc.utexas.edu/-/peeling-back-the-darkness-of-m87\" rel=\"nofollow noopener\">https://www.tacc.utexas.edu/-/peeling-back-the-darkness-of-m87</a></p>"
    ],
    "1072": [
        "<p>I was wondering how others go about using a server for only file transfer purposes such as rsync, scp, and sftp? I see that bridges at PSC does this (<a href=\"https://www.psc.edu/bridges/user-guide/transferring-files\" rel=\"nofollow noopener\">https://www.psc.edu/bridges/user-guide/transferring-files</a>). If you try to ssh to the server, you get a message stating that this is only to be used for file transfer purposes.</p>\n<p>I saw a couple of options such as rssh, but that seems like it is not maintained anymore and could be a security risk. Another option is to use a sftp jail, but I don\u2019t believe that allows you to use rsync and it still allows you to ssh, but just restricting what directories you see.</p>",
        "<p>There is a package called <code>scponly</code> that we have used quite successfully over the last six years.</p>\n<pre><code class=\"lang-auto\">Available Packages\nscponly.x86_64                          4.8-18.el7                          epel\n</code></pre>\n<p>We install that on separate data transfer nodes, and for those nodes only enable password-less, ssh key transfers so that tasks can be automated.</p>\n<p>Since it is ssh/scp under the hood, anything that uses ssh should work with it.  The shell is modified to</p>\n<pre><code class=\"lang-auto\"> username:x:123456:123456:User Name:/home/username:/usr/bin/scponly\n</code></pre>\n<p>so you need something that will convert login shell to the <code>scponly</code> shell for users at or above your minimum, end-user UID on the machines that would offer it.</p>",
        "<p>Thank you. I went with this option even though it seems to be a stale project, but maybe that is just because it has very few security implications.</p>\n<p>For others that may came across this. We are using SSSD for authentication and added the following line to the [nss] section to make sure everybody is using the scponly shell.</p>\n<p>override_shell = /usr/local/bin/scponly</p>",
        "<p>The SSH option ForceCommand can also be used for this without needing additional software. It is built into the SSH daemon, configurable in sshd_config. You can even allow some users to get a shell and prevent others using SSH\u2019s Match command. See <a href=\"https://www.digitalocean.com/community/tutorials/how-to-enable-sftp-without-shell-access-on-ubuntu-16-04\" rel=\"nofollow noopener\">https://www.digitalocean.com/community/tutorials/how-to-enable-sftp-without-shell-access-on-ubuntu-16-04</a> for more details.</p>"
    ],
    "209": [
        "<p>I am an expert user of a cluster with a Sun Grid Engine Scheduler and need to use a cluster with a SLURM Scheduler.  Can someone help me get started by translating the following simple examples from SGE to SLURM?</p>\n<p>What Jobs are currently running?<br>\n<code>qstat</code></p>\n<p>What Jobs am I currently running?<br>\n<code>qstat -u username</code></p>\n<p>Launch an interactive session on one node with 16 cores:<br>\n<code>qrsh -pe omp 16</code></p>\n<p>Launch a batch job one node with 16 cores:<br>\n<code>qsub -pe omp 16 script.sh</code></p>\n<p>Cancel a batch job<br>\n<code>qdel -j jobID</code></p>\n<p>Cancel all my jobs<br>\n<code>qdel -u username</code></p>\n<p><strong>CURATOR:</strong> John Goodhue</p>",
        "<p><strong>ANSWER:</strong><br>\nHere are equivalents to the commands you listed.</p>\n<p>What Jobs are currently running?<br>\n<code>squeue -a</code></p>\n<p>What Jobs am I currently running?<br>\n<code>squeue -u &lt;username&gt;</code></p>\n<p>Launch an interactive session on one node in the default queue, with 16 cores and exclusive use of the node:<br>\n<code>salloc -N 1 -n 16 -p defq --time=1:00:00 --exclusive</code></p>\n<p>Launch a batch job:<br>\n<code>sbatch &lt;scriptname&gt;.slurm</code></p>\n<p>Example batch file with directives that reserve one node in the default queue, with 16 cores and exclusive use of the node:<br>\n<code>#!/bin/bash</code><br>\n<code>#SBATCH -N 1</code><br>\n<code>#SBATCH -n 16</code><br>\n<code>#SBATCH --time=1:00:00</code><br>\n<code>#SBATCH --exclusive</code><br>\n<code>&lt;&lt;shell commands that set up and run the job&gt;&gt;</code></p>\n<p>Cancel a batch job<br>\n<code>scancel &lt;jobid&gt;</code></p>\n<p>For a more comprehensive look, here are links to three SGE-&gt;SLURM translation tables:<br>\n<a href=\"https://srcc.stanford.edu/sge-slurm-conversion\" class=\"onebox\" target=\"_blank\">https://srcc.stanford.edu/sge-slurm-conversion</a><br>\n<a href=\"http://www.mpcdf.mpg.de/services/computing/linux/migration-from-sge-to-slurm\" class=\"onebox\" target=\"_blank\">http://www.mpcdf.mpg.de/services/computing/linux/migration-from-sge-to-slurm</a><br>\n<aside class=\"onebox pdf\">\n  <header class=\"source\">\n      <a href=\"https://slurm.schedmd.com/rosetta.pdf\" target=\"_blank\">slurm.schedmd.com</a>\n  </header>\n  <article class=\"onebox-body\">\n    <a href=\"https://slurm.schedmd.com/rosetta.pdf\" target=\"_blank\"><span class=\"pdf-onebox-logo\"></span></a>\n<h3><a href=\"https://slurm.schedmd.com/rosetta.pdf\" target=\"_blank\">rosetta.pdf</a></h3>\n\n<p class=\"filesize\">148.17 KB</p>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>",
        "<p><strong>COMMENT-JG:</strong> content from this answer was folded into the answer above.</p>",
        "<p><strong>COMMENT-JG:</strong> content from this comment was folded into the answer above.</p>"
    ],
    "927": [
        "<p>I\u2019m interesting in getting access to resources, and you can assume my institution doesn\u2019t have anything local. I heard of something called XSEDE, and I\u2019m wondering if this could offer me (or a general student, researcher) what I\u2019m looking for?</p>",
        "<p>This answer comes by way of the XSEDE mailing list, and the question was so perfectly answered that I wanted to share it here.</p>\n<hr>\n<p>Did you know that XSEDE offers much more than access to supercomputers?</p>\n<p>In addition to connecting researchers with computational resources, XSEDE provides a variety of <a href=\"https://www.xsede.org/for-users/training\" rel=\"nofollow noopener\">trainings</a>, chances to <a>collaborate</a> with computational science and cyberinfrastructure experts, <a href=\"https://www.xsede.org/for-users/ecss\" rel=\"nofollow noopener\">tools</a> for data analysis and visualization, opportunities for <a href=\"https://www.xsede.org/community-engagement/student-engagement\" rel=\"nofollow noopener\">students</a>, and much more.</p>\n<p>In fact, since 2011, we\u2019ve supported over $2 billion dollars worth of research awards from agencies like the National Science Foundation which have enabled competitive research across the nation.</p>\n<p>Together, the XSEDE team is working to bring the best of XSEDE to every user, so that you can Discover More. Check out our new video to explore how. <a href=\"mailto:help@xsede.org\">Questions? Ask us here!</a></p>\n<p><a href=\"https://www.xsede.org/\" rel=\"nofollow noopener\">XSEDE</a>, the Extreme Science and Engineering Discovery Environment, helps the nation\u2019s most creative minds discover breakthroughs and solutions for some of the world\u2019s greatest scientific challenges. Through free, customized access to the National Science Foundation\u2019s advanced digital resources, expert consulting, training and mentorship opportunities, XSEDE enables you to Discover More.</p>"
    ],
    "871": [
        "<p>If I am new to HPC (but perhaps have used Python) what modules should I take a look at?</p>",
        "<p>There is a really fantastic list of resources I\u2019ve unearthed here:</p>\n<p><a href=\"http://andy.terrel.us/blog/2012/09/27/starting-with-python/\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">http://andy.terrel.us/blog/2012/09/27/starting-with-python/</a></p>\n<p>Specifically, it reviews tutorials, Python modules intended for HPC, and resources to help learn about performance, profiling, and scaling. Some of the notes might be a bit old, so if you find an issue please comment on the author\u2019s disqus (at the bottom of the page) to see if an update can be made.</p>",
        "<p>I\u2019d also suggest checking out Dask (<a href=\"https://dask.org/\" rel=\"nofollow noopener\">https://dask.org/</a>) and Ray (<a href=\"https://github.com/ray-project/ray\" rel=\"nofollow noopener\">https://github.com/ray-project/ray</a>).</p>",
        "<p>Here is another nice post on Python Performance Optimization:</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <a href=\"https://stackabuse.com/python-performance-optimization/\" target=\"_blank\" title=\"02:20PM - 21 February 2019\" rel=\"nofollow noopener\">Stack Abuse \u2013 21 Feb 19</a>\n  </header>\n  <article class=\"onebox-body\">\n    \n\n<h3><a href=\"https://stackabuse.com/python-performance-optimization/\" target=\"_blank\" rel=\"nofollow noopener\">Python Performance Optimization</a></h3>\n\n<p>We will optimize common patterns and procedures in Python programming in an effort to boost the performance and enhance the utilization of the available computing resources.</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "<p>And here is another great resources that goes through Python bulletins worth learning!</p>\n<p><a href=\"https://treyhunner.com/2019/05/python-builtins-worth-learning/\" class=\"onebox\" target=\"_blank\" rel=\"nofollow noopener\">https://treyhunner.com/2019/05/python-builtins-worth-learning/</a></p>"
    ],
    "111": [
        "<p>On modern Intel servers what is the typical gain on the Stream Benchmark by switching compilers from gcc to intel (icc)?</p>\n<p><strong>CURATOR:</strong> JPessin1</p>",
        "<p>It will of course depend on system specifics, it would be best to run your own tests on the system of interest.<br>\n<a href=\"https://software.intel.com/en-us/articles/optimizing-memory-bandwidth-on-stream-triad\">https://software.intel.com/en-us/articles/optimizing-memory-bandwidth-on-stream-triad</a>,<br>\nor the authors instructions <a href=\"http://www.cs.virginia.edu/stream/ref.html\">http://www.cs.virginia.edu/stream/ref.html</a></p>\n<p>That said, according to the Stream author himself:</p>\n<blockquote>\n<p>STREAM performance should have only an extremely small dependence on the compiler version (for Intel compilers).  There are certainly no noticeable changes across 13, 14, and 15, and the performance differences that exist are mostly very subtle 2nd-order (or smaller) effects.   There is a big difference in performance between the Intel compilers and gcc, but that is because gcc does not support the generation of streaming stores.</p>\n</blockquote>\n<p><a href=\"https://software.intel.com/en-us/forums/intel-c-compiler/topic/599289\" class=\"onebox\" target=\"_blank\">https://software.intel.com/en-us/forums/intel-c-compiler/topic/599289</a></p>\n<p><strong>COMMENT-JP</strong>: <a class=\"mention\" href=\"/u/aculich\">@aculich</a> Now that I\u2019ve added an answer this looks to me like one of the grey SE questions where folks disagree on whether it belongs \u2026 Thoughts?</p>\n<p><strong>COMMENT-AC</strong>: <a class=\"mention\" href=\"/u/jpessin1\">@jpessin1</a> For the purposes of our Q&amp;A site, I think it is worthwhile to include this question because it represents something that is not easily googleable\u2026 it takes some work to understand the question, read the intel forum thread, and find the answer to the question buried there, so it is adding value.</p>"
    ],
    "270": [
        "<p>I\u2019m trying to do a simple parameter-sweep with SGE, previously I\u2019ve been using array jobs from SGE\u2019s <code>-t</code> flag but the files I have all have different names like F15WT or R20683KY. Is there a straightforward way to use these in an array job without renaming them?</p>",
        "<p>One way to do that is to make a file with one filename per line and then use something (sed in this example) to assign a line to a variable</p>\n<p>First <em>making the file</em></p>\n<blockquote>\n<p><code>for name in * ; do</code><br>\n<code>echo $name &gt;&gt; inputfilelist.txt;</code><br>\n<code>done</code></p>\n</blockquote>\n<p><em>Next</em><br>\nmake sure you have the correct number of files<br>\n<code>wc -l inputfilelist.txt</code></p>\n<p>in the submit script with the output of wc as N</p>\n<blockquote>\n<p>. . .<br>\n<code>#$ -t 1-N</code></p>\n<p><code>infile=$(sed -n -e \"$SGE_TASK_ID p\" inputfilelist.txt)</code></p>\n<p><code>myscript.sh $infile</code></p>\n</blockquote>"
    ],
    "846": [
        "<p>How can I use Singularity containers to install and run software on my institution\u2019s HPC cluster?</p>",
        "<p>Here is a tutorial for using Singularity on the CRC computing cluster at the University of Notre Dame, which uses the SGE job scheduling system. It serves as a general introduction to containers and may be applicable to other computing clusters as well. The tutorial walks you through the process of building a container and running a GPU-accelerated PyTorch program on a GPU node. It also has tips for managing Python packages efficiently.</p>\n<aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://github.githubassets.com/favicon.ico\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://github.com/bdusell/singularity-tutorial\" target=\"_blank\" rel=\"nofollow noopener\">GitHub</a>\n  </header>\n  <article class=\"onebox-body\">\n    <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/dbca9878d5136cd5fff3a043e8d92e685fdbb567.png\" class=\"thumbnail onebox-avatar\" width=\"420\" height=\"420\">\n\n<h3><a href=\"https://github.com/bdusell/singularity-tutorial\" target=\"_blank\" rel=\"nofollow noopener\">bdusell/singularity-tutorial</a></h3>\n\n<p>Tutorial for using Singularity containers. Contribute to bdusell/singularity-tutorial development by creating an account on GitHub.</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n",
        "<p>Singularity is available on compute nodes on Odyssey and user can using SBATCH or an interactive session in SLURM to their workflow using singularity. We also have documentation on how you can convert docker or other OCI containers to a singularity image and launch them. <a href=\"https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/\" rel=\"nofollow noopener\">https://www.rc.fas.harvard.edu/resources/documentation/software/singularity-on-odyssey/</a></p>"
    ],
    "31": [
        "<p>I am an expert user of a cluster with an LSF Scheduler and need to use a cluster with a SLURM Scheduler. Can someone help me get started by translating the following simple examples from SGE to SLURM?</p>\n<p>What Jobs are currently running?<br>\n<code>bqueues</code></p>\n<p>What Jobs am I currently running?<br>\n<code>bqueues -u username</code></p>\n<p>Launch an interactive session on one node with 16 cores:<br>\n<code>bsub -I -n 16</code></p>\n<p>Launch a batch job on one node with 16 cores,<br>\n<code>bsum -n 16</code></p>\n<p>Cancel a batch job<br>\n<code>bkill -J jobname</code></p>\n<p>Cancel all my jobs<br>\n<code>bkill -u myusername</code></p>\n<p><strong>CURATOR:</strong> John Goodhue</p>",
        "<p><strong>ANSWER:</strong> The HPC Wales Portal has a useful mapping of LSF commands to Slurm equivalents - see<br>\n<a href=\"http://portal.hpcwales.co.uk/wordpress/index.php/index/slurm/migrating-jobs/\" class=\"onebox\" target=\"_blank\">http://portal.hpcwales.co.uk/wordpress/index.php/index/slurm/migrating-jobs/</a></p>",
        "<p>There\u2019s also the Slurm Rosetta Stone <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=6\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"> <a href=\"https://slurm.schedmd.com/rosetta.html\" rel=\"nofollow noopener\">https://slurm.schedmd.com/rosetta.html</a></p>\n<p>Some quickies, (Note: some clusters default the <code>squeue</code> command to displaying all users jobs, others to only your jobs):</p>\n<pre><code>##Your jobs:\nsqueu -u $USER\n\n##All Jobs:\nsqueue -u \\*\n\n##Show only running jobs for all users\nsqueue -u \\* --state=RUNNING\n\n## Cancel a job\nscancel &lt;JOBID&gt;\n\n## Cancel all of my jobs\nscancel -u $USER\n</code></pre>\n<p>The two common job start commands in Slurm are (description taken from the man pages):</p>\n<ul>\n<li>\n<strong>srun</strong>: Run a parallel job on cluster managed by Slurm.  If necessary, srun will first create a resource allocation in which to run the parallel job.</li>\n<li>\n<strong>sbatch</strong>: submits a batch script to Slurm.  The batch script may be given to sbatch through a file name on the command line, or if no file name is specified, sbatch will read in a script from standard input. The batch script may contain options preceded with \u201c<span class=\"hashtag\">#SBATCH</span>\u201d before any executable commands in the script.</li>\n</ul>"
    ],
    "36": [
        "<p>If a SLURM job fails or terminates unexpectedly, what mechanisms are available for making sure that temporary data, especially that on compute nodes, is cleaned up?</p>\n<p><strong>CURATOR:</strong> Jack Smith</p>",
        "<p><strong>ANSWER:</strong> If you use the local storage (like $TMPDIR) on the node to store temporary data, it will be automatically purged on exit.  Every HPC cluster can have a different location of $TMPDIR and can have size limits. Check with local HPC provider for those.</p>"
    ],
    "132": [
        "<p>How I can view the logs for my jobs on SLURM for some period of time? I ran a number of jobs and I would like to know how much memory was used, how long did the job take, and its exit status?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>The <code>sacct</code> command is a good way to extract information about previous SLURM jobs.  Use of the man pages (<code>$ man sacct</code>) will list and explain options for inputting parameters for the data one wishes to view, and specifying the desired output in the desired format.</p>\n<p>The options -S and -E allow one to select the start date and end date respectively.  Start date selects jobs in any state (i.e. COMPLETED, FAILED) that started before that date.  End date selects those that finished prior to this date.  The resulting data can be output and formatted based on command line options.  Here is an example:</p>\n<pre><code class=\"lang-auto\">$ sacct -a -S2018-03-15-10:30 -E2018-03-31-10:30 -X -o jobid,start,end,state\n</code></pre>\n<p>A sample output is below:</p>\n<pre><code class=\"lang-auto\">4194000      2018-03-16T00:58:26 2018-03-16T02:20:38  COMPLETED \n4194001      2018-03-16T02:20:43 2018-03-16T02:22:00  COMPLETED \n4194002      2018-03-16T02:22:04 2018-03-16T02:23:07  COMPLETED \n4194562      2018-03-15T07:41:25 2018-03-17T09:57:14 CANCELLED+ \n4194563      2018-03-15T07:43:40 2018-03-17T09:59:59 CANCELLED+ \n4194564      2018-03-15T07:48:45 2018-03-19T16:19:36  PREEMPTED \n4194565      2018-03-15T07:49:45 2018-03-19T16:19:36  PREEMPTED \n4194566      2018-03-15T07:51:10 2018-03-19T16:21:38  PREEMPTED \n4194585      2018-03-15T09:22:37 2018-03-15T10:33:03     FAILED \n4194586      2018-03-15T09:22:37 2018-03-15T10:31:44     FAILED \n</code></pre>\n<p>The <code>-X</code> option displays only cumulative stats for each job, leaving out intermediate steps.</p>",
        "<p><a class=\"mention\" href=\"/u/toreliza\">@toreliza</a> -X option is really useful!!! Thank you.</p>"
    ],
    "233": [
        "<p>What files do I need to run Gaussian on a compute node?</p>",
        "<p>If your server uses SLURM to manage jobs, you will need both a Gaussian input file (.gau, .gzmat, etc.) and a .job file to tell the server how to manage and use your files.</p>\n<p>Your Gaussian file should be formatted normally. Make sure to specify the number of processors, amount of memory, and a checkfile filename in your header. For example:</p>\n<pre><code>%nprocshared=16\n%mem=8gb\n%chk=File1.chk\n#n B3LYP/6-31+G(d,p) opt\n</code></pre>\n<p>Your .job file must contain a few specifications. These include the number of processors and amount of memory, the location of the scratch directory on the server, and the location of the Gaussian program itself. This should look similar to:</p>\n<pre><code>#!/bin/bash\n#SBATCH -n 16\n#SBATCH --mem=9000\n#SBATCH -p partitionname\n#SBATCH -t 24:00:00\n\nset -x\nfilename=File1\nfiletype=gzmat\n\n## Telling the server where Gaussian is ##\n\nmodule add path/to/Gaussian\nunset PGI_TERM\nprgname=g09 #Gaussian program name\n\n## Setting up scratch and copying files ##\n\nSTORAGE_DIR=\"/scratch/users/you_username/${SLURM_JOB_ID}.${filename}\"\nGAUSS_SCRDIR=$STORAGE_DIR\nexport GAUSS_SCRDIR STORAGE_DIR\nmkdir -pv $STORAGE_DIR\ncd $STORAGE_DIR\ncp $SLURM_SUBMIT_DIR/${filename}.${filetype} $STORAGE_DIR\nfor a in $extrafiles ; do cp -r $SLURM_SUBMIT_DIR/$a $STORAGE_DIR/ ;  done\ncat ${filename}.${filetype}\n\n##  Running Gaussian 09 and putting the output files back in your home directory ##\n\n$prgname &lt; ${filename}.${filetype} &gt; ${filename}.out\ncp -a $STORAGE_DIR $SLURM_SUBMIT_DIR\n</code></pre>\n<p>You will need to upload both of these files to the server via FTP (e.g. with FileZilla or similar), then submit the .job file on the cluster by logging in with SSH via Terminal or PuTTY, navigating to the folder where the files are stored, and running</p>\n<pre><code>sbatch filename.job</code></pre>"
    ],
    "39": [
        "<p>This question could be answered to various depths, depending on the stage of \u201cuser organization\u201d from which the asker is starting.  If groups and partitions are already created, then appropriate entries in the SLURM configuration file are all that would be required.  (My <code>slurm.conf</code> is in <code>/etc/slurm</code>.)  If the asker needs to know how to create groups, that\u2019s another layer.  Please explain solutions to both scenarios in your answers.</p>\n<p><strong>CURATOR</strong> torey</p>",
        "<p><strong>ANSWER:</strong> To configure SLURM groups to limit access to SLURM partitions, one must edit the SLURM configuration file that resides on the management node for the given cluster.  Root access will most likely be required.<br>\nThe file to edit is in <code>/etc/slurm</code> and is called <code>slurm.conf</code>.  (As a reminder, it\u2019s a good idea to copy the original <code>slurm.conf</code> to another file in case of disaster.)  For each partition, add a new line in <code>slurm.conf</code> with the following information (the entries to the right of the equals signs are examples):</p>\n<p><code>PartitionName=xyzPartition\t Nodes=compute[001-010] \tPriority=1000 AllowGroups=xxxMioNodes, yyyMioNodes, zzzMioNodes</code></p>\n<p>Some notes:<br>\nThe reason for creating groups is to engage the SLURM pre-emption mechanism;<br>\nThe <code>PartitionName</code> defines the partition;<br>\nThe <code>Nodes</code> entry assigns nodes to that partition;<br>\nThe <code>Priority</code> entry is related to the pre-emption mechanism; information can be found in SLURM documentation;<br>\nThe <code>AllowGroups</code> entry specifies the groups of users that can access this partition (comma-separated).</p>"
    ],
    "220": [
        "<p>Our System Administrators told me that my home account is over the 10GB quota on our cluster, but I executed the <code>ls -l</code> command and I can see only a few small files that do not exceed more than 3GB all together. How is it that am I exceeding the quota?</p>",
        "<p>This often happens when there are some large files (or many smaller files) in so called <em>dot</em> directories.<br>\nTry to execute the following command to see what files you have in all directories (including hidden directories):<br>\n<code>du -hs .[^.]* *</code></p>",
        "<p>On Linux systems, there is a nicer way to find the particular directory that may have a large file (or files) that hog your quota. From your home directory invoke:</p>\n<pre><code>du -S | sort -rnk 1 | head -30\n</code></pre>\n<p>(That is with capital <code>-S</code>, not <code>-s</code>). This will print out the usage of your individual directories <em>WITHOUT</em> including the sum of the disk usage of their child subdirectories and sort them descending in size, and print the first 30 (i.e. the largest offenders). Usually this will get you to the biggest hogging directory right away. Maybe in that directory there is a large temporary file, or maybe a core dump \u2026 things that users don\u2019t frequently check for.</p>"
    ],
    "37": [
        "<p>I need to submit many hundreds jobs to the cluster. What is the best way to submit these jobs to ensure that the jobs are scheduled and complete as fast as possible?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>This question is not very clear so hard to answer. But here are some thoughts.<br>\nIf we talk about a single job that does a lot of I/O communication than there are a couple of suggestions:</p>\n<ul>\n<li>If job reads or writes one line at a time then the most efficient way is to copy (or create) the file to the local scratch/tmp directory (which one would depend on the cluster) and make read/write to/from this local file. At the end file can be moved back to the project space</li>\n<li>Depending on a cluster, some nodes might have faster and slower  ethernet connection on various nodes. Requesting a node with faster ethernet connection might help with jobs that have high I/O demands</li>\n</ul>\n<p>The other way this question could be interpret is how should I arrange and submit my (many)  jobs so they would start running (and finish) as soon as possible. There are a couple suggestions in this case:</p>\n<ul>\n<li>For many similar jobs use array job (instead of submitting many jobs )</li>\n<li>For many very short tasks combine them into a single job instead of submitting many very short jobs</li>\n<li>Make sure you request appropriate resources for your jobs - do not request resources that you job does not need - very long time limit, too many cores etc.</li>\n<li>Study careful resources provided with the cluster. Some clusters have specific queues dedicated to the jobs that otherwise would have a long waiting time in a general queue.</li>\n</ul>",
        "<p>Jack\u2019s COMMENT: Asking Google \u201cslurm options for best throughput\u201d gives as first response:  \u201cTuning Slurm Scheduling for Optimal<br>\nResponsiveness and Utilization\u201d -&gt; <a href=\"https://slurm.schedmd.com/SUG14/sched_tutorial.pdf\">https://slurm.schedmd.com/SUG14/sched_tutorial.pdf</a></p>",
        "<p><strong>ANSWER:</strong></p>\n<p>In general, you should specify to the scheduler all the requirements for your job, and not add constraints which are not requirements.  Adding additional<br>\nconstraints can often cause the job to spend additional time waiting in the queue,<br>\nwhich will degrade overall throughput.</p>\n<p>(NOTE: The Slurm and Moab options below can be affected by how the<br>\nspecific cluster is configured, so while valid for many such clusters they may<br>\nnot be valid for all clusters).</p>\n<p>Some common requirements to consider:</p>\n<ol>\n<li>\n<p>Walltime for the job.<br>\nTypically every job has a wall time (either specified by user or defaulted), and the scheduler will terminate jobs when the walltime is exceeded (whether the job completed or not).  So you usually want to specify the smallest walltime such that you are sure your job (if running properly) will finish within.  I.e., if you expect the job will usually finish in 8 hours, you might want to pad this to 9 or 10 hours just to be certain, but 24 hours is probably excessive.  Shorter jobs might get greater priority, and typically can better take advantage of backfilling, both of which will shorten time waiting in the queue.<br>\nOn Slurm, this is done with the --time=TIME or -t TIME flags, where TIME can<br>\nbe the number of minutes, or something like HOURS:MINS:SECS or DAYS-HOURS:MINS<br>\nFor Moab systems this is typically done with something like \u201c-l walltime=TIME\u201d</p>\n</li>\n<li>\n<p>the number of nodes/CPU cores to be allocated<br>\nThe scheduler allocates CPU cores on nodes to jobs, so it needs to know what<br>\nyou want.  I am assuming you know what is best for your code/problem.  The<br>\nimportant thing is that you tell the scheduler what you need/want.  In particular,<br>\nso codes can use multiple CPUs, but only if they are on the same node, in which<br>\ncase you need to tell the scheduler that (e.g. in Slurm, to get 8 cores on a<br>\nsingle node, something like \u201c\u2013nodes=1 --ntasks=8\u201d or even more specific<br>\n\u201c\u2013ntasks=1 --cpus-per-task=8\u201d.  On Moab systems, this is usually specified<br>\nwith something like \u201c-l nodes=1:ppn=8\u201d ).</p>\n</li>\n</ol>\n<p>For pure MPI jobs, however, it often does not matter much how the tasks are<br>\ndistributed among nodes (at least when all the nodes can talk to each other at<br>\nfull bandwidth over the high speed interconnect).  In such cases, it is usually<br>\nbest to only tell the scheduler how many tasks you wish to run, and not constrain<br>\nthe scheduler in how to distribute the tasks among nodes.  Specifying a node<br>\ncount can cause the job to spend more time in the queue, and is not advised<br>\nunless such will significantly improve runtime.</p>\n<p>In order to request 8 single core MPI tasks, letting the scheduler distribute<br>\nover nodes as it sees fit, on Slurm systems one would use \u201c\u2013ntasks=8\u201d without<br>\nthe --nodes flag.  On Moab systems, it would be something like \u201c\u2013nodes=8\u201d<br>\n(the \u201cnodes\u201d in this case refer to \u201cvirtual nodes\u201d, i.e. a processor cores)</p>\n<ol start=\"3\">\n<li>specifying the amount of memory needed<br>\nYou typically should specify how much memory the job needs.  Different schedulers<br>\ngive somewhat different options in how this can be specified (total for the<br>\njob, for each node in the job, for each task in the job, for each allocated<br>\nCPU core, etc).  It is often most useful to specify per processor core or task.<br>\nOn Slurm, to specify the amount of memory per CPU core allocated, one could<br>\nuse  \u201c\u2013mem-per-cpu=MEMORY\u201d.  Moab users can use something<br>\nlike \u201c-l pmem=MEMORY\u201d.  In both cases, MEMORY is in MB.</li>\n</ol>\n<p>Sometimes users will try to \u201ctrick\u201d the scheduler \u2014 e.g. if the compute nodes<br>\nhave 64 GB of RAM and 16 cores per node, and your MPI job needs 16 cores and<br>\n8 GB of RAM per core, you might request 16 cores over 2 nodes and leave out the<br>\nmemory specification.  But this can in some cases delay the<br>\nscheduling of your job \u2014 it is better tell the scheduler what you really want,<br>\ne.g. \u201c\u2013ntasks=8 --mem-per-cpu=8\u201d in Slurm, as there could be 8 nodes which are<br>\nnot fully utilized and could run a single core task needing 8 GB of RAM on which<br>\nyou job could run immediately, instead of waiting for 2 complete nodes to become<br>\nfree.</p>\n<ol start=\"4\">\n<li>allowing your job to share nodes with other jobs<br>\nMost schedulers support several policies with respect to whether more than one<br>\njob can run on the same node (assuming sufficient resources).  Depending on the<br>\ncluster, this might or might not be selectable by the user submitting the job.<br>\nIf it is an option available to you, in general allowing your job to run on the<br>\nsame nodes as other jobs might reduce the amount of time your jobs waits in the<br>\nqueue.</li>\n</ol>\n<p>There are potential negatives that should be considered as well:<br>\na) running on the same node as other jobs increases the potential for the other<br>\njobs to interfere with your job.  While the operating system and cluster<br>\nconfiguration make some effort to mitigate this, such efforts are not perfect.<br>\nI/O and network bandwidth are typically shared among all jobs on a node, and<br>\nso are usually vulnerable to such interference.</p>\n<p>Typically, if you are running a very parallel code, running on (and using most<br>\nof the cores of) many nodes, it is best not to share nodes with other jobs.<br>\nThe width of these jobs generally increase their vulnerability to<br>\nsuch interference, and generally significantly reduces any benefits in scheduling.</p>\n<p>But if your job is not using all the cores available on a typical node, allowing<br>\nit to run on the same nodes with other jobs will usually give enough benefit<br>\nin the scheduling of the job to more than offset the risk of a job needing<br>\nto be rerun due to negative interference from another job.</p>"
    ],
    "107": [
        "<p>On many research computing facilities an account has access to a number of directory trees. Typically one of these is called or referred to as <code>/home</code> and another is called or referred to as <code>/scratch</code>. Many new users of research computing resource are unclear why there are different directory trees and how to use them. This question seeks explanation and guidance for the use of these different directories.</p>\n<p><strong>CURATOR:</strong> Chris Hill</p>",
        "<p><strong>ANSWER:</strong> On a typical research computing facility the /home or equivalent directory will be the location where a login starts by default. Often times this directory is located on a filesystem that is geared toward editing of files and small analysis of datasets. The filesystem usually has reasonable levels of redundancy and fairly frequent backup practices. This is to ensure that human effort intensive work, for example editing program scripts, writing documents, making plots and so forth against this filesystem is well supported. High levels of redundancy and frequent backups require so investment in capital and in operations. This can make it economically impractical and/or inefficient to provide very large file spaces at the /home type of quality of service.</p>\n<p>Many research computing facilities also operate bulk storage systems, typically called or referred to as /scratch. These are often an order of magnitude or more larger in capacity than the /home system. They may be geared toward highly parallel reading and writing of the sort generated by data intensive applications more than people editing files. These file systems often have redundancy but may not be backed up to another storage location due to economic trade offs.</p>\n<p>In general end users of research computing facilities end up using /home type file systems for digital material that would be hard or impossible to recreate (assuming that /home is a synonym for a fully backed up, highly redundant system). File systems that are designated (or even called) /scratch are typically used for large numbers of files and/or large individual files that cannot fit on /home or do not perform well there. Exact guidance for which system to use when will vary from one installation to another, but the general rules outlined here tend to apply universally.</p>\n<p>Some facilities only provide one flavor of storage service. In some cases a facility chooses to offer highly redundant and multiply backed up storage only. This increases capital and operational costs per unit of storage but reduces the risk that any digital assets will be permanently lost. Other facilities chose to base all there storage on high-performance technologies with limited redundancy and backup but lower cost per unit of storage.</p>\n<p>Almost all research computing facilities assume that end users and/or application service providers understand what level of service is most relevant to their activities. End users of a facility should definitely try and pay attention which levels of data safety and performance service a facility provides on which file systems.</p>",
        "<p><strong>ANSWER:</strong> Some facilities have more filesystems than just the usual /home and /scratch spaces.</p>\n<p>For example, in PSC Bridges, their documentation on <a href=\"https://www.psc.edu/bridges/user-guide/file-spaces\">File Spaces</a> lists the following:</p>\n<p>There are several distinct file spaces available on Bridges, <strong>each serving a different function</strong>.</p>\n<ul>\n<li>Home ($HOME), your home directory on Bridges</li>\n<li>pylon2, ($PROJECT), persistent file storage  Note that due to recent improvements in the pylon5 file system, pylon2 will be phased out.  Please see New on Bridges for directions on how to move your files to pylon5.</li>\n<li>pylon5 ($SCRATCH),  a Lustre system for persistent file storage.  Pylon5 has replaced pylon1.</li>\n<li>Node-local storage ($LOCAL), scratch storage in the local memory associated with a running job</li>\n<li>Memory storage ($RAMDISK), scratch storage on the local disk associated with a running job</li>\n</ul>\n<p>Note, I bolded the text above about each serving a different function\u2014 I am not sure what you are trying to accomplish, so if you could explain more what you want to do then I could provide some more guidance if the examples above are not enough to answer your question.</p>"
    ],
    "206": [
        "<p>I submitted my MPI job and many nodes ran out of memory. Is there any way to submit my code in such a way that it would fit into the memory limits for each node?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p><strong>ANSWER:</strong> In many cases the memory usage on each node may be reduced by using fewer cores than are available on each node. For example consider the case: running the mpi application on 3 nodes with 16 cores each. Your SLURM submission script would include the following lines:</p>\n<pre><code># Request 3 nodes with 16 cores each:\n#SBATCH -n 48\n#SBATCH --tasks-per-node=16\n\n#load modules if needed\nmodule load openmpi\n\n# run program with only half of the available cores on each node\nsrun -n 24 -bynode hello-mpi</code></pre>"
    ],
    "159": [
        "<p>I need to submit 5,000 parallel jobs. Each job takes 10 hours to complete if run using a single core. I parallelized it and it runs much faster if I use many cores (there is an embarrassingly parallel loop within with 1 million iterations). But I noticed that my waiting time in the queue is much longer than if I am using only 1 core for my job. So how should I determine the best number of cores I should request for my jobs, so they will start and finish as fast as possible.</p>",
        "<p>The answer to this question depends on many factors including the following:</p>\n<ol>\n<li>Is there a limit to the number of jobs a user can submit on the cluster you are using?</li>\n<li>What is the time limit for the jobs on your cluster?</li>\n<li>Are there special queues dedicated to run parallel jobs?</li>\n<li>How much memory your jobs use</li>\n</ol>\n<p>Based on the above you should adjust your submission script.<br>\nIf for example you have a limit of 250 jobs per user, the maximum time per user is 5 days and the cluster has nodes with 20 cores, then you might want to run 250 jobs where each job will use 20 cores and each job will run 20 instances of your script in parallel.</p>\n<p>However for each particular setup I would discuss your particular situation with your cluster system administrators and they will provide the best recommendation for your case.</p>"
    ],
    "26": [
        "<p><strong>CURATOR:</strong> Katia</p>\n<p>I have heard that cgroups might be very useful for cluster administrators. Could someone explain what cgroups are and how they are used?</p>",
        "<p>CGroups (in the RedHat/CentOS sense) is a binding mechanism for limiting a \u201cjob\u201d to specific cores and ram.  This is useful for localizing memory references, as well as minimizing job interaction on a multi-core, multi-gigabyte compute node.  I\u2019ve used them extensively on SGI hardware (UV systems) in conjunction with PBSPro in the past, and they provide great localization and isolation, but if a user jobs bloats outside its RAM, that process will swap itself silly.  If you have multiple processes doing that, then swap space (and swap performance) both become a serious contention problem.  There are other uses, like limiting cpu cycles for a given user group, but I have no hands on experience with those.</p>\n<p>CGroups result problems on RHEL 6.x (lost kernel memory), but RHEL says the problems is fixed in RHEL 7.  We\u2019re repurposing some old hardware into a new test environment, and that will be RH 7 based, so I can get some hands on with CGroups and make sure the claims about it \u201cworking fine in 7\u201d ring true.</p>"
    ],
    "934": [
        "<p>Does anyone have experience with molecular dynamics simulations in GROMACS with geometry constraints? I know that GROMACS implements LINCS, SHAKE, and SETTLE, in order to constrain chemical bond lengths, angles, etc., and each of these has different capabilities/advantages. That being said, I rarely run constrained simulations.</p>\n<p>I am trying to constrain all bond lengths <em>and</em> angles, meanwhile using my own table files (custom force field), and hopefully run on more than 1 CPU.</p>\n<p>I run into trouble because the use of custom table files forces me to alter the \u201ccharge group\u201d of atoms in molecules, which causes SHAKE to fail on &gt;1 CPU. But LINCS can not constrain angles. My current workaround has been to make all bond angles very stiff by using arbitrarily large angle force constants. This allows the \u201crigid\u201d simulation to run on multiple CPUs using LINCS, but I won\u2019t generate proper energetics any more.</p>",
        "<p>Hi Ryan,</p>\n<p>I haven\u2019t worked with GROMACS before, so my assistance may be limited. Which version are you using and how are you using parallelization? Is this document helpful? <a href=\"http://www.gromacs.org/Documentation/Acceleration_and_parallelization\" rel=\"nofollow noopener\">http://www.gromacs.org/Documentation/Acceleration_and_parallelization</a></p>\n<p>If you are using GROMACS 4.6, you might be able to try using MPI and/or OpenMP. Apologies if you are already doing this and still running into this problem.</p>",
        "<p>I am using GROMACS 2018.4. I am indeed already using parallelization with MPI. I don\u2019t think it is the MPI that is the problem, per se.<br>\nThe problem is caused by the fact that the algorithm needed for constraining bond lengths <em>and</em> angles (SHAKE) does not seem to work on more than one CPU, if custom table files are used. There is a constraint algorithm that works find with multiple CPUs and custom table files (LINCS), but this algorithm can not constrain bond angles, only lengths.</p>",
        "<p>As far as I understand, Gromacs can constraint both bonds and angles with LINCS using the constraints = all-angles option (<a href=\"http://manual.gromacs.org/documentation/2018-current/user-guide/mdp-options.html#bonds\" rel=\"nofollow noopener\">http://manual.gromacs.org/documentation/2018-current/user-guide/mdp-options.html#bonds</a> ). As stated in the manual:</p>\n<p>Convert all bonds to constraints and all angles to bond-constraints.</p>\n<p>The shake algorithm is only included for reference in Gromacs, and therefore is only used for testing.</p>"
    ],
    "32": [
        "<p>How can I convert this PBS script to SLURM?</p>\n<p>In particular, I\u2019m not quite sure which parameters to use with SLURM that will provide the same behavior as this parameter in the PBS script: <code>-l nodes=2:ppn=16</code></p>\n<pre><code class=\"lang-auto\">#!/bin/bash                                                                      \n#PBS -l nodes=2:ppn=16                                                                                                                        \n#PBS -N abcName                                                       \n#PBS -A 9876                                                                \n#PBS -o $PBS_JOBID.stdout                                        \n#PBS -e $PBS_JOBID.stderr                                        \n#PBS -r n                                                                       \n#PBS -M mlacount@mines.edu                                  \n#PBS -m abe                                                                \n#PBS -V                                                                        \n#PBS -l walltime=3:00:00                                            \n#-----------------------------------------------------\nmodule load PrgEnv/intel/default\nmodule load openmpi/intel/default\nmodule load PrgEnv/libs/fftw/3.3.3\nmodule load Apps/RGWBS/Jan2_2009\n\ncd $PBS_O_WORKDIR\n\n#save a nicely sorted list of nodes\n#sort -u  $PBS_NODEFILE &gt; mynodes.$PBS_JOBID\n\nmpiexec parsec.mpi &gt; parsec.$PBS_JOBID.log\nmpiexec tdlda.mpi &gt; tdlda.$PBS_JOBID.log\nmpiexec sigma.mpi &gt; sigma.$PBS_JOBID.log\nmpiexec bsesolv.mpi &gt; bse.$PBS_JOBID.log\n</code></pre>",
        "<pre><code class=\"lang-auto\">#!/bin/bash                     #!/bin/bash\n#PBS -l nodes=2:ppn=16          #SBATCH --nodes=2      \n                                #SBATCH -n 16\n#PBS -N abcName                 #SBATCH --job-name=\"abcName\"\n#PBS -A 9876                    #SBATCH --account=9876\n#PBS -o $PBS_JOBID.stdout       #SBATCH -o $SLURM_JOBID.out\n#PBS -e $PBS_JOBID.stderr       #SBATCH -e $SLURM_JOBID.err\n#PBS -r n                       #SBATCH --no-requeue\n#PBS -M baz@foo.edu             #SBATCH --mail-user=baz@foo.edu\n#PBS -m abe                     #SBATCH --mail-type=all\n#PBS -V                         #SBATCH --export=ALL\n#PBS -l walltime=3:00:00        #SBATCH -t 180                           \n#-----------------------------------------------------\n\nmodule load PrgEnv/intel/default\t\tmodule load PrgEnv/intel/default\t\t\t\t\t\t\t\nmodule load openmpi/intel/default\t\tmodule load openmpi/intel/default\nmodule load PrgEnv/libs/fftw/3.3.3\t\tmodule load PrgEnv/libs/fftw/3.3.3\nmodule load Apps/RGWBS/Jan2_2009\t\tmodule load Apps/RGWBS/Jan2_2009\n\ncd $PBS_O_WORKDIR\t\t\t\tcd $SLURM_SUBMIT_DIR\n\n\nmpiexec parsec.mpi &gt; parsec.$PBS_JOBID.log\tsrun parsec.$SLURM_JOBID.log\nmpiexec tdlda.mpi &gt; tdlda.$PBS_JOBID.log\tsrun tdlda.$PBS_JOBID.log\nmpiexec sigma.mpi &gt; sigma.$PBS_JOBID.log\tsrun sigma.$PBS_JOBID.log\nmpiexec bsesolv.mpi &gt; bse.$PBS_JOBID.log\tsrun bse.$PBS_JOBID.log\n</code></pre>\n<p>SchedMD provides a document that helps translate between different schedulers: <a href=\"https://slurm.schedmd.com/rosetta.pdf\">SLURM Rosetta Stone</a></p>\n<p>NOTES: In PBS, there is no equivalent to SLURM\u2019s <code>cpus-per-task</code>.  PBS scripts are based on a quantity called Processor Equivalent (PE), a scalar value that is the maximum result among four job and system-dependent parameters.  We tended to base PBS scripts on number of nodes and processors per node, as shown above; far left PBS script.  SLURM allows a script to specify resources in terms of tasks; the above SLURM script (center script) is an attempt to make a \u2018direct\u2019 translation.  These examples are just that; there are other valid parameter combinations that can achieve similar configuration goals.</p>\n<p>Recommended SLURM script:</p>\n<pre><code class=\"lang-auto\">#!/bin/bash                              \n#SBATCH --nodes=2\n#SBATCH --tasks-per-node=8                       \n#SBATCH --cpus-per-task=2                            \n#SBATCH --job-name=\"abcName\"             \n#SBATCH --account=9876                   \n#SBATCH -o $SLURM_JOBID.out              \n#SBATCH -e $SLURM_JOBID.err                                   \n#SBATCH --mail-user=baz@foo.edu\n#SBATCH --mail-type=all                  \n#SBATCH --export=ALL                     \n#SBATCH -t 180\n\nmodule load PrgEnv/intel/default\t\t\t\t\t\t\t\nmodule load openmpi/intel/default\nmodule load PrgEnv/libs/fftw/3.3.3\nmodule load Apps/RGWBS/Jan2_2009\n\ncd $SLURM_SUBMIT_DIR\n\nsrun parsec.$SLURM_JOBID.log\nsrun tdlda.$PBS_JOBID.log\nsrun sigma.$PBS_JOBID.log\nsrun bse.$PBS_JOBID.log\n</code></pre>",
        ""
    ],
    "112": [
        "<p>What is the difference between HPC and HTC? Can HPC and HTC run on the same cluster architecture?</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>HTC = High Throughput Computing<br>\nHPC = High Performance Computing</p>\n<p>Below are some attributes of HTC and HPC that highlight the differences.  HPC and HTC jobs can run on the same cluster architecture, but use the resources differently.  In summary:<br>\nHTC jobs generally involve running multiple independent instances of software on multiple processors, at the same time.  Serial systems are suitable for these requirements.<br>\nHPC jobs generally involve running a single instance of parallel software over many processors.  Results at various instances throughout the computation are communicated among the processors, requiring a parallel environment.</p>\n<p>More detail:</p>\n<p>HTC: use when one needs to:<br>\n-run many jobs that are typically similar but not highly parallel;<br>\n-run the same program with varying inputs;<br>\n-run jobs that do not communicate with each other;<br>\n-execute on physically distributed resources using grid-enabled technologies;<br>\n-make use of many computing resources over long periods of time to accomplish a computational task.</p>\n<p>HPC: use when one needs to:<br>\n-run jobs where rapid communication of intermediate results is required to perform the computations;<br>\n-make intense use of large amounts of computing resources in relatively short time periods.</p>"
    ],
    "113": [
        "<p>There seem to be three main possible places to load modules into one\u2019s compute environment. These include the bash_profile or bashrc file, within the module itself, and in the script one uses to submit a job to the cluster. What are pros and cons of each?</p>",
        "<p>I generally recommend the use of all three locations, but for different purposes:</p>\n<ol>\n<li>inside of a modulefile:<br>\nI recommend use of this either for \u201ctoolchain\u201d/\u201cmeta-module\u201d modules, e.g. you create a module to<br>\nload your standard compilation environment (i.e. your preferred compiler, MPI lib, linalg packages, etc). (This might be better done with Lmod \u201cUser Collections\u201d (module save/restore) in lmod)</li>\n</ol>\n<p>I think this is also useful when the software being made available with a particular modulefile requires certain other packages.  E.g., if a module for \u201cfoo\u201d requires a particular compiler/MPI lib,<br>\nit might be good to module load that compiler/MPI library in the foo modulefile.  (With Lmod, it is probably better to have the foo module in the appropriate module path so it only becomes available<br>\nwhen the required compiler/MPI lib/etc have been previously loaded)</p>\n<ol start=\"2\">\n<li>\n<p>In .bashrc or other dot files:<br>\nThis is good for the user\u2019s default set of modules.  I would strongly recommend that these modules only get loaded for interactive shells (e.g. in a \u201cif [ ! -z \u201c$PS1\u201d ]; then\u201d block or similar).  This way if an user always wants a particular version of matlab and gcc to be loaded, they do not have to manually type module load every time they log in.</p>\n</li>\n<li>\n<p>In job scripts:<br>\nI recommend that job scripts explicitly load all the modules they need, and that they should in general explicitly give the versions of the packages.  This is for documentation and reproducibility.<br>\nIf an user needs to return to a job and re-run it after 9 or 10 months, they might encounter unexpected and undesired problems if the version of a package they were using was \u201cdefaulted\u201d and that version changed.  Or if the user decided to change what their default compiler (loaded by .bashrc) is during that time.</p>\n</li>\n</ol>\n<p>This is also useful when one wishes to do benchmarking or test new versions of an app.  I.e., if I submit lots of Matlab jobs, and want to test if the latest version works with my code, I can have my 25 production runs using the penultimate version, and submit a test job with the new matlab version at the same time.  This would be more complicated if using .bashrc.</p>"
    ],
    "279": [
        "<p>It\u2019s said that LAMMPS is a versatile Molecular Dynamics (MD) code that can interface with a variety of other MD codes, pre- and post-processors, analysis tools, etc., and that it can even be built as a library itself. Can anyone provide a brief overview of its capabilities?</p>",
        "<p><strong>ANSWER:</strong><br>\nLAMMPS is an open-source molecular dynamics code developed and hosted by Sand\u00eda National Laboratories.  The website is <a href=\"http://lammps.sandia.gov\">lammps.sandia.gov</a>.  The documentation pages provide an extensive guide to the many performance enhancements it gains through its ability to integrate with existing software.  Most of the summary information provided below is pulled from these pages (I\u2019ve included specific links where appropriate), and combined with personal experience!</p>\n<p>As described in the LAMMPS documentation, one aim the developers have is to keep the LAMMPS kernel simple and as efficient as they considered feasible; thus LAMMPS\u2019 ability to interface with other applications (rather than re-create already-existing functionality).  LAMMPS\u2019 role is to simulate systems of interacting particles using Newton\u2019s equations of motion; based on certain specific input parameters, calculations involving atomic systems can be computed by LAMMPS itself; for geometries of higher complexity and molecular systems, it\u2019s recommended that a user either generate the input using a code of her own, or another existing code, then convert that result into LAMMPS format.  Commercial codes such as CHARMM and AMBER can be used to create the input parameters for large, elaborate structures, which again can be reformatted for LAMMPS.  (see <a href=\"http://lammps.sandia.gov/doc/Section_start.html\">http://lammps.sandia.gov/doc/Section_start.html</a>).</p>\n<p>The format of LAMMPS output files is similarly simple, allowing users to prepare these files for post-processing by a fairly wide range of commercial options, as well as via user-designed tools.  LAMMPS also includes some post-processing tools of their own; see: <a href=\"http://lammps.sandia.gov/doc/Section_tools.html\">http://lammps.sandia.gov/doc/Section_tools.html</a>.</p>\n<p>Importantly, too, the LAMMPS distribution includes several packages, both developer-created and user-created, that expand on the kernel to offer certain features.  While these packages are part of LAMMPS, many still need to be built prior to implementation.  But, they can be added one at a time, and they do broaden the range of simulations LAMMPS can run, while still maintaining the advantages of a simple kernel.  Details are found at:<br>\n<a href=\"http://lammps.sandia.gov/doc/Section_intro.html#lammps-features\">http://lammps.sandia.gov/doc/Section_intro.html#lammps-features</a>   and<br>\n<a href=\"https://lammps.sandia.gov/doc/Section_packages.html\">https://lammps.sandia.gov/doc/Section_packages.html</a>.</p>\n<p>In another display of agility, LAMMPS can be built as a library; static or shared.  This is discussed well at <a href=\"http://lammps.sandia.gov/doc/Section_start.html#building-lammps-as-a-library;\">http://lammps.sandia.gov/doc/Section_start.html#building-lammps-as-a-library;</a> in short, these forms allow another application or a scripting language to call LAMMPS libraries and invoke the associated functionalities.</p>\n<p>An amusing outcome produced by post-processing output from the lmp_png and lmp_mpi executables is the creation of the LAMMPS logo (which is, of course, extendable and/or modifiable to represent one\u2019s own institution, or \u2026).  My boss enjoyed working out the display of some \u2018Mines\u2019 logos\u2026 !</p>\n<p>In summary, LAMMPS does interface well with both pre- and post- processing applications, commercial or otherwise, and can be built as a library, static or shared.  It is also a source of creative diversion.<br>\n<a href=\"http://lammps.sandia.gov\">lammps.sandia.gov</a></p>"
    ],
    "283": [
        "<p>Our institution uses IBM\u2019s GPFS for the file systems on all of our clusters.  Is there a command, or set of commands, that will provide version (and other) information about each GPFS installation?</p>",
        "<p>IBM answers these questions very well on its website.  Here I offer two commands, and provide the appropriate IBM website links.</p>\n<p>On Linux:</p>\n<p>To display the GPFS version, type:</p>\n<pre><code class=\"lang-auto\">$ rpm -qa | grep gpfs\n</code></pre>\n<p>Associated link:<br>\n<a href=\"https://www.ibm.com/developerworks/community/forums/html/topic?id=77777777-0000-0000-0000-000014415658\" class=\"onebox\" target=\"_blank\">https://www.ibm.com/developerworks/community/forums/html/topic?id=77777777-0000-0000-0000-000014415658</a></p>\n<p>To list GPFS configuration information for the cluster, type:</p>\n<pre><code class=\"lang-auto\">$ mmlscluster\n</code></pre>\n<p>Associated link:<br>\n<a href=\"https://www.ibm.com/support/knowledgecenter/en/STXKQY_4.2.0/com.ibm.spectrum.scale.v4r2.adm.doc/bl1adm_clinfo.htm\" class=\"onebox\" target=\"_blank\">https://www.ibm.com/support/knowledgecenter/en/STXKQY_4.2.0/com.ibm.spectrum.scale.v4r2.adm.doc/bl1adm_clinfo.htm</a></p>"
    ],
    "150": [
        "<p>I want to see the memory footprint for all jobs currently running on a cluster that uses the SLURM scheduler. When I run the sacct command, the output does not include information about memory usage. The man page for sacct, shows a long and somewhat confusing array of options, and it is hard to tell which one is best.</p>\n<p><strong>CURATOR:</strong> John Goodhue</p>",
        "<p><strong>ANSWER:</strong> This topic has been addressed in stackoverflow at:<br>\n<aside class=\"onebox stackexchange\">\n  <header class=\"source\">\n      <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">stackoverflow.com</a>\n  </header>\n  <article class=\"onebox-body\">\n      <a href=\"https://stackoverflow.com/users/1701545/user1701545\" target=\"_blank\" rel=\"nofollow noopener\">\n    <img alt=\"user1701545\" src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/4f9fa3d4a1a1fbb4dcd540b0ef3f655664e0ec11.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n  </a>\n<h4>\n  <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">Find out the CPU time and memory usage of a slurm job</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>slurm</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://stackoverflow.com/users/1701545/user1701545\" target=\"_blank\" rel=\"nofollow noopener\">\n    user1701545\n  </a>\n  on <a href=\"https://stackoverflow.com/questions/24020420/find-out-the-cpu-time-and-memory-usage-of-a-slurm-job\" target=\"_blank\" rel=\"nofollow noopener\">04:35PM - 03 Jun 14 UTC</a>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>\n<p>Rephrased and enhanced by me:</p>\n<p>As stated in the <code>sacct</code> man pages:</p>\n<pre><code class=\"lang-auto\">sacct  -  displays  accounting  data for all jobs and job steps in the Slurm job accounting log or Slurm database\n</code></pre>\n<p>Viewing the man pages offers help with options and output formatting, but as stated in the stackoverflow response, MaxRSS and CPUTime are probably the fields you need.</p>\n<p>For example:</p>\n<pre><code class=\"lang-auto\">[battelle@mio001 ~]$ sacct -j 4296946.batch --format=\"CPUTime,MaxRSS\"\n   CPUTime     MaxRSS \n---------- ---------- \n  00:08:00    669060K \n</code></pre>\n<p>Here the jobid is <code>4296946</code>.  I added the <code>.batch</code> because I have no associated job steps and I submitted in batch.</p>\n<p>An option to <code>sacct</code> is to use <code>sstat</code>; the job must be running to produce output with this command.<br>\nExample:</p>\n<pre><code class=\"lang-auto\">[battelle@mio001 tbDocu52a]$ sstat -j 4296949.batch --format=AveCPU,AvePages,AveRSS,AveVMSize,JobID\n    AveCPU   AvePages     AveRSS  AveVMSize        JobID \n---------- ---------- ---------- ---------- ------------ \n 00:29.000          0    761920K  10872144K 4296949.bat+ \n</code></pre>\n<p>Fields are analogous to those of <code>sacct</code>;<br>\n<code>AveVMSize</code> refers to average virtual memory size of all tasks in the job.</p>\n<p>At our site we run a program called ganglia on the head node which all users can access;<br>\nit shows many job properties, including real-time memory use for a given node.</p>",
        "<p><strong>ANSWER:</strong></p>\n<p>As an addendum to my previous reply; one can view all information on all jobs on the cluster as well; here is one example of how to do so (without the actual output\u2026 it\u2019s similar to that of a specific job):</p>\n<pre><code class=\"lang-auto\">[battelle@mio001 ~]$ sacct -a --format=\"CPUTime,MaxRSS,JobID\"\n   CPUTime     MaxRSS        JobID \n---------- ---------- ------------ \n</code></pre>"
    ],
    "82": [
        "<p>What are the key commands/steps for running Amber using GPUs under SLURM and with the MVAPICH version of MPI?</p>",
        "<p>This may help <a href=\"https://wikis.nyu.edu/display/NYUHPC/Running+Amber+GPU+jobs\">https://wikis.nyu.edu/display/NYUHPC/Running+Amber+GPU+jobs</a></p>"
    ],
    "1065": [
        "<p>Are there known ways to get the power utilization off of a node? I would like to get this data to compare the \u201ccost\u201d of two apps that I use. Preferably I would like to be able to run this at the user level and spit out the data to a file during a run of the app, but if there are admin tools out there that can run as a daemon or something similar that I can just get approximate times to correspond to my app runs, that would be useful as well.</p>",
        "<p>I\u2019ve seen this type of data in the management controller on nodes.  If you have an iDRAC(Dell) or iLO (HP), you might be able to query this data.</p>"
    ],
    "809": [
        "<p>On slurm, when will the scheduler end a job, and how will I know this ahead of time?  How can I catch the error code before my job gets killed?</p>",
        "<p>Hi jma,</p>\n<p>For jobs that are reaching their TimeLimit, you have the option of using</p>\n<pre><code class=\"lang-auto\">--mail-type=TIME_LIMIT_50,TIME_LIMIT_80,TIME_LIMIT_90\n</code></pre>\n<p>to get a warning email when the job reaches the respective 50%, 80% or 90% of it\u2019s TimeLimit.</p>\n<p>For jobs being preempted where PreemptMode=CANCEL, the scheduler first sends SIGCONT and SIGTERM then later (depending on the configured GraceTime) sends SIGCONT, SIGTERM and SIGKILL.</p>\n<p>You can react to these signals in your job script by using a trap, see <a href=\"https://bash.cyberciti.biz/guide/Trap_statement\" rel=\"nofollow noopener\">https://bash.cyberciti.biz/guide/Trap_statement</a> for a description and examples.</p>"
    ],
    "222": [
        "<p>I am trying to parallelize my Python job, but I am not sure if it runs using many cores. I looked at the time of the execution  and the time of the execution is a little shorter than when I submit the same job without parallelization, but I expected that it would be 4 times shorter since I am using 4 cores. How do I know if the program actually using all 4 cores?</p>\n<p><strong>Curator</strong>: Katia</p>",
        "<p><strong>ANSWER:</strong> One quick and easy way is to run <code>top</code> and examine the %CPU column. If the %CPU exceeds 100% you have multiple cores working on it.  Remember, you have to have loops that are time-consuming enough to make multiple core worthwhile.  The setup and tear down for parallel loops is 1 or 2 orders of magnitude slower than memory access operations.  That means you need to have a fairly beefy processing problem to really rack up parallel processing time.</p>",
        "<p><strong>ANSWER:</strong> You can also use the \u2018time\u2019 command.  It looks like this:</p>\n<blockquote>\n<p>time myexecutable --myparameters</p>\n</blockquote>\n<p>At the completion of the execution you\u2019ll get a report that looks something like this:</p>\n<blockquote>\n<p>real    81m59.485s<br>\nuser    1707m42.779s<br>\nsys     9m31.001s</p>\n</blockquote>\n<p>The ratio between user and real shows how efficiently you were using processing.  In this case the 21:1 ratio shows how efficiently I used the 24 cores associated with this run</p>",
        "<p><strong>COMMENT:</strong></p>\n<p><a class=\"mention\" href=\"/u/lwhitsel\">@lwhitsel</a> Actually, with many R parallelization packages instead of 1 line with CPU column close to 400%, the top command will show 4 lines with R processes each close to 100%.</p>"
    ],
    "749": [
        "<p>Sometimes when I run showstart to determine when the PBS scheduler has placed my job, it returns</p>\n<blockquote>\n<p>INFO:  cannot determine start time for job xxxx</p>\n</blockquote>\n<p>Is there any way to tell if there\u2019s something wrong with my job, or something wrong with the scheduler, or any other way to troubleshoot this message and figure out what\u2019s gone wrong?</p>",
        "<p>Ben- Can you provide a screenshot of the interaction? The command as you enter it and then the message returned by the system?</p>"
    ],
    "744": [
        "<p>In high performance computing, we generally work in a terminal, meaning using some shell. Have you ever seen these lines at the top of your \u201cshell scripts?\u201d</p>\n<pre><code class=\"lang-bash\">#!/bin/sh\n</code></pre>\n<p>or</p>\n<pre><code class=\"lang-bash\">#!/bin/sh\n</code></pre>\n<p>Those first lines are the interpreter lines - or an instruction for what program to use to run the script. If you look at the variable <code>SHELL</code> in your terminal, you likely will see the shell that <em>you are using as we speak!</em></p>\n<pre><code class=\"lang-bash\">echo $SHELL\n/bin/bash\n</code></pre>\n<p>There is a <a href=\"https://en.wikipedia.org/wiki/Bash_(Unix_shell)\" rel=\"nofollow noopener\">rich history</a> of how the Unix shell became the \u201cBourne again\u201d shell, or what we commonly refer to as bash.</p>\n<blockquote>\n<p>So why bash?</p>\n</blockquote>\n<p>The reason I want you to get excited about bash is because there are SO many things you can do with it that you would typically rely on a higher level language (python, R, etc.) to do. For example, you can trim strings, write functions to otherwise manipulate strings, calculate quantities, read files, count things\u2026 it\u2019s a powerful language! Here is a one line function to make a string all lowercase:</p>\n<pre><code class=\"lang-bash\">lower() {\n    printf '%s\\n' \"${1,,}\"\n}\n\n$ lower LiKeOmGTaCoS\nlikeomgtacos\n</code></pre>\n<p>Specifically, I want to share <a href=\"https://github.com/dylanaraps/pure-bash-bible\" rel=\"nofollow noopener\">THE BASH BIBLE</a> that is not only interesting, it\u2019s fun and a great resource to learn from! So the next time you want to do some special thing from the command line? Ask yourself if you can do it with bash first, before you delve into requiring a higher level language dependency.</p>",
        "<p>It\u2019s also very simple to use loops in BASH:</p>\n<ul>\n<li>Simple <strong>for</strong> loop</li>\n</ul>\n<pre><code class=\"lang-bash\">for node in compute{1..10}; do\n  ssh $node 'hostname -s'\ndone\n</code></pre>\n<ul>\n<li>Simple <strong>while</strong> loop</li>\n</ul>\n<pre><code class=\"lang-bash\">count=1\nwhile /bin/true; do\n  echo \"looped ${count} times\"\n  let count=${count}+1\n  sleep 10\ndone\n</code></pre>\n<p>And classic <strong>if then else</strong> statement</p>\n<pre><code class=\"lang-bash\">result=0\n\nif [[ \"$result\" == \"0\" ]];then\n  echo \"Success\"\nelse\n  echo \"Fail\"\nfi\n</code></pre>",
        "<p>Agreed! Another useful example is to loop over a listing of files, or generally any terminal command that produces a list of things:</p>\n<pre><code class=\"lang-bash\">for file in $(ls $PWD); \n    do \n    echo $file; \ndone\n</code></pre>\n<p>That would generate an echo of all the files in the present working directory. You can imagine running a command instead and using the variable! Another simple loop is literally just a line of space separated strings, like this:</p>\n<pre><code class=\"lang-bash\">$ for thing in \"one\" \"two\";\n    do \n        echo $thing \n    done\n</code></pre>\n<p>That would print out:</p>\n<pre><code class=\"lang-bash\">one\ntwo\n</code></pre>\n<p><img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/c9082f89fe6207c900c02e9342612ef92814ad90.jpeg\" alt=\"image\" width=\"350\" height=\"350\"></p>"
    ],
    "79": [
        "<p><strong>CURATOR:</strong> Jack Smith</p>",
        "<p><strong>ANSWER:</strong> [Katia] Benchmarking/profiling tools are specific for each application:<br>\nFor a program written in c and compiled with gcc compiler, one can use gprof :<a href=\"http://sourceware.org/binutils/docs/gprof/\">http://sourceware.org/binutils/docs/gprof/</a>.<br>\nThere are a number of other popular profilers.</p>\n<p>For R script the basic profiling can be done using Rprof() function: <a href=\"http://stat.ethz.ch/R-manual/R-devel/library/utils/html/Rprof.html\">http://stat.ethz.ch/R-manual/R-devel/library/utils/html/Rprof.html</a> which comes with base R. However there are some other very helpful tools like proftools library <a href=\"https://cran.r-project.org/web/packages/proftools/index.html\">https://cran.r-project.org/web/packages/proftools/index.html</a> and profvis library <a href=\"https://rstudio.github.io/profvis/\">https://rstudio.github.io/profvis/</a></p>\n<p>Python just like  R comes with profiling tools: <a href=\"https://docs.python.org/2/library/profile.html\">https://docs.python.org/2/library/profile.html</a> and just like R there are some additional packages that might be helpful to graphically determine the bottleneck: <a href=\"http://pycallgraph.slowchop.com/en/master/\">http://pycallgraph.slowchop.com/en/master/</a></p>\n<p>MATLAB has its own built-in profiler.</p>",
        "<p>[deleted - obsolete]</p>",
        "<p><strong>COMMENTARY</strong>: Could you please explain what you are trying to do? And why you want to find out about the wallclock time?</p>"
    ],
    "644": [
        "<p>I want to use <a href=\"https://www.paraview.org/\" rel=\"nofollow noopener\">Paraview</a> but the installation seems very complicated. Is there a quick or easy way to do it without asking my admin for a special installation?</p>",
        "<p>If you are interested in paraviewweb (meaning a server with apache), then continue reading! If you want to just use the visualizer (without apache) <a href=\"https://github.com/singularityhub/paraview-visualizer\" rel=\"nofollow noopener\">see this repository here</a>.</p>\n<p>There are two possible versions of paraview that you might be interested in:</p>\n<h1>1. ParaviewWeb</h1>\n<p>If you are interested in using the \u201cparaviewweb,\u201d meaning serving the applications via a browser and a container instance, see <a href=\"https://github.com/singularityhub/paraviewweb-apache#singularity\" rel=\"nofollow noopener\">this post</a>. This will walk you through building a container, and running it as an instance with specific binds to the host where you need to write files. It also has instructions for <a href=\"https://github.com/singularityhub/paraviewweb-apache#docker\" rel=\"nofollow noopener\">using the Docker image</a> to deploy the same thing. You get a nice web interface with these applications:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/f4d1edf158af49d9b18ca922719fef40310f98c0.jpeg\" data-download-href=\"https://ask.cyberinfrastructure.org/uploads/default/f4d1edf158af49d9b18ca922719fef40310f98c0\" title=\"paraview.jpg\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/f4d1edf158af49d9b18ca922719fef40310f98c0_2_690x385.jpeg\" alt=\"paraview\" width=\"690\" height=\"385\" srcset=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/f4d1edf158af49d9b18ca922719fef40310f98c0_2_690x385.jpeg, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/f4d1edf158af49d9b18ca922719fef40310f98c0_2_1035x577.jpeg 1.5x, https://ask.cyberinfrastructure.org/uploads/default/original/1X/f4d1edf158af49d9b18ca922719fef40310f98c0.jpeg 2x\" data-small-upload=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/f4d1edf158af49d9b18ca922719fef40310f98c0_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">paraview.jpg</span><span class=\"informations\">1357\u00d7758 245 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>If you want to run Paraview (the program) from a container continue below - that\u2019s what the tutorial here will cover today!</p>\n<hr>\n<h1>2. Paraview as a Program</h1>\n<p>We can create a Singularity container to use Paraview, specifically from <a href=\"https://hub.docker.com/r/openfoam/openfoam6-paraview54/\" rel=\"nofollow noopener\">this Docker container</a>. Note that there might be other versions of Paraview, you can search the openfoam Docker Hub organization to check. Let\u2019s walk through the steps of how to do this.</p>\n<h2>Image Generation</h2>\n<p>First pull the image from Docker Hub, select the version below that is your preference.</p>\n<pre><code class=\"lang-bash\">singularity pull --name paraview.simg docker://openfoam/openfoam4-paraview50\nsingularity pull --name paraview.simg docker://openfoam/openfoam6-paraview54\n</code></pre>\n<p>This (50) version of the image is also provided on the Sherlock cluster by <a class=\"mention\" href=\"/u/vsoch\">@vsoch</a></p>\n<pre><code class=\"lang-bash\">cp /scratch/users/vsoch/share/paraview.simg $SCRATCH\n</code></pre>\n<hr>\n<h2>How do I know which version to use?</h2>\n<p>Another form of this question is <em>how might performance vary on my cluster?</em>. The answer is that the more recent version that uses OpenGL2 rendering needs some additional attention. For OpenGL2:</p>\n<ul>\n<li>if you don\u2019t have an nvidia card on your machine, you need to install mesa &gt;= 17.xx.</li>\n<li>The more recent mesa gives better performance (with swr or llvmpipe)</li>\n</ul>\n<p>This would mean adding the <code>--nv</code> flag to tell the container to use the nvidia libraries on the host:</p>\n<pre><code class=\"lang-bash\">$ singularity shell --nv paraview.simg\n</code></pre>\n<p>Thanks to <a href=\"https://github.com/trophime\" rel=\"nofollow noopener\">@trophime</a> for this tip!</p>\n<hr>\n<h2>Using the image</h2>\n<p>If you need to load singularity as a module or similar, do that first (on our sherlock cluster Singularity is provided <a href=\"https://news.sherlock.stanford.edu/posts/sherlock-goes-container-native\" rel=\"nofollow noopener\">natively</a>).</p>\n<pre><code class=\"lang-bash\">$ module load singularity\n</code></pre>\n<p>Then shell into the image</p>\n<pre><code class=\"lang-bash\">$ singularity shell paraview.simg \n</code></pre>\n<p>The paraview executable is located at <code>/opt/paraviewopenfoam54/bin/paraview</code></p>\n<pre><code class=\"lang-bash\">Singularity: Invoking an interactive shell within container...\n\nSingularity paraview.simg:/home/vanessa/Documents/Dropbox/Code/singularity/docker/singularity&gt; cd /opt/paraviewopenfoam54/\n</code></pre>\n<p>We can see all the binary files provided in this folder!</p>\n<pre><code class=\"lang-bash\">Singularity paraview.simg:/opt/paraviewopenfoam54&gt; ls\nbin  include  lib  share\nSingularity paraview.simg:/opt/paraviewopenfoam54&gt; ls bin\nparaview\t pvrenderserver\t\tvtkLegacyColorMapXMLToJSON  vtkWrapJava-pv5.4\t     vtkkwProcessXML-pv5.4\nparaview-config  pvserver\t\tvtkParseJava-pv5.4\t    vtkWrapPython-pv5.4\npvbatch\t\t smTestDriver\t\tvtkParseOGLExt-pv5.4\t    vtkWrapPythonInit-pv5.4\npvdataserver\t vtkEncodeString-pv5.4\tvtkWrapClientServer-pv5.4   vtkWrapTcl-pv5.4\npvpython\t vtkHashSource-pv5.4\tvtkWrapHierarchy-pv5.4\t    vtkWrapTclInit-pv5.4\n</code></pre>\n<p>Then to run paraview, given that you have x11 display, just do it <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=9\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\"></p>\n<pre><code class=\"lang-bash\">$ ./bin/paraview\n</code></pre>\n<p>It will open up the Paraview interface.</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3.png\" data-download-href=\"https://ask.cyberinfrastructure.org/uploads/default/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3\" title=\"paraview.png\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3_2_690x475.png\" alt=\"paraview\" width=\"690\" height=\"475\" srcset=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3_2_690x475.png, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3_2_1035x712.png 1.5x, https://ask.cyberinfrastructure.org/uploads/default/original/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3.png 2x\" data-small-upload=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/cea879a46df0fe7a6b2af5dc2c0abf51bafb02c3_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">paraview.png</span><span class=\"informations\">1150\u00d7792 253 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>You can also interact with software by executing a command to the container with <code>exec</code>. For example, this<br>\nwould list the content at the root of the container:</p>\n<pre><code class=\"lang-bash\">$ singularity exec paraview.simg ls /\n</code></pre>\n<p>Again, notice that we are using <code>exec</code> to send a command directly to the container. You can do any command that you like.</p>\n<hr>\n<h2>Customize the Image</h2>\n<p>If you need to make changes to the image, on your local machine, <a href=\"https://www.sylabs.io/guides/2.6/user-guide/installation.html\" rel=\"nofollow noopener\">install Singularity</a> and then create a recipe file called <code>Singularity</code> with the following content:</p>\n<pre><code class=\"lang-bash\">Bootstrap: docker\nFrom: docker://openfoam/openfoam6-paraview54\n\n%environment\n   export MYVAR=MYVAL\n\n%post\n   echo \"Write you changes here!\"\n</code></pre>\n<p>Then build the image.</p>\n<pre><code class=\"lang-bash\">$ sudo singularity build paraview.simg Singularity\n</code></pre>\n<p>You then then transfer to the cluster as you would for any file. It\u2019s a binary that can sit on your desktop.</p>"
    ],
    "193": [
        "<p>CURATOR: Scott Valcourt</p>",
        "<p>I\u2019m providing a few of the larger ones here.  Most of these are associated with ACM/IEEE publications.</p>\n<ul>\n<li>Supercomputing <a href=\"http://www.supercomp.org/\">http://www.supercomp.org/</a>\n</li>\n<li>Practice &amp; Experience in Advanced Research Computing <a href=\"https://www.pearc.org/\">https://www.pearc.org/</a>\n</li>\n<li>IEEE High-Performance Extreme Computing Conference <a href=\"http://ieee-hpec.org/\">http://ieee-hpec.org/</a>\n</li>\n<li>EDUCAUSE as a number sections include HPC, Cyberinfrastructure, Network Architecture, Cloud Computing, \u2026 which are relevant <a href=\"https://library.educause.edu/topics/infrastructure-and-emerging-technologies/high-performance-computing-hpc\">https://library.educause.edu/topics/infrastructure-and-emerging-technologies/high-performance-computing-hpc</a>\n</li>\n</ul>"
    ],
    "597": [
        "<p>A researcher in bioinformatics on our campus is seeking advice for use of Comet resources and specifically is seeking an example batch job script for any of the bioinformatics tools. She had seen the examples scripts at this URL (<a href=\"https://portal.xsede.org/sdsc-comet#running:jobscripts\" rel=\"nofollow noopener\">https://portal.xsede.org/sdsc-comet#running:jobscripts</a>) but was hoping to be pointed to something more bioinformatic specific.</p>\n<p>Also, this individual was able to upload her data to Oasis, but was not able to determine how to \u2018connect\u2019 Comet to Oasis (is it as simple as a CD command?</p>",
        "<p>I\u2019m not staff at SDSC nor do I know a lot about Comet, <em>but</em> I know that they have Singularity installed, so I would open up her world to running scripts via containers. And Comet has <a href=\"http://www.sdsc.edu/support/user_guides/tutorials/about_comet_singularity_containers.html\">quite a nice set</a>. You could start like this:</p>\n<ol>\n<li>Tell her about reproducible science, how containers can package it up, be run as executables, and help with that.</li>\n<li>Find some software she is interested in, find a matching container.</li>\n<li>Take her straight to the <a href=\"http://www.sdsc.edu/support/user_guides/tutorials/singularity.html\">section here</a> (I can\u2019t link to it, you need to scroll) that is titled \u201cRun the Container on Comet.\u201d Skip over the entire first sections - the content is dated and the sheer length would be overwhelming for a new user to think \u201cI have to do all this?!\u201d</li>\n<li>Then jump to \u201cUsing Tensorflow with Singularity\u201d that shows the same thing, but with the corresponding sbatch!</li>\n</ol>\n<p>At this point she should be able to:</p>\n<ol>\n<li>Find the software she needs, via a container</li>\n<li>Submit a job to run the container directly <em>or</em> an sbatch</li>\n</ol>\n<p>The next steps are where she might be interested, and also say \u201chey, I need/want this other container.\u201d or \u201chey, how do I change this?\u201d That\u2019s when you rewind and tell her \u201cGuess what, you can build these on your own, or modify one that is built!\u201d And at that point I\u2019d send her to the Singularity docs to go through one of the Getting Started guides, or some center \u201cGetting Started\u201d guide that you like. The important thing is to not overwhelm her with too much to learn, to show her how easy it can be to run an entire (complicated to generate) software stack, and then when she is comfortable reveal that she can roll her own. And most importantly, she is starting from step 1 with reproducible practices.</p>\n<hr>\n<p>Ah! And I just remembered from long ago, a user posted a great tutorial (with the batch submission script!) for Comet! zazing --&gt; <a href=\"https://github.com/zonca/singularity-comet\">https://github.com/zonca/singularity-comet</a> And <a href=\"https://asciinema.org/a/130218\">an asciinema</a>.</p>\n<p>No comment (or should I say \u201cComet\u201d on Oasis) because I don\u2019t know the answer, harhar. <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/slight_smile.png?v=6\" title=\":slight_smile:\" class=\"emoji\" alt=\":slight_smile:\">If I were you, I\u2019d check the path at <code>/oasis</code> to see if there are files there? It might be organized by user, project, group, you would find out! If that doesn\u2019t work, just explore the root (<code>/</code>) and you might find something.</p>",
        "<p>This seems extremely helpful and containers would ideal to reduce redundant work and  offer reproducibility. I appreciate your insight, and your humor! <img src=\"https://ask.cyberinfrastructure.org/images/emoji/twitter/blush.png?v=6\" title=\":blush:\" class=\"emoji\" alt=\":blush:\"><br>\n~ Cyd</p>"
    ],
    "275": [
        "<p>How can I prepare an R project for transfer and archiving?</p>\n<p>I have several project directories that are between 100 &amp; 700 Gigabyts each, by far the largest files are .Rdata. How can I cleanup and condense them for archiving without losing reproducibility?</p>",
        "<p>For existing workspaces in .Rdata, I can think of 2 options:</p>\n<p>For if rerunning the script from the beginning with the same inputs, gets the same files (use a diff) it is probably the same and you can save the inputs and script independently, if not you may have changed things.</p>\n<p>Separately you can compress the work space \u2013 it\u2019s anacdotal but I mostly here .xz does great (relative) compression, with moderate time.</p>\n<p>The advantage of a workspace is its edit-ability, but like most good things this can also create challenges.  Workspace space files store everything in active memory, including unused information in dataframes and variables that you reran with a new name but did not remove this can lead to bulky workspace files. This also means that if your operation resulting in the object in memory might not be identical to the operations in the script, introducing questions of reproducibility for the code.</p>\n<p>It is often preferable to write in chunks and rerun if you are developing in Rstudio. This can be as simple as clicking the source button after you\u2019ve added each section (if you have time consuming models, you can save the model matrix as a file and read it in to use it). Once the code is done, do a full run through with <code>Rscript --vanilla</code> and you can reasonably expect that other folks doing the same will get the same results.</p>",
        "<p>added note: For compression R by default uses gzip (and it\u2019s default compression level of -6).<br>\n<a href=\"https://stat.ethz.ch/R-manual/R-devel/library/base/html/save.html\" class=\"onebox\" target=\"_blank\">https://stat.ethz.ch/R-manual/R-devel/library/base/html/save.html</a><br>\nand you will probably get (the same or) better results adjusting the setting internally, than trying to run the file.rdata though a compression program, especially if its already been compressed.</p>"
    ],
    "325": [
        "<p>Is there a command/option you can run to determine the specifics of why a SLURM job is still pending execution besides the REASON CODE given by the squeue command (with default options)?   E.g. What resources is it waiting on and/or what currently running/pending jobs might be competing for those resources?</p>\n<p><strong>CURATOR:</strong> Jack Smith</p>",
        "<p>Here\u2019s one example, using the <strong>scontrol</strong> command using <strong>grep</strong> to filter out the out the other 30ish lines:</p>\n<pre><code>scontrol -d show job &lt;JOBID&gt; | grep Reason\n\nJobState=PENDING Reason=launch_failed_requeued_held Dependency=(null)</code></pre>",
        "<p>I don\u2019t think the standard Slurm commands will give you much beyond the REASON code.<br>\nAnd I believe that the REASON code is from the last time the job was examined in the normal scheduler run (I don\u2019t think it gets updated by the backfill process).  Depending where the job is in the queue, there may be a field SchedNodeList which will show you what nodes Slurm is thinking about using for this job (I believe this is available if REASON=Resources).  And note that the StartTime field may have the estimated start time for the job.  That\u2019s about all I ever found really usable for jobs with REASON=Resources.</p>\n<p>REASON=Priority and the various held states are pretty self explanatory.  Stuff like QOSResourceLimit, and AssocGrpCPUMinsLimit might take a little work to figure out what limit is being hit, but usually not to bad to do so.</p>\n<p>Other reasons, like \u201claunch_failed_requeued\u201d typically indicate something abnormal in the system, and the sysadmin should examine logs on the node the job ran on to see what is up.</p>",
        "<p>The most common Reason code is \u201cResources\u201d and if that is the case then a good place to look is your job\u2019s priority. That can be queried with the sprio command. That command should list all pending jobs with their priority number along with the priority factors that are used to calculate the overall number. You may want to restrict the output to the partition that you\u2019re job was submitted to. There may be several factors that weigh into your jobs priority depending on your site\u2019s configuration. You can see those weights with \u201csprio -w\u201d.<br>\nAnother thing that you may want to look at is if this job was submitted with any Dependency.</p>"
    ],
    "171": [
        "<p>I would like to parallelize my Python script over multiple nodes on the cluster. Which Python package is most efficient for this purpose?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p>For the python ecosystem, consider using <a href=\"http://dask.pydata.org/en/latest/\">Dask</a> which provides advanced parallelism for analytics. <a href=\"http://dask.pydata.org/en/latest/why.html\">Why use Dask</a> versus (or along with) other options? Dask integrates with Numpy, Pandas, and Scikit-Learn, and it also:</p>\n<ul>\n<li>\n<a href=\"http://dask.pydata.org/en/latest/why.html#scales-out-to-clusters\">scales up to clusters</a> with multiple nodes</li>\n<li>\n<a href=\"https://dask-jobqueue.readthedocs.io/en/latest/\">deployable on job queuing systems</a> like PBS, Slurm, MOAB, SGE, and LSF</li>\n<li>also <a href=\"http://dask.pydata.org/en/latest/why.html#scales-down-to-single-computers\">scales down to parallel usage of a single-node such as a server or laptop</a>\u2014 modern laptops often have a multi-core CPU, 16-32GB of RAM, and flash-based hard drives that can stream through data several times faster than HDDs or SSDs of even a year or two ago.</li>\n<li>supports a <a href=\"http://dask.pydata.org/en/latest/why.html#supports-complex-applications\">map-shuffle-reduce pattern</a> popularized by Hadoop and is a smaller, lightweight <a href=\"http://dask.pydata.org/en/latest/spark.html\">alternative to Spark</a>.</li>\n<li>works with <a href=\"http://dask.pydata.org/en/latest/setup/hpc.html#using-mpi\">MPI via mpi4py library</a> (see <a class=\"mention\" href=\"/u/jpessin1\">@jpessin1</a>\u2019s <a href=\"https://ask.cyberinfrastructure.org/t/what-is-the-most-efficient-python-package-to-run-a-parallel-job-over-multiple-nodes/171/2\">suggestion above</a>)  and compatible with <a href=\"http://dask.pydata.org/en/latest/setup/hpc.html#high-performance-network\">infiniband or other high speed networks</a>.</li>\n</ul>\n<p>See example <a href=\"https://dask-jobqueue.readthedocs.io/en/latest/#example\">Dask Jobqueue for PBS cluster</a>:</p>\n<pre><code class=\"lang-auto\">from dask_jobqueue import PBSCluster\ncluster = PBSCluster()\ncluster.scale(10)         # Ask for ten workers\n\nfrom dask.distributed import Client\nclient = Client(cluster)  # Connect this local process to remote workers\n\n# wait for jobs to arrive, depending on the queue, this may take some time\n\nimport dask.array as da\nx = ...                   # Dask commands now use these distributed resources\n</code></pre>\n<div class=\"lazyYT\" data-youtube-id=\"FXsgmwpRExM\" data-youtube-title=\"Dask on HPC Introduction\" data-width=\"480\" data-height=\"270\" data-parameters=\"feature=oembed&amp;wmode=opaque\"></div>",
        "<p>If you are looking for parallel processing the traditional (and still very valid) approach is use an MPI library,<br>\nmpi4py is an example of a python based wrapper, and <a href=\"https://mpi4py.readthedocs.io/en/stable/intro.html\">https://mpi4py.readthedocs.io/en/stable/intro.html</a><br>\nincludes a good overview of the concepts and related methods. (Not an endorsement, just not reinventing the wheel here)</p>\n<p>Some other things to consider:<br>\nWould it be less work to make the job fit on a single node?  With tools like concurrent.futures (or the underlying multiprocessing &amp; threading modules) or mixed tools like numpy/scipy/pandas with Cython?</p>\n<p><i>Would a faster python implementation (like pypy) provide enough speed? </i></p>\n<p>Not that they go away when you move to multi-node, but they are often, though not always sufficient and less demanding of the user/developers time.</p>",
        "<p><a class=\"mention\" href=\"/u/katia\">@katia</a>  As an aside if you are trying to bring more hardware resources to bear but the jobs don\u2019t require true parallelization, message queuing is an alternate/async approach, (queue is in the standard lib), there are several message queuing (MQ) systems out there for or in python off the top of my head zMQ (null-MQ), and RabbitMQ</p>"
    ],
    "513": [
        "<p>We\u2019re trying to run multi-node MPI computations with TURBOMOLE 7.3, specifically the ridft program. We are running Slurm on CentOS 7, and users do not have ssh access to compute nodes.</p>\n<p>From what I can see Turbomole really wants to use ssh (or rsh!) for communication among individual nodes.</p>\n<p>In similar situations (e.g. NAMD) I\u2019ve been able to write a ssh \u201cstand-in\u201d script that invokes srun under the hood, but I haven\u2019t been able to make one that works with Turbomole.</p>\n<p>Is anyone successfully running Turbomole in a slurm environment without ssh access?</p>",
        "<p>A few thoughts about this:</p>\n<ul>\n<li>\n<p>Re Turbomole using ssh/rsh to for communication among compute nodes: are you getting \u2018permission denied\u2019 errors?  Possibly each compute node needs to be configured with ssh key authentication.</p>\n</li>\n<li>\n<p>Re users not having access to compute nodes: is this in reference to job submission directory, or location of, say, input files?  Is it the user that needs access to compute nodes or that compute nodes need to read input files?</p>\n</li>\n<li>\n<p>Can you provide specific error messages or an example of the environment, the command or submission that produces the error and the error itself?</p>\n</li>\n</ul>\n<p>Thanks, torey</p>",
        "<p><em>Comment</em>: Have you had a chance to ask Turbomole directly? (<a href=\"http://www.turbomole-gmbh.com/contatus.html\">http://www.turbomole-gmbh.com/contatus.html</a> <a href=\"http://www.turbo-forum.com/\">www.turbo-forum.com/</a>)?</p>",
        "<p>Is the limitation with ssh because interactive user-access is totally unavailable, or is it due to the method/protocols ?</p>",
        "<p>I heard back from Turbomole support, and version 7.3 supports srun natively for mpi invocation, so no ssh needed. From what I can tell this is not mentioned in the <a href=\"http://www.turbomole-gmbh.com/manuals/version_7_3/Turbomole_Manual_7-3.pdf\" rel=\"nofollow noopener\">Turbomole Manual</a>.</p>\n<p>Turbomole bundles their own instance of IBM Platform MPI, and <a href=\"https://www.ibm.com/support/knowledgecenter/en/SSF4ZA_9.1.3/pmpi_guide/implied_srun_mpi.html\" rel=\"nofollow noopener\">those docs</a> do mention that you can include the following in your slurm script to tell MPI to use srun:</p>\n<p><code>export MPI_USESRUN=1</code></p>"
    ],
    "90": [
        "<p>On a Linux cluster with a SLURM scheduler, how do I discover the amount of temporary disk space available on each node so I can config my job and set <code>sbatch -\u2013tmp</code>?</p>\n<p><strong>CURATOR: Katia</strong></p>",
        "<p><strong>ANSWER:</strong></p>\n<p>Various clusters might be set slightly differently and which partition is recommended to use as a \u201ctemp\u201d might differ from cluster to cluster. One way to explore the environment on any scheduler is to submit a job that executes \u201cenv\u201d command. Here is an example of output of this command on the c3ddb cluster:</p>\n<pre><code class=\"lang-auto\">SLURM_CHECKPOINT_IMAGE_DIR=/scratch/users/koleinik\nSLURM_NODELIST=node005\n...\nTMPDIR=/tmp\n</code></pre>",
        "<p><strong>ANSWER:</strong> The amount of temporary disk space configured for a node that Slurm knows<br>\nabout can be displayed with the sinfo command.</p>\n<pre><code>sinfo -l -N\n</code></pre>\n<p>will list every node/partition combination along with various data, including<br>\na TMP_DISK field giving the available temporary disk space for the node in MB.</p>\n<p>As Katia mentioned, what this temporary disk is/where it is mounted might<br>\nvary from cluster to cluster, but the value returned by sinfo should be the<br>\nsame as is used by the scheduler when trying to meet the temporary disk requirement<br>\nspecified by the --tmp flag to sbatch.</p>\n<p>Sample output:</p>\n<pre><code>Tue Apr 17 11:12:25 2018\nNODELIST        NODES      PARTITION       STATE CPUS    S:C:T MEMORY TMP_DISK WEIGHT AVAIL_FE REASON              \ncompute-0001        1       standard   allocated   20   2:10:1 128000   750000      1   (null) none                \ncompute-0001        1      scavenger   allocated   20   2:10:1 128000   750000      1   (null) none \ncompute-0002        1       standard   allocated   20   2:10:1 128000   750000      1   (null) none                \n...\n</code></pre>\n"
    ],
    "136": [
        "<p>I work for an HPC center and have been training local HPC users for the last 5 years. We have developed  training to guide our users to scale their workflow on GPUs. I love teaching and would like to make this training available to researchers who are not aware of GPUs. I have heard about Software Carpentry and want to get involved in it to offer my expertise to a larger audience. How can I get involved in it?</p>\n<p>CURATOR: Raminder Singh</p>",
        "<p>I want to rephrase this question for you (and perhaps take it a little too far to be quora-esche\" by asking you What do you <em>enjoy</em> learning. Arguably, you already have a pretty good answer - you\u2019ve done training with GPUs, and if you\u2019ve continued it you must be having fun! So the answer to your question is simple - first become a participant in Software Carpentry, and give yourself the broadest exposure possible to the different topics. You will find yourself in one of two situations:</p>\n<ul>\n<li>you have vision for how your ideas fit into something that exists</li>\n<li>it doesn\u2019t really fit.</li>\n</ul>\n<p>For the first case, you can then identify the teachers and points of contact to discuss how you can fold in. For the second, this is the more fun opportunity, because you can reach out to the organizers and propose a different idea. You don\u2019t even necessarily need to follow some preset template of \u201ca teaching session must have slides followed by hands on programming\u201d - you could arguably teach in a way that best brings out your passion and has worked in the past.</p>\n<p>Likely both of the above will lead to good conversation, development, and be more productive than signing your name on some sheet and trying to fit the teacher mold. If the students are to best learn the material, they will do so from the teachers that are most excited to teach it. The teachers that are most excited to teach it probably are having the most fun doing it. That\u2019s how I would go about getting involved, and +1 points for making your material version controlled, possibly reproducible for others to teach, and thus having an even larger impact.</p>",
        "<p>The software carpentry movement main web-site <a href=\"https://software-carpentry.org/\">https://software-carpentry.org/</a> has a sub-page <a href=\"https://software-carpentry.org/join/\">https://software-carpentry.org/join/</a> that can be used to self identify as an interested participant. This is a great way to get started.</p>\n<p>The software carpentry web site also maintains a list of upcoming workshops globally <a href=\"https://software-carpentry.org/workshops/\">https://software-carpentry.org/workshops/</a>. Attending one of these workshops, or even volunteering to host one, can be a great way to get engaged.</p>",
        "<p>As of this writing, the menu at the top of the Software Carpentry website at <a href=\"https://software-carpentry.org\" rel=\"nofollow noopener\">https://software-carpentry.org</a> includes a drop down called \u201cGet Involved\u201d that does a great job of explaining how to get involved. Here\u2019s a screenshot:</p>\n<p><div class=\"lightbox-wrapper\"><a class=\"lightbox\" href=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7.jpg\" data-download-href=\"https://ask.cyberinfrastructure.org/uploads/default/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7\" title=\"Screen Shot 2018-03-30 at 8.12.01 AM.jpg\"><img src=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7_2_657x499.jpg\" alt=\"01%20AM\" width=\"657\" height=\"499\" srcset=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7_2_657x499.jpg, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7_2_985x748.jpg 1.5x, https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7_2_1314x998.jpg 2x\" data-small-upload=\"https://ask.cyberinfrastructure.org/uploads/default/optimized/1X/e26923d3e19aff2bc5c1d5c1bc6130f293fad8d7_2_10x10.png\"><div class=\"meta\">\n<svg class=\"fa d-icon d-icon-far-image svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#far-image\"></use></svg><span class=\"filename\">Screen Shot 2018-03-30 at 8.12.01 AM.jpg</span><span class=\"informations\">2292\u00d71742 734 KB</span><svg class=\"fa d-icon d-icon-discourse-expand svg-icon\" aria-hidden=\"true\"><use xlink:href=\"#discourse-expand\"></use></svg>\n</div></a></div></p>\n<p>This question is a little non-specific.</p>"
    ],
    "116": [
        "<p>My group regularly has to transfer multiple large (several TB) files to AWS for processing, we would like to use our institute\u2019s Globus service to move the files more efficiently.  How can I use Globus to transfer multiple TB-sized files between my local cluster and AWS S3 storage in a short amount of time?</p>\n<p><strong>CURATOR:</strong> jpessin1</p>",
        "<p>Globus offers a special tool to connect to AWS\u2019s s3 storage, unsurprisingly, it\u2019s called \u201cAmazon Web Services S3 Connector.\u201d</p>\n<p>You install this in an ec2, then you point it to a bucket, and configure the credentials, and you have a Globus endpoint.</p>\n<p>The Globus instructions are here:</p>\n<p><a href=\"https://docs.globus.org/premium-storage-connectors/aws-s3/\" class=\"onebox\" target=\"_blank\">https://docs.globus.org/premium-storage-connectors/aws-s3/</a></p>\n<p>and Northwestern has a nice walk through (and other considerations) that is generally useful:<br>\n<a href=\"https://kb.northwestern.edu/using-globus-with-s3\" class=\"onebox\" target=\"_blank\">https://kb.northwestern.edu/using-globus-with-s3</a></p>\n<p>One other thing to keep in mind, since the end point is an ec2 instance - it will have its own I/O limitations - select an instance that will have the throughput capacity you need. If you are dealing with both very large volume and multiple files, consider more instances instead of a bigger instance.<br>\n(Myself, I\u2019d tend toward the M5\u2019s, 4xL or smaller, YMMV)</p>"
    ],
    "271": [
        "<p>Is there a way to run one time commands at the beginning before the first task in the array or after the last task?</p>\n<p>Doing things like creating a new directory before hand to put all the output files in, or being able to tar and move them to a long term storage location would be very helpful.</p>",
        "<p>There are different, but combinable options for doing so by either when the first or last task starts<br>\nand for when all tasks finish:</p>\n<p><strong>When only concerned about when tasks start</strong>:<br>\nThe key is that SGE array jobs set some additional variables<br>\n<code>$SGE_TASK_FIRST</code>, <code>$SGE_TASK_LAST</code>, <code>$SGE_STEP_SIZE.</code></p>\n<blockquote>\n<p><code>#!/bin/bash</code><br>\n<code>#$ -t 1-100</code><br>\n<code>if [ $SGE_TASK_ID -eq $SGE_TASK_FIRST ] ; then</code><br>\n<code># do first-task stuff here</code><br>\n<code>fi</code></p>\n<p><code># do normal processing here</code></p>\n<p><code>if [ $SGE_TASK_ID -q $SGE_TASK_LAST ]; then</code><br>\n<code># do last-task stuff here</code><br>\n<code>fi</code></p>\n</blockquote>\n<p><strong>When concerned about when the last job finishes</strong>:<br>\nyou can use the <code>--sync</code> flag in a script</p>\n<blockquote>\n<p><code>qsub --sync y jobscript.sh &gt;&gt; exitstatus.log</code><br>\n<code># do things after</code></p>\n</blockquote>\n<p>Will wait on the submitted job(s) to complete and report its exit code before closing.<br>\nWith an array job it will wait on, and report on all of them.</p>",
        "<p>This seems rather clunky are there better ways?</p>"
    ],
    "110": [
        "<p>On the cluster, we need different flavors of netCDF, for example, with C and Fortran libraries. Where can I find an EasyBuild config file for this?</p>\n<p><strong>CURATOR:</strong> Raminder Singh</p>",
        "<p>There is a collection of Easybuild configuration files (called easyconfig files) in the Easybuild <a href=\"https://github.com/easybuilders\" rel=\"nofollow noopener\">github organization</a> in a repository called <a href=\"https://github.com/easybuilders/easybuild-easyconfigs\" rel=\"nofollow noopener\">easybuild-easyconfigs</a>.<br>\nWithin that repository you can find a subdirectory <a href=\"https://github.com/easybuilders/easybuild-easyconfigs/tree/master/easybuild/easyconfigs/n\" rel=\"nofollow noopener\"><code>easyconfigs/n</code></a>. This contains a set of Easybuild configuarition files in sub-directories <a href=\"https://github.com/easybuilders/easybuild-easyconfigs/tree/master/easybuild/easyconfigs/n/netCDF\" rel=\"nofollow noopener\"><code>netCDF</code></a> and <a href=\"https://github.com/easybuilders/easybuild-easyconfigs/tree/master/easybuild/easyconfigs/n/netCDF-Fortran\" rel=\"nofollow noopener\"><code>netCDF-Fortran</code></a>.</p>\n<p>There are 56 different compiler version, MPI version and netCDF version combination config files in the  <a href=\"https://github.com/easybuilders/easybuild-easyconfigs/tree/master/easybuild/easyconfigs/n/netCDF\" rel=\"nofollow noopener\"><code>netCDF</code></a> directory at the moment.  For each particular version of netCDF there are a handful of variants. Usually there is a <em>FOSS</em> tool chain (GNU compilers, OpenMPI) and and <em>Intel</em> toolchain option.</p>\n<p>If you have Easybuild already on a system then the sub-directory <code>software/EasyBuild/3.6.2/lib/python2.7/site-packages/easybuild_easyconfigs-3.6.2-py2.7.egg/easybuild/easyconfigs</code> within the Easybuild install directory will contain a similar tree of configuration files. In theory these can also be used to derive the many other combinations of compiler, MPI version, HDF parallel, netCDF version and so on.  I am not sure if there is an exhaustive set anywhere.</p>"
    ],
    "101": [
        "<p>How can I set up a personal environment modules file for my own build of LAMPPS, netCDF and MPI</p>\n<p><strong>CURATOR:</strong> Scott Yockel</p>",
        "<p>Details will vary a bit depending what version of the \u201cmodules\u201d command is<br>\nbeing used, but basically (to my knowledge) they all allow for the creation<br>\nof \u201cpersonal\u201d modules.  This is certainly true of the two big branches:<br>\nTcl Modules and Lmod.</p>\n<p>Basically, you can create a directory (typically <code>~/privatemodules</code> or something<br>\nsimilar) and then place your own module files there.  Then issue a module<br>\ncommand to add that directory to your modules path, and those modules are now<br>\naccessible for you to use.  I would suggest using names different than the<br>\nsystem supplied LAMMPS, netCDF, and MPI packages, so that it is both clear<br>\nwhich versions you are using and you can still access the system versions if<br>\ndesired.</p>\n<p>First, determine what modules system is used on your system.  If you don\u2019t<br>\nknow, try issuing the <code>module spider</code> command.  If it returns an \u201cunrecognized<br>\nsubcommand\u201d error, you are probably using Tcl modules.  If it returns a list<br>\nof modules, you are probably using Lmod.</p>\n<p>Whichever module system being used, you need to figure out the changes to<br>\nthe environment you wish the module package to implement.  Typically this<br>\nincludes adding directories to the path, maybe setting <code>LD_LIBRARY_PATH</code> and/or<br>\nother environmental variables, etc.  I would suggest creating modulefiles for<br>\neach version of each software package first, and then if desired you can create<br>\na \u201cbundle\u201d package that loads the standard version of the package set.</p>\n<p>If using Tcl modules, see<br>\n<a href=\"https://modules.readthedocs.io/en/stable/modulefile.html\" class=\"onebox\" target=\"_blank\">https://modules.readthedocs.io/en/stable/modulefile.html</a><br>\nfor details on how to write the modulefile.  You can then use the<br>\n<code>module use $DIR</code> command to add your directory to the module path.  If you<br>\nare using <code>~/privatemodules</code> as the directory, you could instead load the<br>\nuse.own module to add that path.</p>\n<p>If using Lmod, see e.g.<br>\n<a href=\"http://lmod.readthedocs.io/en/latest/100_modulefile_examples.html\" class=\"onebox\" target=\"_blank\">http://lmod.readthedocs.io/en/latest/100_modulefile_examples.html</a><br>\nfor help on writing the modulefiles.  You can then use the<br>\n<code>module use $DIR</code> command to add your directory to the module path.</p>"
    ],
    "232": [
        "<p>How many resources should I allocate for a typical Gaussian calculation? How do I assign them?</p>",
        "<p>Note that this is assuming that you are running common density functional theory (DFT, e.g. B3LYP) (or Moller-Plesset (MP2)) methods. Gaussian does not scale well for coupled cluster (e.g. CCSD) or configuration interaction (CISD) methods.</p>\n<p>For DFT methods, Gaussian will scale well up to 16 cores, with diminishing returns (or even losses!) past this point.</p>\n<p>Memory allocations will depend on the size of your molecules. Large systems or systems that contain heavy atoms (more electrons) will require more memory. 256-1024 MB per CPU is generally the optimal range. Note that using too little or too much total memory can also be detrimental to the calculation speed.</p>\n<p>Here are the results running a geometric optimization with DFT (B3LYP/6-31+G(d,p)) of a small sample molecule (aspirin) on a cluster:</p>\n<p><img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/7481dc49d36e2bbdd8238e5396702426fdb7ffe7.png\" alt=\"cpu%20mem%20gaussian\" width=\"218\" height=\"118\"></p>\n<p>In your Gaussian input file, you can specify these parameters with</p>\n<pre><code>%nprocshared=16\n%mem=8gb\n</code></pre>\n<p>You should also pass these parameters to the cluster in the batch file with:</p>\n<pre><code>#!/bin/bash\n#SBATCH -n 16\n#SBATCH --mem=9000\n</code></pre>\n<p>Note that it is best to allocate slightly more memory on the cluster than Gaussian is instructed to use (~9GB instead of 8GB in this case).</p>\n<p>Final notes:</p>\n<p>If you\u2019re using a cluster that has very small or heavily used nodes, you may wish to restrict the resources allocated, as running your Gaussian calculation on one node is virtually always advantageous compared to running the calculation across multiple nodes.</p>\n<p>Additionally, requesting fewer resources will also allow your job to start more quickly and is less likely to be interrupted by higher priority jobs.</p>"
    ],
    "86": [
        "<p>In AWS, what are class(es) of use-cases where batch is more efficient than a cluster build tool like CnfCluster?</p>",
        "<p><b>In short: </b></p>\n<p>AWS batch is great for large numbers of jobs with a simple work-flow pattern composed of autonomous jobs.</p>\n<p>Not so great for many types of finer control, like administration of user-space or jobs that require more than one instance/node</p>\n<p><b> The longer take :</b><br>\nThe primary advantages over something like Cnfcluster and many container management tools like mesosphere is that you have scheduling (on Spot) headlessly, and this, as often is the case, is also the main disadvantage.</p>\n<p>Batch is useful if you need a large number of (docker-compatible) container jobs that will run without interaction and want to queue them to spot - batch is exactly for that. This can be many things, two common uses are running large, one-time batch runs, and using another tool (often AWS\u2019s lambda) to start a job(s) up in response to a triggering event.  (These are pretty much the example life science use cases at <a href=\"https://aws.amazon.com/batch/use-cases/\">https://aws.amazon.com/batch/use-cases/</a> )</p>\n<p>You get queuing on AWS spot for limited effort, a config and maybe a lambda, plus your docker setup, without paying for a head node or unused uptime, and under some cases less setup/scheduling effort.</p>\n<p>The drawbacks (or disadvantages) from this are all in a way a lack of control.<br>\nIt isn\u2019t very practical to separate Admin and user space, AWS\u2019s IAM\u2019s are not a replacement for groups, limits, or other finer-grained controls like there are with modern HPC schedulers such as permissions/ACLs or groups.</p>\n<p>Additionally, the autonomous nature of the supported task can be an additional challenge in terms of coordination, the system may be ill-suited as a replacement for multi-node operations (such as message queues or MPI)</p>"
    ],
    "269": [
        "<p>I have a large set of jobs using the exact same script, just different input and output files.<br>\nHow can I run several hundred at a time?<br>\n(we have slurm and SGE)</p>\n<p>On SGE the test script looks like:</p>\n<blockquote>\n<p>#!/bin/bash<br>\n<code>#$ -N myjobname</code><br>\n<code>#$ -l h_vmem=100M</code><br>\n<code>#$ -pe smp 1</code><br>\n<code>#$ -cwd</code></p>\n<p>myscript infile.txt outfile.txt</p>\n</blockquote>\n<p><strong>Curator</strong> Jpessin</p>",
        "<p>That sound like a good use of the \u201c<strong>Array</strong>\u201d option. They\u2019re a type of general purpose option for running the same code many times with something (inputs /output / seeds etc.) different for each run, which is what you want for most simple parameter-sweeps. Take a look at:</p>\n<p>gridEngine (SGE &amp; co) <a href=\"http://wiki.gridengine.info/wiki/index.php/Simple-Job-Array-Howto\">http://wiki.gridengine.info/wiki/index.php/Simple-Job-Array-Howto</a><br>\nor<br>\nSlurm <a href=\"https://slurm.schedmd.com/job_array.html\">https://slurm.schedmd.com/job_array.html</a></p>\n<p>With SGE for simple situations use <code>-t &lt;m&gt;-&lt;n&gt;</code> where <code>&lt;m&gt;</code> and  <code>&lt;n&gt;</code>  are the number range for each run in your submit script which become the <code>$SGE_TASK_ID</code> variable which is unique for each task but share a <code>$JOB_ID</code></p>\n<p>So if you have input files input.1.txt to input.100.txt</p>\n<blockquote>\n<p><code>#!/bin/bash</code><br>\n<code>#$ -N myjobname</code><br>\n<code>#$ -l h_vmem=100M</code><br>\n<code>#$ -pe smp 1</code><br>\n<code>#$ -cwd</code></p>\n</blockquote>\n<p>Everything in the above will be true for each individual task separately.<br>\nThe following will loop through the range with the task id in the name for each.</p>\n<blockquote>\n<p><code>#$ -t 1-100</code><br>\n<code>myscript infile.$SGE_TASK_ID.txt outfile.$SGE_TASK_ID.txt</code></p>\n</blockquote>"
    ],
    "510": [
        "<p>Hey folks,</p>\n<p>We have some issues where users run \u201cmake -j\u201d on our systems login node which is causing massive performance issues for others connected. I know that if the  -j  option is given without an argument,  make will not limit the number of jobs that can run simultaneously.</p>\n<p>How do you handle users running make -j without a specified number of jobs? Do you simply document SOP is to always specify a number of jobs? Do you have people build on compute or interactive nodes rather than login? Do you use a wrapper for it? Are there other more proficient methods out there people are using?</p>\n<p>Max</p>",
        "<p>We don\u2019t do anything to control this on our systems: it\u2019s a problem that only comes up very, very rarely (usually when people are compiling C++ and <code>icpc</code> devours all the node\u2019s RAM).</p>\n<p>I guess <em>in principle</em>, you could probably set <code>MAKEFILES</code> in the default system profile to a file only containing the <code>.NOTPARALLEL</code> pseudo-target, which would inhibit parallel builds unless that variable was reset. This is a pretty opaque and surprising, though, with regards to the principles <a class=\"mention\" href=\"/u/jpessin1\">@jpessin1</a> mentioned.</p>\n<p>I tend to use something like <code>make -l $(( $(nproc) / 2 )) -j</code> if I\u2019m building on shared nodes myself: that starts as many jobs as it wants but won\u2019t start new processes if the load is above half the number of cores.</p>",
        "<p>+1  for <code>make -l</code></p>",
        "<p>For a shared environment, typical procedure is to use \u201cmake\u201d on the compute nodes.</p>\n<p>Most uses of \u201cmake\u201d on a cluster are compiling for larger builds with an occasional long running tasks e.g. using make as a work-flow manager. Neither of which are appropriate for typical shared login-nodes.</p>\n<p>On heterogeneous systems there is also the consideration of having the compiled program match the system it is being run on, which is part of a larger compatibility verse optimization question . (Modulefiles/LMOD is usually used to manage which runs where)</p>",
        "<p>JM2C:</p>\n<p>Capping the number of make threads with a wrapper seems like a challenge in terms of \u2018Unix Philosophy.\u2019 It is changing a behavior from one that is common to many systems, explicit in the documentation, and one that external programs such as cmake, automake/autoconf interact with.</p>\n<p>If you simply hide it behind a wrapper it\u2019s problematic in terms \u2018Least Surprise,\u2019 and \u2018Transparency.\u2019<br>\nWhere as being verbose to let folks know can interfere with automated functions and piping.<br>\n<a href=\"https://en.wikipedia.org/wiki/Unix_philosophy#Eric_Raymond%E2%80%99s_17_Unix_Rules\">https://en.wikipedia.org/wiki/Unix_philosophy#Eric_Raymond\u2019s_17_Unix_Rules</a></p>",
        "<p>If you want to control users running make, you have three options here.</p>\n<ol>\n<li>Allow them to run it (meaning, do nothing).</li>\n<li>Try to allow them to run it with some filter for catching \u201cspecial cases\u201d</li>\n<li>Don\u2019t allow them to run it.</li>\n</ol>\n<p>Option 1 is obviously not idea, hence the posting of your question to begin with. Option 2 goes against (the user\u2019s perception) of reliability and consistency, because it appears that running make is an okay thing to do, but then \u201cuhoh, this one time\u2026\u201d and so I don\u2019t think is ideal. Option 3 is not perfect because it <em>should</em> be the case that we are helping users to compile and do all the things they need to perform the task at hand.</p>\n<p>Let\u2019s step back though, how can we implement 3 (solving the issue) but also do so in a way that supports and educates? In the simplest case, we hide the binary and the user is upset that \u201cmake\u201d cannot be found. We get a ticket. But what if we allowed them to find it, but used it to inform them how we wanted make to be used for our cluster? For example:</p>\n<pre><code>cd mysciencething/\nmake\n# --- A Message from Research Computing ---#\n# We provide make for you on an interactive node! Please run:\n# $ sdev\n# to launch your node and try this command again\n</code></pre>\n<p>from a very practical standpoint, this meets requirements to handle the running of make without hurting users, but also educating them how to make the best decision in the future. The next or subsequent time this comes up, they would likely launch sdev without thinking.</p>"
    ],
    "991": [
        "<p>My setup has one head node which hosts a bootable image, which many compute nodes PXE boot from using grub. The issue is because of the varying hardware of the various nodes, I need different grub configurations (to load different images) to different clients.</p>\n<p>First, I tried <a href=\"https://docs.oracle.com/cd/E52668_01/E54695/html/ol7-install-pxe-boot-uefi.html\" rel=\"nofollow noopener\">this</a>. My network has all nodes with lets say configuration \u201cA\u201d under the IP range 10.0.1.1-10.0.15.255, and configuration \u201cB\u201d in the range 10.0.16.1-10.0.31-255. I tried creating the files <code>grub.cfg-0A000</code>, and <code>grub.cfg-0A001</code>, respectively, but it seemed to load the default grub.cfg anyway.</p>\n<p>Then, I tried using the variable $net_default_ip and the <code>regexp</code> command to determine which ip range the node is located in, and set a default menu item based on that. The issue is, there is next to no documentation about this command that I could find. I tried using a standard POSIX regex syntax: <code>if regexp /10\\.0\\.1\\.1/gx;</code>, but this conditional seems to return true every time, and the default menu item is simply my last if statement. Creating individual if statements for each node works: <code>if [ \"$net_default_ip\" = \"10.0.1.1\" ];</code>, however, I would prefer not to go this route because of the amount of nodes that this would have to be done for, not to mention new nodes that would be added in the future.</p>\n<p>Any help would be greatly appreciated, I\u2019m at a loss at this point.</p>",
        "<p>Have you looked at iPXE (<a href=\"http://ipxe.org\" rel=\"nofollow noopener\">http://ipxe.org</a>) for handling this? It\u2019s pretty straightforward to use PXE to bootstrap iPXE, and once done you can have iPXE pull its configuration from http(s). If you have that point to a simple CGI then you can have that CGI return whatever config you want based on the parameters it gets in the request, which can include things like the system MAC address, see <a href=\"http://ipxe.org/scripting\" rel=\"nofollow noopener\">http://ipxe.org/scripting</a></p>"
    ],
    "170": [
        "<p>I generated a set of random numbers in my R script. I need to run this script 50,000 times. How can I ensure the randomness of these sets of numbers between each job when I submit the 50K jobs to the cluster?</p>\n<p><strong>CURATOR:</strong> Katia</p>",
        "<p>I would ask the guys that make this package -&gt; <a href=\"https://ignaciomsarmiento.github.io/2018/11/11/RDperm.html\" rel=\"nofollow noopener\">https://ignaciomsarmiento.github.io/2018/11/11/RDperm.html</a> they might even be able to add an HPC example (I think this would be useful to others!)</p>"
    ],
    "1035": [
        "<p>Just curious if anyone has any comments regarding a problem we are seeing on our now skylake cluster.  All MPI/compiler combinations including intel-2018, intel-2019, gcc-9.1.0 with openmpi/mvapich2 as well as intel-2018-mpi run fine on all 960 cores, however, intel-2019-mpi on more than ~300 cores fails.   We can switch the FI_PROVIDER from ofi_rxm to verbs, but then all codes slow down significantly (but no crash).</p>\n<p>I have posted a message on Mellanox\u2019s forum and was told I should contact Intel.  I have also tried to post on Intel\u2019s HPC forum and the libfabric forum, but these messages are stuck in moderation.</p>\n<h2>Anyway, if anyone has any pointers for this.  I am really interested in using intel-2019 mpi.</h2>\n<p>Hi, we are currently standing up a new cluster with Mellanox ConnectX-5 adapters. I have found that using openMPI, mvapich2, and intel2018-mpi, we can run MPI jobs on all 960 cores in the cluster, however, using intel2019-mpi we can\u2019t get beyond ~300 mpi ranks. If we do, we get the following error for every rank:</p>\n<h2>Abort(273768207) on node 650 (rank 650 in comm 0): Fatal error in PMPI_Comm_split: Other MPI error, error stack:<br>\nPMPI_Comm_split(507)\u2026: MPI_Comm_split(MPI_COMM_WORLD, color=0, key=650, new_comm=0x7911e8) failed<br>\nPMPI_Comm_split(489)\u2026:<br>\nMPIR_Comm_split_impl(167)\u2026:<br>\nMPIR_Allgather_intra_auto(145)\u2026: Failure during collective<br>\nMPIR_Allgather_intra_auto(141)\u2026:<br>\nMPIR_Allgather_intra_brucks(115)\u2026:<br>\nMPIC_Sendrecv(344)\u2026:<br>\nMPID_Isend(662)\u2026:<br>\nMPID_isend_unsafe(282)\u2026:<br>\nMPIDI_OFI_send_lightweight_request(106):<br>\n(unknown)(): Other MPI error</h2>\n<p>This is using the default FI_PROVIDER of ofi_rxm. If we switch to using \u201cverbs\u201d, we can run all 960 cores, but tests show an order of magnitude increase in latency and much longer run times.</p>\n<p>We have tried installing our own libfabrics (from the git repo ; also we verified with verbose debugging that we are using this libfabrics) and this behavoir does not change</p>\n<p>Is there anything I can change to allow all 960 cores using the default ofi_rxm provider?  Or, is there a way to improve performance using the verbs provider?</p>\n<p>For completeness:<br>\nUsing MLNX_OFED_LINUX-4.6-1.0.1.1-rhel7.6-x86_64 ofed<br>\nCentOS 7.6.1810 (kernel = 3.10.0-957.21.3.el7.x86_64)<br>\nIntel Parallel studio version 19.0.4.243<br>\nInfiniband controller: Mellanox Technologies MT27800 Family [ConnectX-5]</p>\n<p>Thanks!</p>\n<p>Eric</p>",
        "<p>Eric, we have a very similar system, and have Intel 19 in the queue to install, and can move it up.</p>\n<p>It seems counterintuitive that mpi over libfabric over verbs is a lot faster than mpi over verbs, but a lot of counterintuitive things are true.  If you could show some low-level benchmarks like osu_latency with intel 18/19/verbs/libfabric, that would help.</p>\n<p>Thanks,<br>\nDavid Chaffin<br>\nUArk</p>",
        "<p>Hi David,</p>\n<p>Thanks for reaching out.   According to Intel support, this is a bug and the next update will fix this.</p>\n<p>Anyway, I was able to compile my own libfabric v1.8.0 and I believe things are working OK now when I swap the intel 2019-mpi fabric provider out and provide my own.</p>\n<p>As far as the latency results, I think that Intel-2019-mpi just has some problems with the verbs provider.  Here are some results I just generated using Intel-2019 and Intel-2018 with/without my own libfabric:</p>\n<p>Note, the Intel2019 provided libfabric verbs is much worse than my own libfabric.  Also, the Intel2019 provided libfabric verbs crashes when the number of cores &gt; 300 or so.  This doesn\u2019t happen with my own libfabric.   Also note that both libfabric verbs are worse than than intel2018, intel2019 with FI_PROVIDER=ofi_rxm and intel2019 w/ openMPI.</p>\n<p>All of these tests were done on two nodes, one core each:</p>\n<ol>\n<li>intel/2019 + intel/2019+mpi:<br>\n[slurm&gt; [7 ewalter@fm03 ~/osu_intel2019/mpi/pt2pt ]$srun ./osu_latency</li>\n</ol>\n<h1>OSU MPI Latency Test v5.4.1</h1>\n<h1>Size          Latency (us)</h1>\n<p>0                       1.34<br>\n1                       1.34<br>\n2                       1.34<br>\n4                       1.35<br>\n8                       1.34<br>\n16                      1.34<br>\n32                      1.34<br>\n64                      1.37<br>\n128                     1.40<br>\n256                     1.97<br>\n512                     2.06<br>\n1024                    2.29<br>\n2048                    2.75<br>\n4096                    3.67<br>\n8192                    5.18<br>\n16384                   7.86<br>\n32768                  10.52<br>\n65536                  15.27<br>\n131072                 23.25<br>\n262144                 85.20<br>\n524288                126.66<br>\n1048576               208.21<br>\n2097152               367.19<br>\n4194304               691.05</p>\n<ol start=\"2\">\n<li>Same but did export FI_PROVIDER=^ofi_rxm    (Intel docs say this is how to choose \u201cverbs\u201d instead of \u201cofi_rxm\u201d:</li>\n</ol>\n<p>[slurm&gt; [8 ewalter@fm03 ~/osu_intel2019/mpi/pt2pt ]$export FI_PROVIDER=^ofi_rxm<br>\n[slurm&gt; [9 ewalter@fm03 ~/osu_intel2019/mpi/pt2pt ]$srun ./osu_latency</p>\n<h1>OSU MPI Latency Test v5.4.1</h1>\n<h1>Size          Latency (us)</h1>\n<p>0                      48.79<br>\n1                      48.86<br>\n2                      49.05<br>\n4                      49.04<br>\n8                      48.97<br>\n16                     49.02<br>\n32                     49.49<br>\n64                     51.34<br>\n128                    52.55<br>\n256                    58.17<br>\n512                    99.53<br>\n1024                  156.44<br>\n2048                   91.36<br>\n4096                  111.51<br>\n8192                  143.85<br>\n16384                 215.19<br>\n32768                 356.01<br>\n65536                 634.66<br>\n131072               1191.38<br>\n262144               2313.45<br>\n524288               4548.35<br>\n1048576              9012.70</p>\n<ol start=\"3\">\n<li>Same as 2 but using my own libfabric verbs:</li>\n</ol>\n<p>[slurm&gt; [2 ewalter@fm03 ~/osu_intel2019/mpi/pt2pt ]$env|grep FI_<br>\nFI_PROVIDER_PATH=/usr/local/skylake/gcc-4.8.5/libfabric-1.8.0/lib/libfabric:/usr/local/skylake/gcc-4.8.5/libfabric-1.8.0/lib<br>\nFI_PROVIDER=^ofi_rxm<br>\n[slurm&gt; [3 ewalter@fm03 ~/osu_intel2019/mpi/pt2pt ]$srun -n 2 ./osu_latency</p>\n<h1>OSU MPI Latency Test v5.4.1</h1>\n<h1>Size          Latency (us)</h1>\n<p>0                       1.92<br>\n1                       1.91<br>\n2                       1.91<br>\n4                       1.91<br>\n8                       1.91<br>\n16                      1.91<br>\n32                      1.93<br>\n64                      1.94<br>\n128                     2.01<br>\n256                     2.55<br>\n512                     3.20<br>\n1024                    2.76<br>\n2048                    3.18<br>\n4096                    4.52<br>\n8192                    5.74<br>\n16384                   7.87<br>\n32768                  10.44<br>\n65536                  16.10<br>\n131072                 27.73<br>\n262144                 52.73<br>\n524288                104.75<br>\n1048576               219.32<br>\n2097152               444.31<br>\n4194304               895.42</p>\n<ol start=\"4\">\n<li>Now with intel/2018 + intel/2018-mpi:</li>\n</ol>\n<h1>OSU MPI Latency Test v5.4.1</h1>\n<h1>Size          Latency (us)</h1>\n<p>0                       1.30<br>\n1                       1.30<br>\n2                       1.30<br>\n4                       1.30<br>\n8                       1.30<br>\n16                      1.30<br>\n32                      1.79<br>\n64                      1.80<br>\n128                     1.86<br>\n256                     1.96<br>\n512                     2.06<br>\n1024                    2.21<br>\n2048                    2.63<br>\n4096                    3.38<br>\n8192                    4.86<br>\n16384                   6.67<br>\n32768                   9.31<br>\n65536                  13.78<br>\n131072                 21.16<br>\n262144                 86.97<br>\n524288                127.97<br>\n1048576               208.06<br>\n2097152               365.83<br>\n4194304               672.90</p>\n<ol start=\"5\">\n<li>Finally, intel2019 with openmpi-3.1.4:</li>\n</ol>\n<p>[slurm&gt; [1 ewalter@fm03 ~/osu_intel2019_ompi/mpi/pt2pt ]$srun ./osu_latency</p>\n<h1>OSU MPI Latency Test v5.4.1</h1>\n<h1>Size          Latency (us)</h1>\n<p>0                       1.21<br>\n1                       1.24<br>\n2                       1.24<br>\n4                       1.24<br>\n8                       1.27<br>\n16                      1.27<br>\n32                      1.30<br>\n64                      1.39<br>\n128                     1.94<br>\n256                     2.05<br>\n512                     2.18<br>\n1024                    2.42<br>\n2048                    2.78<br>\n4096                    3.84<br>\n8192                    5.18<br>\n16384                   7.00<br>\n32768                   9.12<br>\n65536                  12.20<br>\n131072                 21.61<br>\n262144                 32.46<br>\n524288                 56.39<br>\n1048576                97.14<br>\n2097152               180.75<br>\n4194304               353.95</p>\n<p>Let me know if you have any questions or comments.</p>\n<p>Thanks!</p>\n<p>Eric</p>",
        "<p>Eric,</p>\n<p>ofi_rxm doesn\u2019t look very good, does it?</p>\n<p>I did the OSU latency and bw tests with both single-node shared memory and two-node over IB.<br>\nCentos and OFED are about 1 version older.</p>\n<p>Centos 3.10.0-957.10.1<br>\nMOFED 4.5.1.0.1.1<br>\nIntel MPI 18.0.2 and 19.0.4<br>\nConnect-X5<br>\nunmodified intel libfabric<br>\n19.0.4:<br>\n<span class=\"math\"> export I_MPI_FABRICS=shm:ofi\n</span> export FI_PROVIDER=verbs</p>\n<p>I haven\u2019t tried a large run yet, but these data seem to show IB performance in 19.0.4 is slightly improved and zero-size latency is slightly improved,  but there is a pretty significant regression in shared-memory performance for large transfers.</p>\n<div class=\"md-table\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n<th>latency</th>\n<th></th>\n<th></th>\n<th></th>\n<th>bandwidth</th>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Size</td>\n<td>18.0.2 SHM</td>\n<td>18.0.2 IB</td>\n<td>19.0.4 SHM</td>\n<td>19.0.4 IB</td>\n<td>18.0.2 SHM</td>\n<td>18.0.2 IB</td>\n<td>19.0.4 SHM</td>\n<td>19.0.4 IB</td>\n</tr>\n<tr>\n<td>0</td>\n<td>0.66</td>\n<td>1.21</td>\n<td>0.4</td>\n<td>1.16</td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n<tr>\n<td>1</td>\n<td>0.94</td>\n<td>1.22</td>\n<td>0.4</td>\n<td>1.16</td>\n<td>1.78</td>\n<td>2.73</td>\n<td>3.59</td>\n<td>5.42</td>\n</tr>\n<tr>\n<td>2</td>\n<td>0.94</td>\n<td>1.22</td>\n<td>0.4</td>\n<td>1.17</td>\n<td>3.63</td>\n<td>5.6</td>\n<td>7.09</td>\n<td>10.93</td>\n</tr>\n<tr>\n<td>4</td>\n<td>0.94</td>\n<td>1.22</td>\n<td>0.4</td>\n<td>1.17</td>\n<td>7.38</td>\n<td>11.16</td>\n<td>14.42</td>\n<td>22.11</td>\n</tr>\n<tr>\n<td>8</td>\n<td>0.94</td>\n<td>1.22</td>\n<td>0.4</td>\n<td>1.17</td>\n<td>14.68</td>\n<td>22.43</td>\n<td>29.2</td>\n<td>44.22</td>\n</tr>\n<tr>\n<td>16</td>\n<td>0.94</td>\n<td>1.22</td>\n<td>0.4</td>\n<td>1.18</td>\n<td>29.25</td>\n<td>44.83</td>\n<td>58.73</td>\n<td>88.36</td>\n</tr>\n<tr>\n<td>32</td>\n<td>0.97</td>\n<td>1.28</td>\n<td>0.41</td>\n<td>1.15</td>\n<td>60.93</td>\n<td>87.79</td>\n<td>111.7</td>\n<td>179.1</td>\n</tr>\n<tr>\n<td>64</td>\n<td>0.98</td>\n<td>1.68</td>\n<td>0.41</td>\n<td>1.19</td>\n<td>134.3</td>\n<td>157.79</td>\n<td>226.13</td>\n<td>355.12</td>\n</tr>\n<tr>\n<td>128</td>\n<td>1.03</td>\n<td>1.71</td>\n<td>0.54</td>\n<td>1.24</td>\n<td>266.58</td>\n<td>312.79</td>\n<td>416.61</td>\n<td>665.17</td>\n</tr>\n<tr>\n<td>256</td>\n<td>0.99</td>\n<td>1.74</td>\n<td>0.58</td>\n<td>1.65</td>\n<td>523.78</td>\n<td>617.98</td>\n<td>1122.71</td>\n<td>1251.76</td>\n</tr>\n<tr>\n<td>512</td>\n<td>1.14</td>\n<td>1.82</td>\n<td>0.8</td>\n<td>1.73</td>\n<td>872.19</td>\n<td>1182.07</td>\n<td>872.98</td>\n<td>2495.59</td>\n</tr>\n<tr>\n<td>1024</td>\n<td>1.42</td>\n<td>1.97</td>\n<td>0.86</td>\n<td>1.91</td>\n<td>1465.47</td>\n<td>2209.63</td>\n<td>1209.55</td>\n<td>4316.68</td>\n</tr>\n<tr>\n<td>2048</td>\n<td>1.51</td>\n<td>2.34</td>\n<td>1</td>\n<td>2.29</td>\n<td>2344.37</td>\n<td>3856.31</td>\n<td>2051.44</td>\n<td>6367.19</td>\n</tr>\n<tr>\n<td>4096</td>\n<td>2.1</td>\n<td>2.92</td>\n<td>1.44</td>\n<td>3.07</td>\n<td>3185.61</td>\n<td>6148.02</td>\n<td>3797.18</td>\n<td>8060.09</td>\n</tr>\n<tr>\n<td>8192</td>\n<td>3.86</td>\n<td>4.13</td>\n<td>1.9</td>\n<td>4.32</td>\n<td>4219.96</td>\n<td>8352.73</td>\n<td>5494.97</td>\n<td>9239.97</td>\n</tr>\n<tr>\n<td>16384</td>\n<td>5.79</td>\n<td>5.38</td>\n<td>3.31</td>\n<td>6.74</td>\n<td>4710.59</td>\n<td>8521.69</td>\n<td>6699.2</td>\n<td>10219.29</td>\n</tr>\n<tr>\n<td>32768</td>\n<td>11.59</td>\n<td>7.62</td>\n<td>5.18</td>\n<td>9.3</td>\n<td>5198.02</td>\n<td>10567.78</td>\n<td>7501.25</td>\n<td>10752.05</td>\n</tr>\n<tr>\n<td>65536</td>\n<td>8.16</td>\n<td>11.1</td>\n<td>9.3</td>\n<td>12.67</td>\n<td>12671.75</td>\n<td>10856.02</td>\n<td>8053.1</td>\n<td>11419.71</td>\n</tr>\n<tr>\n<td>131072</td>\n<td>10.76</td>\n<td>18.63</td>\n<td>18.35</td>\n<td>19.47</td>\n<td>14723.34</td>\n<td>11740.45</td>\n<td>8345.94</td>\n<td>10722.96</td>\n</tr>\n<tr>\n<td>262144</td>\n<td>18.37</td>\n<td>32.14</td>\n<td>35.29</td>\n<td>71.74</td>\n<td>16153.7</td>\n<td>11837.02</td>\n<td>8353.96</td>\n<td>10132.35</td>\n</tr>\n<tr>\n<td>524288</td>\n<td>35.13</td>\n<td>126.22</td>\n<td>84.07</td>\n<td>112.44</td>\n<td>16253.88</td>\n<td>11628.41</td>\n<td>8331.19</td>\n<td>11583.93</td>\n</tr>\n<tr>\n<td>1048576</td>\n<td>81.57</td>\n<td>208.41</td>\n<td>169.7</td>\n<td>193.16</td>\n<td>13875.37</td>\n<td>11720.75</td>\n<td>7590.23</td>\n<td>11606.28</td>\n</tr>\n<tr>\n<td>2097152</td>\n<td>204.52</td>\n<td>377.61</td>\n<td>337.33</td>\n<td>349.34</td>\n<td>10451.14</td>\n<td>11771.32</td>\n<td>7348.55</td>\n<td>11600.84</td>\n</tr>\n<tr>\n<td>4194304</td>\n<td>439.36</td>\n<td>740.37</td>\n<td>670.89</td>\n<td>678.62</td>\n<td>9806.69</td>\n<td>11767.09</td>\n<td>7591.09</td>\n<td>11631.22</td>\n</tr>\n</tbody>\n</table>\n</div>",
        "<p>Hi David,</p>\n<p>Thanks for running these tests and the info.</p>\n<p>It looks like we get similar results for the IB tests.  I repeated my tests using SHM (2 cores on 1 node) and also get similar results (with the nosedive at the larger message sizes).</p>\n<p>So it turns out that this seems to be wrong (or, at least I am misunderstanding it):</p>\n<p>From: <a href=\"https://software.intel.com/en-us/mpi-developer-guide-linux-ofi-providers-support\" rel=\"nofollow noopener\">https://software.intel.com/en-us/mpi-developer-guide-linux-ofi-providers-support</a></p>\n<p>\u201cThe verbs provider uses RxM utility provider to emulate FI_EP_RDM endpoint over verbs FI_EP_MSG endpoint by default. The verbs provider with FI_EP_RDM endpoint can be used instead of RxM by setting the FI_PROVIDER=^ofi_rxm runtime parameter,\u201d</p>\n<p>I find that this results the provider becoming <em>sockets</em> for me.   Using FI_PROVIDER=verbs gives similar results as the default ofi_rxm provider using intel-2019, but <em>both</em> results in segfaults at larger numbers of cores (~400).   When I use my own built libfabric, I get the results I posted before (set <span class=\"hashtag\">#3</span>), which are somewhat worse in latency, but much worse in the osu_bw test:</p>\n<h1>OSU MPI Bandwidth Test v5.4.1</h1>\n<p>FI_PROVIDER_PATH=/usr/local/skylake/gcc-4.8.5/libfabric-1.8.0/lib/libfabric:/usr/local/skylake/gcc-4.8.5/libfabric-1.8.0/lib<br>\nFI_PROVIDER=^ofi_rxm</p>\n<h1>Size      Bandwidth (MB/s)</h1>\n<pre><code>1                       1.39\n2                       2.82\n4                       5.66\n8                      11.31\n16                     22.86\n32                     45.56\n64                     89.51\n128                   176.62\n256                   349.46\n512                   564.31\n1024                 1317.93\n2048                 2318.49\n4096                 2800.52\n8192                 4030.74\n16384                4743.87\n32768                5668.91\n65536                6082.44\n131072               6236.04\n262144               6293.15\n524288               6138.85\n1048576              5645.81\n2097152              5597.79\n4194304              5589.22\n</code></pre>\n<p>I would love to see if you also get crashes for intel-2019 with 400 or so cores.  For instance, osu_gather crashes at size=32768 on 400 cores for me.  When I try to use 896 cores, it crashes before any test is run.</p>\n<p>I am going to steer users away from Intel-2019 mpi (and instead use OpenMPI) until the next update comes out (in a few weeks).</p>\n<p>Thanks again,</p>\n<p>Eric</p>"
    ],
    "971": [
        "<p>I found Ohio Supercomputer Center\u2019s Open OnDemand, and I\u2019m interested in developing interactive apps for it. What are some of my options?</p>",
        "<p>If your institution has OnDemand running on a cluster, then your admin can enable a sandbox for you to develop in. You can <a href=\"https://osc.github.io/ood-documentation/master/app-development/enabling-development-mode.html\" rel=\"nofollow noopener\">point him or her to the documentation here</a>. If you want to develop locally, then you have a few options! There are some Vagrant images that you can build:</p>\n<ul>\n<li><a href=\"https://github.com/OSC/ood-images\" rel=\"nofollow noopener\">https://github.com/OSC/ood-images</a></li>\n<li><a href=\"https://github.com/OSC/ood-images-full\" rel=\"nofollow noopener\">https://github.com/OSC/ood-images-full</a></li>\n</ul>\n<p>or a recent ood-compose (that uses Docker Compose) that I created to bring up a cluster (SLURM) easily.</p>\n<ul>\n<li><a href=\"https://www.github.com/vsoch/ood-compose\" rel=\"nofollow noopener\">https://www.github.com/vsoch/ood-compose</a></li>\n</ul>",
        "<p>For anyone looking for more information about Open OnDemand, our website is <a href=\"http://openondemand.org/\" rel=\"nofollow noopener\">http://openondemand.org/</a></p>\n<p>We also have a very active discussion board at <a href=\"https://discourse.osc.edu/c/open-ondemand\" rel=\"nofollow noopener\">https://discourse.osc.edu/c/open-ondemand</a></p>"
    ],
    "262": [
        "<p>Some of my calculations are taking a long time to run on a single compute node, and I would like to speed them up as much as possible.  I am also willing to use semi-empirical methods such as DFT, or even a fragmentation method, if they scale better for my system.</p>",
        "<p>Scalability and parallelization in GAMESS varies greatly depending on the QM method being used.</p>\n<p>For example, the distributed memory MP2 algorithm scales extremely well across many nodes, up to thousands of cores.</p>\n<p>On the other hand, most semi-empirical methods in GAMESS are serial algorithms that do not benefit from more than one core.</p>\n<p>However, from a speed perspective the serial semi-empirical methods are going to be significantly faster than running the same calculation with MP2.</p>\n<p>But both of these methods are applicable to very different types of chemical problems. You really need to give more specifics about the chemistry you are investigating.</p>\n<p>Before you start your project, you need to identify the correct level of theory to use based on the chemistry, and then start performing some test calculations and investigating parallelization strategies.</p>",
        "<p>Adding to the spruitt\u2019s answer above:</p>\n<ul>\n<li>Hartree-Fock, DFT, MP2 all will scale quite well</li>\n<li>MCSCF: it depends on orbital optimizer and CI method</li>\n<li>Full CI (ALDET) method does NOT scale beyond one process</li>\n</ul>\n<p>GAMESS official reference on parallelization, etc \u2013 it digs very deep:</p>\n<p><a href=\"http://www.msg.ameslab.gov/gamess/GAMESS_Manual/prog.pdf\" class=\"onebox\" target=\"_blank\">http://www.msg.ameslab.gov/gamess/GAMESS_Manual/prog.pdf</a></p>\n<p>Some notes on GAMESS parallelization with benchmarks (unfortunately graphs are too small)</p>\n<p><a href=\"http://www.sdsc.edu/~kimb/gmstuff/parallel.html\" class=\"onebox\" target=\"_blank\">http://www.sdsc.edu/~kimb/gmstuff/parallel.html</a></p>"
    ],
    "261": [
        "<p>GAMESS has a long list of files it uses during a calculation, but my local cluster has very slow local disks.  Even worse, the system I am using remotely has no local disks on the compute node and I have to use the remote filesystem to store these files!</p>",
        "<p>There are some system level options in GAMESS that can help reduce the amount of disk I/O depending on the method being used.</p>\n<p>Check the input keywords MODIO and MEM10 in the $SYSTEM control group in the GAMESS manual.  These two keywords provide control over storage of the dictionary file in memory, reduction of print statements and file flushing during calculations, and additional GDDI options for FMO calculations.</p>\n<p>On large super computers such as some Cray systems, if there are no local disks it is beneficial to store GAMESS files in a RAM disk (e.g. /tmp directory) as well.  Otherwise, the I/O to the network parallel filesystem will make the calculations run very slowly.</p>"
    ],
    "109": [
        "<p>I\u2019m used to doing cost analysis for on premise setups and am trying to compare costs between running an on premise HPC to an all-cloud (AWS) HPC. How are the cloud pricing schemes with features like suspend different from owning the hardware?</p>\n<p><strong>CURATOR:</strong> jpessin1</p>",
        "<p><strong>ANSWER:</strong> With Cloud services like AWS, you are paying for utilization. So with a system configured to take advantage of this during down time, you are only paying for storage during down time (ESB, S3 etc.)<br>\nand, if you don\u2019t have an Egress waiver (for exporting data back out), a network fee for exported data.<br>\nMore here: <a href=\"https://aws.amazon.com/blogs/publicsector/aws-offers-data-egress-discount-to-researchers/\">https://aws.amazon.com/blogs/publicsector/aws-offers-data-egress-discount-to-researchers/</a></p>\n<p>\u2013 For a typical multi-user setup on AWS - an always on login/headnode and a spot-base \u201ccompute-fleet\u201d with auto-scaling for compute nodes, most of the saving (if any) comes from the spot fleet - where you can set a maximum price per as a bid and they turn themselves off at the end of a job (or job set)<br>\n<a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html\" class=\"onebox\" target=\"_blank\">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/how-spot-instances-work.html</a><br>\n<a href=\"https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html#on-demand-in-spot\" class=\"onebox\" target=\"_blank\">https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/spot-fleet.html#on-demand-in-spot</a></p>\n<p>A word of caution -  this is the AWS defined <i>Stopped</i> state of the instance, and while it is often tied to OS functions, the cost is tied to the instance (VM) occupancy and not activity, so if a user hibernate or suspend function is called to enter a low power state, you are still occupying the EC2 instance and will be billed for it.</p>"
    ],
    "1063": [
        "<p>Hello,</p>\n<p>We\u2019re re-evaluating the battery back up policies for our data center.  Currently we have all nodes on battery back up; head nodes, storage nodes, compute nodes.  We are thinking of no longer backing up compute nodes, and are wondering what hardware/nodes other institutions consider critical to back up (via battery).  If other HPC centers have experience and/or advice they would be willing to share I\u2019d very much appreciate the wisdom!</p>",
        "<p>We have our entire data center protected by double-conversion flywheel UPSes, just long enough to keep things up before backup generators can kick on in the event of a power outage.  Personally, I\u2019d suggest against segregating your data center in such a way.</p>\n<p>That being said, our data center has more than just our HPC clusters.  A fair amount of space is used for data storage, and alot of our space is used for things that aren\u2019t clusters.  That\u2019s intentional, though; if you are building a data center around a cluster, and aren\u2019t going to use it for anything else, then of course things will be different.</p>\n<p>But it\u2019s also nice having the peace-of-mind.  We don\u2019t have to take the risk that someone plugged a storage controller into the non-UPS rack.  We don\u2019t have to deal with a transient power issue knocking out all of the compute nodes, not only from the sudden workload of having to bring everything back up, but also from the impact to our reputation.  It can be hard telling users that they\u2019ve lost a day of compute because we decided to save $X in capital costs.  And of course the outage would happen when there\u2019s a critical grant deadline.</p>\n<p>All that being said, there are still ways you can save money.  We use flywheel UPSes, so there are no batteries to replace.  We do fresh-air cooling whenever possible, which saves on power costs.  Our PDUs run at 240 VAC line-to-neutral (415 VAC line-to-line), which means we only need a single set of transformers (prior to the UPS), plus a small 120/240 transformer for office spaces. And our data center is single-fed:  We have two sets of cables coming in to the building, but we are getting power from just one substation.  Each rack only has one PDU, and row only has one set of busbars, and traces back to only one UPS.  We have to shut everything down once every 5 years, for several days of maintenance, but it was deemed to be an acceptable trade-off for a research data center.</p>",
        "<p>The batteries keep our systems up and constant power while the generator gets up to point where it produce the energy need.  This eliminates equipment failures sometimes experienced with rapid power lost.  It has been my experience that turning on and off equipment increases the risk of equipment failure.  The sudden lost of power also can also increase risks of leaving software applications in unstable states and the time required to clean up after power failures more than pays for the cost of the batteries.</p>"
    ],
    "80": [
        "<p>Many resource schedulers provide a way to indicate the duration of wall clock time a job will require. What are  tips and tricks for estimating the duration to specify prior to execution of a job?</p>\n<p><strong>CURATOR:</strong> Scott Yockel</p>",
        "<p><strong>ANSWER:</strong> It would depend on application. But there are common approaches:<br>\nIf there is a loop (for example with iterator ranging from 1 to a number of simulations), one can run a job for a few iterations (assuming that all iterations take approximately the same time) and then based on this estimate the time it would take to run the full job.</p>\n<p>In some other cases running a program for a smaller input allows estimating the time for a larger input.</p>",
        "<p>In addition to the situations described by Katia, one might need to estimate how a job might scale.  There are several options, depending on what data, if any, is available.  One can extrapolate from as little as two timing instances, say completion on two nodes and completion on 8 nodes (or core, or other resource \u2018unit\u2019).  If one knows how long a serial run takes, and has data points of runtimes from a completely different computation, those three numbers can be used to estimate parallel performance of the serial run (assuming likeness of parallelizability between the computations).  If the reason a wall clock time is needed is for allocation purposes on a \u2018new\u2019 system, one might report in scaling percentages based on runs made on another cluster.</p>"
    ],
    "198": [
        "<p>On-loading and off-loading interconnect: what are the differences?</p>\n<p><strong>CURATOR:</strong> Wirawan</p>",
        "<p>Recently, Intel introduced the Omnipath Architecture (OPA) as an alternative to the more established Infiniband. OPA falls under the category of \u201conloading interconnect\u201d technology, whereas Infiniband is an \u201coffloading interconnect\u201d.</p>"
    ],
    "221": [
        "<p>I am trying to connect to our cluster using the <code>ssh</code> command:</p>\n<p><code>ssh -X username@scc1.bu.edu</code></p>\n<p>But every time I go to lunch or am not using my laptop for a few minutes, my session is disconnected. I am using a Mac laptop.</p>",
        "<p><strong>ANSWER:</strong> Try to use <code>-Y</code> option when connecting to the cluster from Mac:</p>\n<p><code>ssh -Y username@server.name</code></p>\n<p><code>-Y</code> option on Mac corresponds to  <em>trusted X11 forwarding</em>. When you use <code>ssh -Y username@server.name</code> the remote machine is treated as trusted client.</p>",
        "<p><strong>ANSWER:</strong> As Pointed out by Katia, the <code>-Y</code> flag may do the trick especially if this only happens with X11 forwarding with <code>-X</code> (i.e. using a GUI).</p>\n<p>if it doesn\u2019t help, or it also happens without <code>-X</code>.<br>\nIt could be the \u2018keep alive\u2019 settings<br>\nTake a look at:<br>\n<aside class=\"onebox stackexchange\">\n  <header class=\"source\">\n      <a href=\"https://unix.stackexchange.com/questions/2010/what-does-the-broken-pipe-message-mean-in-an-ssh-session\" target=\"_blank\" rel=\"nofollow noopener\">unix.stackexchange.com</a>\n  </header>\n  <article class=\"onebox-body\">\n      <a href=\"https://unix.stackexchange.com/users/1431/peter-stuifzand\" target=\"_blank\" rel=\"nofollow noopener\">\n    <img alt=\"Peter Stuifzand\" src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/378724363e2c408a13bc049143ccf1c7e8d41d66.jpeg\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n  </a>\n<h4>\n  <a href=\"https://unix.stackexchange.com/questions/2010/what-does-the-broken-pipe-message-mean-in-an-ssh-session\" target=\"_blank\" rel=\"nofollow noopener\">What does the Broken pipe message mean in an SSH session?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>ssh</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://unix.stackexchange.com/users/1431/peter-stuifzand\" target=\"_blank\" rel=\"nofollow noopener\">\n    Peter Stuifzand\n  </a>\n  on <a href=\"https://unix.stackexchange.com/questions/2010/what-does-the-broken-pipe-message-mean-in-an-ssh-session\" target=\"_blank\" rel=\"nofollow noopener\">09:04AM - 14 Sep 10 UTC</a>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n<br>\nand explanation breaking it down:<br>\n<aside class=\"onebox stackexchange\">\n  <header class=\"source\">\n      <a href=\"https://unix.stackexchange.com/questions/3026/what-options-serveraliveinterval-and-clientaliveinterval-in-sshd-config-exac\" target=\"_blank\" rel=\"nofollow noopener\">unix.stackexchange.com</a>\n  </header>\n  <article class=\"onebox-body\">\n      <a href=\"https://unix.stackexchange.com/users/2094/m-tibbits\" target=\"_blank\" rel=\"nofollow noopener\">\n    <img alt=\"M. Tibbits\" src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/9cfadb93d1793deb2f979f7510c9ff4449d350b2.png\" class=\"thumbnail onebox-avatar\" width=\"128\" height=\"128\">\n  </a>\n<h4>\n  <a href=\"https://unix.stackexchange.com/questions/3026/what-options-serveraliveinterval-and-clientaliveinterval-in-sshd-config-exac\" target=\"_blank\" rel=\"nofollow noopener\">What options `ServerAliveInterval` and `ClientAliveInterval` in sshd_config exactly do?</a>\n</h4>\n\n<div class=\"tags\">\n  <strong>ssh, configuration</strong>\n</div>\n\n<div class=\"date\">\n  asked by\n  \n  <a href=\"https://unix.stackexchange.com/users/2094/m-tibbits\" target=\"_blank\" rel=\"nofollow noopener\">\n    M. Tibbits\n  </a>\n  on <a href=\"https://unix.stackexchange.com/questions/3026/what-options-serveraliveinterval-and-clientaliveinterval-in-sshd-config-exac\" target=\"_blank\" rel=\"nofollow noopener\">04:11PM - 12 Oct 10 UTC</a>\n</div>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>"
    ],
    "40": [
        "<p>I have a job that has 6 MPI processes with 4 OpenMP threads per process.  How do I write a SLURM script to submit this job?</p>\n<p>18.04.19:<br>\nNotes:</p>\n<ol>\n<li>Assumptions:<br>\nprocessor == logical CPU<br>\nnode hierarchy: node/socket/core/thread<br>\nthreads per task = cpus per task (see below)<br>\nMPI process == MPI task == task<br>\ndefault:  1 cpu per task<br>\n=&gt; \u201cOpenMP threads per process\u201d == cpus-per-task == OMP_NUM_THREADS</li>\n<li>Node specs not given: we will assume 16 core/node.</li>\n<li>Hyperthreading not turned on (generally not useful for HPC environs).<br>\n*For SLURM, this makes one thread per core, and equivalently, one cpu per core</li>\n<li>SelectType=select/cons_res<br>\n=&gt; CPU is consumable resource</li>\n</ol>\n<p>So, \u201c6 MPI processes with 4 OpenMP threads per process\u201d specifies a total of<br>\n6 MPI tasks, with 4 threads per task, the latter expressed as <code>OMP_NUM_THREADS = 4</code><br>\nand/or <code>cpus-per-task = 4</code>.  These variables correspond to <code>-n</code> and <code>-c</code>, which are the minimum specifications needed to submit a job.</p>\n<p>The number of nodes is not specified, so we leave that to SLURM.</p>\n<pre><code class=\"lang-auto\">#!/bin/bash\n#SBATCH   --ntasks=6\n#SBATCH   --cpus-per-task=4\n\nOMP_NUM_THREADS = 4\n</code></pre>\n<p><strong>CURATOR:</strong> Torey</p>",
        "<p>Hi Jack,<br>\nI\u2019d set up the script in terms of number of nodes and number of tasks per node, then specify number of threads; something along these lines (assume each node has 16 core, or cpu):</p>\n<pre><code class=\"lang-auto\">#SBATCH --nodes=2\n#SBATCH --ntasks-per-node=8\n#SBATCH --cpus-per-task=2\n#SBATCH --ntasks=32\n\nOMP_NUM_THREADS=2\n</code></pre>\n<p>In the srun line, you can specify number of nodes and number of processes per node, but that shouldn\u2019t be necessary if you\u2019ve defined those as above.  The MPI part is the number of tasks, the OpenMP is the number of processes per task.</p>\n<p>I hope this helps; questions are welcome!</p>"
    ],
    "78": [
        "<p>How do I submit an MPI/OpenMP job in a slurm cluster? Are there any tricks to ensure that processors and memory get assigned the way that I am intending?</p>",
        "<p>You should supply the following options to sbatch (typically, as shown here<br>\nas part of the job script):</p>\n<pre><code>#!/bin/sh\n#SBATCH --cpus-per-task=4\n#SBATCH --ntasks=6\n...\n</code></pre>\n<p>The \u201c\u2013cpus-per-task=4\u201d can be be abbreviated \u201c-c 4\u201d and the \u201c\u2013ntasks=6\u201d can<br>\nbe abbreviated \u201c-n 6\u201d.</p>\n<p>The specifies that you wish to run 6 MPI \u201ctasks\u201d, with each task getting 4<br>\nCPU cores.   This way every OpenMP thread will get its own CPU core.  It will<br>\nalso ensure that all four cores for each MPI task are allocated on the same node<br>\n(e.g. you won\u2019t get 10 cores on each of 2 nodes and 4 cores on a third node).</p>\n<p>You will need to add other sbatch options (walltime, memory, etc) as usual.</p>"
    ],
    "280": [
        "<p>Which notebook tools are most appropriate for writing down procedures, observations, conclusions and for drawing flowcharts?</p>",
        "<p>The HMS data management group has evaluated some of the tools currently available and created a comparison matrix.</p>\n<p><aside class=\"onebox whitelistedgeneric\">\n  <header class=\"source\">\n      <img src=\"https://ask.cyberinfrastructure.org/uploads/default/original/1X/5cc803df0dc2442211033b06d1e17f5512d6e7f5.png\" class=\"site-icon\" width=\"32\" height=\"32\">\n      <a href=\"https://datamanagement.hms.harvard.edu/electronic-lab-notebooks\" target=\"_blank\" rel=\"nofollow noopener\">datamanagement.hms.harvard.edu</a>\n  </header>\n  <article class=\"onebox-body\">\n    <div class=\"aspect-image\" style=\"--aspect-ratio:690/407;\"><img src=\"http://static.projects.iq.harvard.edu/files/styles/os_files_xxlarge/public/bdata/files/eln_matrix_thumb.png?m=1516137909&amp;amp;itok=acO-P-k1\" class=\"thumbnail\"></div>\n\n<h3><a href=\"https://datamanagement.hms.harvard.edu/electronic-lab-notebooks\" target=\"_blank\" rel=\"nofollow noopener\">Electronic Lab Notebooks</a></h3>\n\n<p>Electronic Lab Notebooks at HMS  Lab notebooks are good for writing down procedures, observations, conclusions and for drawing flow charts and diagrams by hand. However, in order to accommodate the increase of digital data collected, researchers have...</p>\n\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n<br>\nor<br>\n<aside class=\"onebox googledocs\">\n  <header class=\"source\">\n      <a href=\"https://docs.google.com/spreadsheets/d/1ar8fgwagOh30E31EAPL-Gorwn_g6XNf81g3VDQnQ_I8/edit#gid=0\" target=\"_blank\" rel=\"nofollow noopener\">docs.google.com</a>\n  </header>\n  <article class=\"onebox-body\">\n    <a href=\"https://docs.google.com/spreadsheets/d/1ar8fgwagOh30E31EAPL-Gorwn_g6XNf81g3VDQnQ_I8/edit#gid=0\" target=\"_blank\" rel=\"nofollow noopener\"><span class=\"googledocs-onebox-logo g-sheets-logo\"></span></a>\n\n<h3><a href=\"https://docs.google.com/spreadsheets/d/1ar8fgwagOh30E31EAPL-Gorwn_g6XNf81g3VDQnQ_I8/edit#gid=0\" target=\"_blank\" rel=\"nofollow noopener\">ELN Features Matrix</a></h3>\n\n<p>Sheet1\n\n      Yes \n      No\n  *   Additional Information available on the ELN subpage\n\nPage last updated August 22,...</p>\n\n  </article>\n  <div class=\"onebox-metadata\">\n    \n    \n  </div>\n  <div style=\"clear: both\"></div>\n</aside>\n</p>",
        "<p>Wow <a class=\"mention\" href=\"/u/raminder\">@raminder</a> this is fantastic! Did you capture which of those solutions are open source, and how they are impemented? For example, if I wanted to bootstrap one with a Python backend, how would I find this information?</p>",
        "<p>I am aware eLabFTW (<a href=\"https://www.elabftw.net/\">https://www.elabftw.net/</a>) is open source notebook developed using PHP/MySQL. On <a href=\"https://datamanagement.hms.harvard.edu/electronic-lab-notebooks\">https://datamanagement.hms.harvard.edu/electronic-lab-notebooks</a>,  If you click on the individual tools on the left, it shows all the features and classification but somehow there is no good search/summary available.</p>",
        "<p>Have you thought about either rendering the Google Sheet (with Sheets API) into a static interface so it\u2019s easier to browser, or creating a Github repository (with Github Pages) to render the information? It\u2019s very hard to browse in the Google Sheet, and probably there is a lot of good information to share!</p>"
    ],
    "277": [
        "<p>I have a researcher asking for a build of Abinit with netCDF.  Is there precedent someone can share with me? The machine I\u2019m using is a homogeneous cluster of x86 nodes.</p>\n<p><strong>CURATOR:</strong> torey</p>",
        "<p><strong>ANSWER:</strong><br>\nI have a successful build of Abinit 8.4.2 on a cluster of x86s.  It\u2019s not the latest production upgrade, but is at least version 8.  Much trial and error and testing of false leads resulted in what amounts to a fairly straightforward build script.</p>\n<p>At one point during this process, I realized Abinit has a `fallback\u2019 directory that harbors various software packages one might choose to include in one\u2019s Abinit build.  To grab it, download all fallbacks listed below the appropriate version of Abinit at</p>\n<p><code>http://www.abinit.org/downloads/fallbacks-sources</code>.</p>\n<p>Ultimately, I wasn\u2019t able to build successfully with the fallback netCDF; I ended up using the netCDF instance already present on my cluster.  [I chose the combined Fortran and C version.] As you\u2019ll see in the build script, I left the fallback directory information in the script for possible future reference, but it does not contribute to the final build.</p>\n<h1>170712: build script for 8.4.2 with netCDF:</h1>\n<pre><code class=\"lang-bash\">#! /bin/bash     \nmodule purge     \nmodule load PrgEnv/intel/16.0     \nmodule load openmpi/intel/1.6.5     \nmodule load PrgEnv/netcdf/combined/C-4.3.0_F-4.2     \nmodule load PrgEnv/hdf5/intel/1.8.11     \nmodule load PrgEnv/python/gcc/3.4.3     \n     \nBUILDROOT=/opt/BUILD/src/abinit/AB842-NC/abinit-8.4.2     \n     \nexport CC=mpicc     \nexport CXX=mpicxx     \nexport FC=mpif90     \nexport F77=mpif77     \n     \n./configure \\     \n   --enable-mpi \\     \n   --enable-netcdf \\     \n      --with-netcdf-incs=\"-I/opt/netcdf/C-4.3.0_F-4.2/include\" \\     \n      --with-netcdf-libs=\"-L/opt/netcdf/C-4.3.0_F-4.2/lib -lnetcdf -lnetcdff\" \\     \n      --with-trio-flavor=\"netcdf\" \\     \n   --with-fallbacks-tardir=${BUILDROOT}/distrib \\     \n   --prefix=/opt/abinit/8.4.2-NC     \nmake &amp;&gt; ../BUILD842nc.log     \nmake install     \n</code></pre>"
    ],
    "248": [
        "<p>My R code fails within a 3rd party package. I would like to debug it to understand what exactly causes the code to fail (and possibly change my input parameters). Is there a way to do it?</p>\n<p>The package I have a problem with is <a href=\"https://cran.r-project.org/web/packages/mgcv/index.html\" rel=\"nofollow noopener\">mgcv</a> (function <code>gam()</code>).<br>\nIt runs fine for some formulas I have and fails or takes forever with others.<br>\nI wonder if I can debug the code within the package to see where the code fails.</p>",
        "<p>I know this is an old issue, but you can see the source code for R functions by typing the name of the function without the parenthesis. (so for <code>gam()</code>, you would just type <code>gam</code>)</p>\n<p>You can then copy that code into your own script (I usually name it something similar like <code>gam2</code> and debug/alter it as needed. It\u2019s probably not the most elegant solution, but it has worked for me in the past.</p>",
        "<p>Yes, This is exactly the solution I found that worked for me!.Thank you.</p>"
    ],
    "268": [
        "<p>How do I know whether I\u2019m required to use two-factor authentication using Bridges file transfer? Are there any situations where I should not be using two-factor authentication, or should I be using it by default?</p>"
    ],
    "278": [
        "<p>I would like to mount a CIFS group share directory on a Linux server and maintain the group permissions of users configured in the Active Directory (AD). The Linux server is already configured to use AD.</p>\n<p>CURATOR: Raminder Singh</p>",
        "<p>Here are the commands to mount with write permissions on the group share:</p>\n<pre><code class=\"lang-auto\">mount -t cifs -o username='userid',workgroup='groupName',uid='userid',gid='groupname/id',file_mode=0664,dir_mode=0775 //server/location/ 'local mount location'\n</code></pre>"
    ]
}